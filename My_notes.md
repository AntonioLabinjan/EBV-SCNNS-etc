#### Ovaj file Ä‡u koristit za pisanje biljeÅ¡ki i zapaÅ¾anja kad krenen detaljnije istraÅ¾ivat materiju i Äitat resources koje iman

Neuromorphic Electronic Systems, Carver Mead, 1990
- https://hasler.ece.gatech.edu/Published_papers/Technology_overview/MeadNeuro1990.pdf

- PotroÅ¡nja energije je velik problem kod raÄunala
- ObiÄna raÄunala ne mogu imitirati mozak, pa ni njegove najjednostavnije procese
- Mozak je i 10 milijuna puta efikasniji nego raÄunala iz 90-ih
- Funkcije u mozgu se mogu djeliti na: jednostavne elementarne funkcije, reprezentacije informacija i najkompleksnije organizacijske principe 
- Ideja je pokuÅ¡ati reverse-engineerati mozak
- Kompleksno je rastavljati fizikalne principe u bitove i onda ih rekreirati s AND i OR gatesima
- Mozak se moÅ¾e gledati kao distribuirani sustav s viÅ¡e nodesa koji primaju elektriÄne impulse
- Sigurno se radi o nelinearnim funkcijama
- Napon u sinapsama neurona za osnovne funkcije raste eskponencijalno s naponom
- Mozak ima i sustave za dugotrajno uÄenje i memoriju
- Dobro izgraÄ‘en sustav moÅ¾e simulirati uÄenje i pamÄ‡enje (silicon chips)
- Neuromorphic sustavi su sustavi koji implementiraju iste operacija poput Å¾ivÄanog sustava
- Zero-cost addition using Kirchhoff's Law

Kirchhoffov zakon (struja): u jednom Ävoru zbroj svih struja koje ulaze = zbroj svih struja koje izlaze.

Ako viÅ¡e izvora struje spojiÅ¡ na isti Ävor â†’ automatski se saberu (nema dodatnih komponenti).

Zero-cost addition = zbrajanje bez dodatnog sklopa â†’ priroda elektronike sama radi raÄunanje.

Kapacitet Ävora (parazitski ili namjerni kondenzator) integrira ukupnu struju tijekom vremena â†’ dobijeÅ¡ napon koji predstavlja zbroj.

U digitalnim sklopovima bi ti za zbrajanje trebao adder (logika, tranzistori, energija).

U neuromorfnim sklopovima: samo spojiÅ¡ sinaptiÄke struje na Ävor i dobijeÅ¡ sabiranje â€œbesplatnoâ€.

To je ultra-bitno jer neuron = integrator sinaptiÄkih ulaza â†’ Kirchhoff + kapacitet daju ti toÄno tu funkcionalnost prirodno.

Mead je rekao: iskoristi fiziku (Kirchhoffov zakon) umjesto da je â€œnadograÄ‘ujeÅ¡â€ kompleksnim digitalnim adderima.

ğŸ‘‰ Ukratko: viÅ¡e sinapsi Å¡alje spikeove kao struje â†’ struje se automatski zbroje na membrani neurona â†’ kondenzator integrira â†’ izlaz = ponaÅ¡anje bioloÅ¡kog neurona, i to praktiÄki bez troÅ¡ka.

Evo kako ide â€œstoryâ€ u neuromorfnom hardveru i u mozgu:

ViÅ¡e sinapsi Å¡alje svoje â€œsignaleâ€ (u elektronici kao struje, u mozgu kao ionski tokovi).

Te sve struje ulaze u jedan Ävor (membrana neurona).

Po Kirchhoffovom zakonu â†’ struje se automatski zbroje (niÅ¡ta ne moraÅ¡ posebno raÄunati).

Kondenzator membrane integrira taj ukupni signal kroz vrijeme â†’ to daje membranski potencijal.

Ako potencijal preÄ‘e odreÄ‘eni threshold â†’ neuron ispali spike (akcijski potencijal).

ğŸ‘‰ Ukratko: Neuron radi kao prirodni zbrajaÄ + integrator.

Sabira ulaze (Kirchhoff).

Pamti ih kroz vrijeme (kapacitor = integracija).

Triggera izlaz kad sve skupa dosegne kritiÄnu vrijednost (threshold).

- Zjenica oka se, pri direktom osvjetljenju Äini svjetlijom/tamnijom u odnosu na okolinu, ovisno o okolini
- Zjenica stvara napon po primitku inputa (svjetlosti)
- RaÄuna se prosjek prostorno weighted inputa (ne vrijedi svaki input jednako, ovisno o poziciji)
- Cilj je napraviti senzor sliÄan oku koji moÅ¾e reagirati na sve inpute, neovisno od kud dolaze i koji im je intenzitet (zato se koriste weightovi)
- Koriste se amplifieri kako bi se bolje simulirao pravi potencijal Å¾ivÄanog sustava
- Laplacian filter => edge detction filter

Ajmeee, top Å¡to pitaÅ¡ za Laplacian filter! ğŸ”¥ To ti je jedan od najpoznatijih **edge detection filtera** u raÄunalnom vidu i obradi slika.

Evo ti jasno u natuknicama:

---

### ğŸ”¹ Å to je Laplacian filter?

* **MatematiÄki temelj:** koristi **Laplacian operator** (druga derivacija funkcije).
* **Poanta:** pronalazi mjesta gdje se intenzitet slike brzo mijenja â†’ tj. rubove (*edges*).
* Za razliku od Sobel/Prewitt (koji koriste prvu derivaciju i detektiraju smjer ruba), Laplacian gleda **drugu derivaciju** â†’ pa je osjetljiv na *naglu promjenu nagiba*.

---

### ğŸ”¹ Kako radi na slici?

* Sliku gleda kao **matricu piksela**.
* Na svaki piksel primjenjuje kernel (konvolucijsku masku) koji aproksimira Laplacian operator.
* TipiÄni kernel izgleda npr. ovako:
Laplacian filter kerneli:
```
0  -1   0
-1  4  -1
0  -1   0
```

i "jaÄa" verzija:
```
-1  -1  -1
-1   8  -1
-1  -1  -1
```

* Kad se primijeni, filter daje visoke vrijednosti na mjestima gdje postoji jaka promjena intenziteta â†’ tj. rub.

---

### ğŸ”¹ ZaÅ¡to je koristan?

* Detektira rubove **neovisno o smjeru** (Sobel detektira horizontalne/vertikalne, Laplacian je â€œisotropicâ€).
* Jako dobar za **naglaÅ¡avanje struktura** i **detekciju kontura**.
* ÄŒesto se koristi nakon blura (npr. Gaussian blur + Laplacian = *Laplacian of Gaussian*, LoG) â†’ to pomaÅ¾e da se smanji Å¡um.

---

### ğŸ”¹ Intuicija

* Ako piksel izgleda â€œsliÄanâ€ susjedima â†’ rezultat â‰ˆ 0.
* Ako je piksel jako razliÄit od susjeda â†’ rezultat velik (pozitivan ili negativan) â†’ to je rub.

---

ğŸ‘‰ Ukratko: **Laplacian filter je edge detector baziran na drugoj derivaciji, hvata rubove u svim smjerovima i jako se koristi u raÄunalnom vidu.**


PRIMJER PRIMJENE by ChatGPT:

Ajmo brutalno jednostavno da odmah sjedne ğŸ”¥

---

### ğŸ“Œ Primjer matrice (mala â€œslikaâ€ 5Ã—5 piksela)

Zamisli da imaÅ¡ grayscale sliku, gdje su vrijednosti piksela:

```text
10  10  10  10  10
10  10 100  10  10
10  10 100  10  10
10  10 100  10  10
10  10  10  10  10
```

ğŸ‘‰ To ti je slika gdje imaÅ¡ **vertikalnu bijelu crtu** (100) na sredini crne pozadine (10).

---

### ğŸ“Œ Laplacian kernel (klasiÄni)

```text
0  -1   0
-1  4  -1
0  -1   0
```

---

### ğŸ“Œ Primjena filtera (konvolucija)

1. Uzimamo kernel 3Ã—3 i stavljamo ga iznad piksela u centru (recimo sredina je `100`).
2. PomnoÅ¾imo element po element i zbrojimo:

```
Kernel:          Dio slike:       Rezultat = sum(kernel * dio_slike)

 0  -1   0       10  100  10
-1   4  -1   *   10  100  10   =   (0*10) + (-1*100) + (0*10) +
 0  -1   0       10  100  10       (-1*10) + (4*100) + (-1*10) +
                                    (0*10) + (-1*100) + (0*10)

= -100 -10 +400 -10 -100
= 180
```

ğŸ‘‰ Dakle u centru bijele crte izlazni piksel je **jako velik (180)** â†’ filter ga oznaÄi kao rub.

3. Ako isti kernel stavimo na dio pozadine (gdje su sve vrijednosti 10):

```
 0  -1   0       10  10  10
-1   4  -1   *   10  10  10   = (0*10) + (-1*10) + (0*10) +
 0  -1   0       10  10  10      (-1*10) + (4*10) + (-1*10) +
                                  (0*10) + (-1*10) + (0*10)

= -10 -10 +40 -10 -10
= 0
```

ğŸ‘‰ Rezultat = **0** â†’ pozadina nema rub, pa filter niÅ¡ta ne detektira.

---

### ğŸ“Œ ZakljuÄak

* Na rubu (gdje se vrijednost naglo mijenja) dobijeÅ¡ **visok rezultat**.
* Na ravnom dijelu slike â†’ rezultat â‰ˆ **0**.

---

Primjenjuje se na cijelu sliku, dio po dio
Evo kako to ide u praksi:

ImaÅ¡ cijelu sliku (npr. 512Ã—512 piksela).

Uzmemo kernel (mala matrica, npr. 3Ã—3 ili 5Ã—5).

Kernel â€œkliziâ€ po slici â€“ piksel po piksel, red po red (to se zove konvolucija).

Za svaki poloÅ¾aj:

UzmeÅ¡ â€œkomadiÄ‡â€ slike iste veliÄine kao kernel.

PomnoÅ¾iÅ¡ element po element (kernel Ã— slika).

ZbrojiÅ¡ sve rezultate â†’ to je novi izlazni piksel u filtriranoj slici.

Rezultat cijelog procesa = nova slika gdje su naglaÅ¡eni rubovi (ili Å¡to god kernel radi).

ğŸ‘‰ Dakle, da, filter se primjenjuje na cijelu sliku, dio po dio, i rezultat je feature map (slika s naglaÅ¡enim znaÄajkama).

- PomaÅ¾e u lokalizaciji objekata (odredimo di su u prostoru pomoÄ‡u edge detectiona)
- Bitno je napravit da se broj kalkulacija u oku/mozgu prilagodi broju vanjskih evenata (MOZAK NE PROCESIRA ISTU KOLIÄŒINU PODATAKA AKO GLEDA U BIJELI ZID I AKO -GLEDA U NEÅ TO POKRETNO I DINAMIÄŒNO) => dali je to maybe event-based princip??
- Cilj: viÅ¡e kalkulacija za viÅ¡e evenata; manje kalkulacija za manje evenata
- VaÅ¾nost napona pojedinog eventa slabi s protokom vremena i dolaskom novih evenata
- Ni jedan senzor u oku i mozgu nije 100% isti kao neki drugi i zato koriste adaptivne mehanizme da kompenziraju manjak preciznosti
- U mraku zjenica ne mora niÅ¡ procesirat jer ne vidi niÅ¡
- Uzima se input. Radi se predikcija inputa (Äa mozak misli da vidi). Ako je ok, ne dela nikakav dodatan tuning. Ako pogrijeÅ¡i, mora opet kalkulirat i malo prilagodit parametre (primjer: zjenice se Å¡ire u tami da bolje vidimo)
- Isti princip je i za situaciju: neÅ¡to gledamo i delamo predikciju Äa Ä‡e se desit. Ako pogrijeÅ¡imo, radi se tuning, ako pogodimo, sve je ok
- Adaptation feedback
- Mozak raÄuna average od svih viÄ‘enih piksela da se bolje adaptira i da vidi bitno, a izbacuje nebitno
- Problem simuliranog mozga pomoÄ‡u Äipova: ako 1 Äip crkne, sve zgori. Stvara se jako puno topline i troÅ¡i se puno energije
- NaÅ¡ mozak nije u potpunosti spojen (x nodeova spojeno sa x nodeova, nego su spojeni lokalno i onda se to nadoveÅ¾e, ali ne svaki sa svakin, jer bi to zauzimalo previÅ¡e mista)
- Lokalno spajanje je kljuÄno za efikasnost
- Ako imamo nepravilne inpute, treba nam neuromorphic computing 
- I do 10x efikasnije u performansama + 10000 x manje power consumptiona


 A 128x128 120 db 15 Âµs Latency Asynchronous Temporal Contrast Vision Sensor, Patrick Lichsteiner, Cristopher Posch, Tobi Debruck
- https://www.ifi.uzh.ch/dam/jcr:18928364-d16b-4403-9217-2098aaad72bd/lichtsteiner_dvs_jssc08.pdf
- 128x128 pikselni CMOS vision senzor
- Svaki piksel zasebno i kontinuirano generira spike evente na temelju lokalnih promjena intenziteta
- brÅ¾i od milisekunde
- "mreÅ¾nica od silcija"

- PROS and CONS FRAME BASED VISIONA
- PROS: mali i jednostavni pikseli -> visoka rezolucija
                                   -> viskok fill factor i nizak imager cost
---

### ğŸ¯ **Fill Factor**

**Definicija:**
Fill factor = **udio povrÅ¡ine piksela koji stvarno prima svjetlo** u odnosu na **ukupnu povrÅ¡inu piksela**.

Zamisli da svaki piksel ima odreÄ‘enu povrÅ¡inu (npr. 10Ã—10 Âµm). Dio te povrÅ¡ine zauzimaju fotodetektor i elektroniÄki sklopovi (tranzistori, kondenzatori, Å¾ice...).
Samo **fotodetektor** (photo diode) zapravo skuplja svjetlo â€” i to je efektivna "korisna povrÅ¡ina".

ğŸ‘‰ Formula:
[
\text{Fill Factor} = \frac{\text{PovrÅ¡ina osjetljiva na svjetlo}}{\text{Ukupna povrÅ¡ina piksela}} \times 100%
]

---

**Primjer:**

* Ako je piksel 10Ã—10 Âµm, ali samo 5Ã—5 Âµm hvata svjetlo â†’ fill factor = 25%.
* Ako se koristi **mikro-leÄ‡e** koje fokusiraju svjetlo na aktivni dio â†’ fill factor raste.

---

**ZaÅ¡to je bitan:**

* **VeÄ‡i fill factor = bolja osjetljivost na svjetlo (viÅ¡i SNR)**
* **Manji fill factor = viÅ¡e Å¡uma, loÅ¡iji kontrast u slabom svjetlu**

---

**U kontekstu frame-based senzora:**
Frame-based senzori imaju **jednostavnije piksele**, pa mogu imati **veÄ‡i fill factor** i time hvataju viÅ¡e svjetla â€” to je njihov *PRO*.

**Kod DVS-a (event-based):**
Pikseli imaju viÅ¡e elektronike (detekcija promjene intenziteta, threshold komparator itd.) â€” pa Äesto **fill factor pada**.
Zato se Äesto dodaju **mikroleÄ‡e** i posebni layouti da se fill factor poboljÅ¡a.

---

### âš¡ **Imager Noise (Å¡um senzora)**

**Definicija:**
To je **neÅ¾eljena varijacija** u elektriÄnom signalu piksela koja **nije rezultat stvarne promjene svjetla**.

---

**Glavne vrste Å¡uma u imagerima:**

1. **Photon shot noise** â€“ dolazi od same prirode svjetlosti (nasumiÄan broj fotona).
2. **Thermal noise (Johnson noise)** â€“ termiÄke fluktuacije u elektronici.
3. **Read noise** â€“ Å¡um koji nastaje pri Äitanju signala s piksela (ADC, bufferi...).
4. **Fixed pattern noise (FPN)** â€“ razlike izmeÄ‘u piksela zbog proizvodnog procesa.

---

**ZaÅ¡to je bitan:**

* Visok Å¡um â†’ senzor ne moÅ¾e toÄno detektirati male promjene svjetla.
* Kod **DVS-a**, Å¡um direktno utjeÄe na toÄnost generiranja eventa â€”
  ako je noise previsok, senzor moÅ¾e â€œlaÅ¾noâ€ detektirati promjenu i emitirati spike event iako svjetlo nije stvarno promijenjeno.

---

**Balans kod DVS-a:**

* Ako se threshold za promjenu intenziteta postavi **prenisko**, Å¡um Ä‡e stvarati laÅ¾ne evente.
* Ako se postavi **previsoko**, senzor Ä‡e ignorirati male, ali bitne promjene u sceni.

---

### ğŸ” Ukratko:

| Pojam            | ObjaÅ¡njenje                                                               | Posljedica                              |
| ---------------- | ------------------------------------------------------------------------- | --------------------------------------- |
| **Fill Factor**  | Postotak povrÅ¡ine piksela koji hvata svjetlo                              | ViÅ¡i = bolja osjetljivost               |
| **Imager Noise** | NasumiÄne elektroniÄke varijacije koje uzrokuju greÅ¡ke u mjerenju svjetla | ViÅ¡i = viÅ¡e laÅ¾nih eventa, niÅ¾a toÄnost |

---

- CONS: - baziran na serijama snapshota -> pikseli se ponovno obraÄ‘uju Äak i ako su nepromijenjeni iz framea u frame -> JAKO BITNO
        - limitirani bandwith (FRAME RATE/2)
        - limitirani dynamic range (ograniÄen broj piksela po frameu)

IDEJA: senzor koji prati promjene inteziteta u okolini i pretvara ih u asinkrone promjene piksela
output: asinkroni stream pixel address evenata (AEs) => smanjuje se redundantnost (ignoriramo nepromijenjene piksele)
imitiranje bioloÅ¡kog vida i odbacivanje frame-based principa

KONCEPT ADDRESS-EVENT: svaki piksel dobije svoju koordinatnu adresu (lokalni array)
                       kontinuirano; sliÄno kao moÅ¾dani impulsi
                       jako high speed

PROBLEM S PROTOTIPOVIMA: uopÄ‡e ne smanjuju redundantnost podataka, nego samo prostornu redundantnost
- puno noisea
- spori response
- limitirani dynamic range
- mala osjetljivost na kontrast

POLJE JE BILO NERAZVIJENO ZBOG NEZNANJA O ASINKRONOSTI I ZBOG BEZNAÄŒAJNE UNIFORMNOSTI RESPONZIVNIH KARAKTERISTIKA PIKSELA

1) AER senzor -> MAHOWALD I MEAD
   - silikonska mreÅ¾nica s adaptivnim fotoreceptorima, spatial smoothing mreÅ¾om i self-timed komunikacijom
   DEMO UREÄAJ BEZ IKAKVE REAL-WORLD PRIMJENE

2) Spatial+temporal filtering -> ZAGHOUL I BOAHEN
   - puno malih tranzistora i el. krugova usko spojenih diffusor networksima
   - veliki mismatch -> GOTOVO 50% PIKSELA NE OSTVARUJE SPIKE

3) CSEM NEUCHATEL -> ostvaren spatial kontekst -> transisija evenata high-low
  - moguÄ‡e zaustaviti ranije
  - ne smanjuje redundantnost, ograniÄena rezolucija zbog frame ratea

4) CULURCIELLO-ANDREON -> inter-event interval / mean frequency
   (+) - mala koliÄina piksela
   (-) - bandwith ovisi o osvjetljenju
   nema reset mehanizma (puno tamnih piskela)

5) ETIENNE-CUMMING
   - temporal change detection imager
   - moÅ¾e detektirati apsolutnu promjenu osvjetljenja
   - sinkrono -> FIFO pristup
  
VISION SENSOR DESIGN
a) PIXEL DESIGN
 - cilj je: minimizacija mismatcheva
 - Å¡iroki dynamic range
 - low latency
BRZI LOGARITAMSKI PHOTORECEPTOR CIRCUIT -> pojaÄava promjene
- kontrolira pojedine piksele + brzo odgovara/reagira na promjene osvjetljenja
- mana: tranzistori uzrokuju mismatch meÄ‘u pikselima zbog varijacija u thresholdu
- potrebna je dodatna kalibracija
KALIBRACIJA : balansiranje outputa na reset level nakon generiranja eventa (nekon Äa se zabiljeÅ¾i event, senzor se resetira => fadeout u onima mojima testnima kodovima...)
!differencing circuit! -> pikseli su osjetljivi na temporal contrast -> ima formula u paperu; bitno

RECEPTOR CIRCUIT SADRÅ½I: fotodiodu, tranzistor, amplifier -> "TRANSIMPEDANCE CONFIGURATION" -> logaritamska pretvorba photocurrenta u NAPON

- PoveÄ‡an bandwith -> veÄ‡a brzina
- adaptive biasing -> znatno manja potroÅ¡nja energije
- reset switch -> OKIDA input i output zajedno i tako resetira napon

OVO OPISUJE ONAJ PROCES KADA SE EVENT POJAVI NA KAMERI I ONDA SAMO IZBLJEDI I RESETIRA SE

ON i OFF eventi -> circuit ih emitira u periferiju
- Pixel more emitat ili ON ili OFF event (NIKAD OBA ISTOVREMENO) prema periferiji
- Proces "komunikacije" kreÄ‡e kad event trigerira piksel, a zavrÅ¡ava kada se piksel resetira na 0 (vrati u poÄetno stanje)
- Prijevod na glupo: ON event -> neÅ¡to se miÄe i pikseli reagiraju; OFF event -> niÅ¡ se viÅ¡e ne miÄe, pikseli miruju
- Bitna napomena: ON event oznaÄava da je piksel posvjetlio, OFF event da je potamnio

- ograniÄava se "fire-rate" za piksele kako pojedini pikseli ne bi zauzeli sve resurse za obradu
- omoguÄ‡ava da se viÅ¡e resursa posveti aktivnijim podruÄjima (procesiraÅ¡ ono di se neÅ¡to deÅ¡ava; di ima evenata)
- Cilj je da se circuit ne pregrijava pretjerano, da ne troÅ¡i resurse nepotrebno, da radi samo kad se neÅ¡to dogaÄ‘a

KARAKTERISTIKE NAJVAÅ½NIJIH ASPEKATA:

- Uniformity of response - vraÄ‡a razliku u osvjetljenju piksela -> bitno je uniformno i standardizirano evaluirati promjene
- Dynamic range - razlika imzeÄ‘u maksimalnog i minimalnog osvjetljenja u "sceni" kroz piksele; reliable and reproducible events
- Pixel bandwith - iznos raspona jaÄine najjaÄeg i najslabijeg intenziteta koji 1 piksel "prepozna"/"odradi". Stariji i noviji eventi se razlikuju u intenzitetu; intenzitet opada protokom vremena (fade-out)
- Latency&Latency jitter - ideja: Äa je osvjetljenje manje, latencija je veÄ‡a => proporcionalna reciproÄnom osvjetljenju (Äa je Å¡kurije, teÅ¾e se skuÅ¾e eventi i promjene u svjetlosti kod piksela)
- UtvrÄ‘eno je kako je latencija ipak jako mala u svim uvjetima (SUPER ZA REAL-TIME PROCESSING)


### Synaptic modifications in cultured hippocampal neurons:
### Dependence on spike timing, synaptic strength and postsynaptic cell type
### Guo-qiang Bi&Mu-ming Poo

Eksperimenti raÄ‘eni na hipokampusnim neuronima Å¡takora
PostsinaptiÄki i presinaptiÄki neuroni

PresinaptiÄki neuron = onaj koji Å¡alje signal.

Njegov akson zavrÅ¡ava na sinapsi i otpuÅ¡ta neurotransmitere (npr. glutamat).

To je â€œpoÅ¡iljatelj porukeâ€.

PostsinaptiÄki neuron = onaj koji prima signal.

Na svojim dendritima ima receptore koji hvataju neurotransmitere i reagira (moÅ¾e spajkati ako se dovoljno pobudi). => procesira neÅ¡to samo ako dobije dovoljno inputa i skuÅ¾i da se neÅ¡to desilo

To je â€œprimatelj porukeâ€.

Spike neurona => registrira dovoljno ulaznih signala i preÄ‘e threshold aktivacije => ako je input dovoljno "jak", aktivira se spike
Okine strujni elektriÄni impuls (par milisekundi) i otpuÅ¡ta neurotransmitere

U kontekstu event based visiona => spike je event
Nema stalnih signala kao kod obiÄnih CNN-ova nego samo triger kad se dogodi dovoljno jaka promjena
TroÅ¡i se energija samo kada se neÅ¡to stvarno dogaÄ‘a
Spike => kratki elektriÄni event kojim neuron javlja da je aktivan
Npr. Ako se detektira dovoljno pokreta, onda se input procesira, a ako ima malo/niÅ¡ pokreta, ne procesiramo niÅ¡

LTP i LTD = dugotrajno jaÄanje ili slabljenje sinapsi, inducirano ponavljanom elektriÄnom aktivnoÅ¡Ä‡u.

KlasiÄni protokoli: obiÄno ukljuÄuju repetitivnu presinaptiÄku stimulaciju (razne frekvencije) + Äesto dodatnu depolarizaciju postsinaptiÄkog neurona.

U nekim eksperimentima trebalo je blokirati spontane spikeove (npr. tetrodotoksin) ili smanjiti MgÂ²âº da bi LTP uspio.

Novija istraÅ¾ivanja (in vitro slices) pokazala su da precizno tempirani back-propagating action potentials (postsynaptic spike koji se vraÄ‡a kroz dendrite) mogu inducirati LTP ili LTD.

KljuÄna nova ideja: nije samo vaÅ¾na frekvencija stimulacije â†’ relativno vrijeme izmeÄ‘u presinaptiÄkog i postsinaptiÄkog spikea odluÄuje smjer plastiÄnosti.
Ni bitno koliko je 1 event jak, nego je za spike bitno da se deÅ¡ava viÅ¡e evenata u kratkom vremenu

Rezultati ove studije:

PostsinaptiÄki spike <20 ms nakon presinaptiÄkog â†’ LTP.

PostsinaptiÄki spike <20 ms prije presinaptiÄkog â†’ LTD.

Postoji uska prijelazna zona od samo ~5 ms izmeÄ‘u LTP i LTD.

Ovisnost o poÄetnoj snazi sinapse:

Slabe sinapse = visoka Å¡ansa za LTP.

Jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.

SpecifiÄnost ciljne stanice:

GlutamatergiÄke sinapse na GABA neurone ne pokazuju ovu vrstu plastiÄnosti.

Implicira target cellâ€“specific mehanizme.


---

* **LTP i LTD** = dugotrajno jaÄanje ili slabljenje sinapsi, inducirano ponavljanom elektriÄnom aktivnoÅ¡Ä‡u.
* **KlasiÄni protokoli**: obiÄno ukljuÄuju **repetitivnu presinaptiÄku stimulaciju** (razne frekvencije) + Äesto dodatnu depolarizaciju postsinaptiÄkog neurona.

  * U nekim eksperimentima trebalo je blokirati spontane spikeove (npr. tetrodotoksin) ili smanjiti MgÂ²âº da bi LTP uspio.
* **Novija istraÅ¾ivanja (in vitro slices)** pokazala su da **precizno tempirani back-propagating action potentials** (postsynaptic spike koji se vraÄ‡a kroz dendrite) mogu inducirati LTP ili LTD.
* **KljuÄna nova ideja**: nije samo vaÅ¾na frekvencija stimulacije â†’ **relativno vrijeme izmeÄ‘u presinaptiÄkog i postsinaptiÄkog spikea odluÄuje smjer plastiÄnosti**.
* **Rezultati ove studije**:

  * PostsinaptiÄki spike **<20 ms nakon** presinaptiÄkog â†’ **LTP**.
  * PostsinaptiÄki spike **<20 ms prije** presinaptiÄkog â†’ **LTD**.
  * Postoji uska prijelazna zona od samo **~5 ms** izmeÄ‘u LTP i LTD.
* **Ovisnost o poÄetnoj snazi sinapse**:

  * **Slabe sinapse** = visoka Å¡ansa za LTP.
  * Jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.
* **SpecifiÄnost ciljne stanice**:

  * GlutamatergiÄke sinapse na **GABA neurone** ne pokazuju ovu vrstu plastiÄnosti.
  * Implicira **target cellâ€“specific mehanizme**.

STDP je bioloÅ¡ki mehanizam uÄenja kojim se jaÄina veze (sinaptiÄka teÅ¾ina) izmeÄ‘u dva neurona mijenja ovisno o vremenskom razmaku izmeÄ‘u njihovih spikeova (akcijskih potencijala).

Drugim rijeÄima:
Nije samo vaÅ¾no da neuroni spajkaju zajedno, nego toÄno kada to rade.

Pravilo (u osnovnoj formi):

PresinaptiÄki neuron spajka PRVI â†’ PostsinaptiÄki ubrzo nakon (do ~20 ms)

LTP (Long-Term Potentiation): sinapsa se ojaÄa.

ZnaÄenje: presinaptiÄki neuron je vjerojatno pridonio aktivaciji postsinaptiÄkog â€“ mozak to â€œnagradiâ€ jaÄanjem veze.

PostsinaptiÄki neuron spajka PRVI â†’ PresinaptiÄki tek kasnije (do ~20 ms)

LTD (Long-Term Depression): sinapsa se oslabi.

ZnaÄenje: presinaptiÄki neuron nije uzrokovao aktivaciju postsinaptiÄkog, pa mozak smatra da je ta veza nebitna.

Ako su spikeovi previÅ¡e udaljeni u vremenu (> ~20 ms)

 Nema promjene â€“ mozak zakljuÄuje da nema uzroÄno-posljediÄne veze.
 
 U mozgu (STDP):

Ako presinaptiÄki spike doÄ‘e, i postsinaptiÄki spike se dogodi ubrzo nakon â†’ mozak zakljuÄi da ovaj input uzrokuje ovaj output.

Rezultat = ojaÄaj tu sinapsu (nauÄi asocijaciju).

Ako je obrnuto (postsinaptiÄki prije presinaptiÄkog) â†’ veza se smatra nebitnom â†’ oslabi sinapsu.

Analogija s event-based kamerom:

Ako se u kratkom vremenu i prostoru javi viÅ¡e evenata â†’ sustav zakljuÄuje da pripadaju istoj stvari (npr. kretanje osobe).

Ako eventi dolaze previÅ¡e razdvojeni u vremenu/prostoru â†’ nisu povezani, ignoriraÅ¡ ih.

1. â€œPostsinaptiÄki spike slijedi EPSP unutar ~15 ms â†’ LTPâ€

EPSP (Excitatory Post-Synaptic Potential) = mali elektriÄni signal u postsinaptiÄkom neuronu, nastao kad presinaptiÄki neuron otpusti glutamat.

Ako taj EPSP uspije â€œpoguratiâ€ postsinaptiÄki neuron do praga i on okine spike vrlo brzo nakon toga (~15 ms) â†’ mozak zakljuÄi:

â€œOvaj presinaptiÄki input je doprinos postsinaptiÄkoj aktivaciji.â€

Rezultat: ojaÄaj tu sinapsu (LTP).

To je zapravo bioloÅ¡ki dokaz Hebbove ideje: neuroni koji spajkaju zajedno, povezuju se zajedno, ali uz precizan timing.

2. â€œI slabe i jake sinapse mogu se ojaÄati ako je spike timing pozitivno koreliranâ€

â€œSlaba sinapsaâ€ = EPSP sam po sebi nije dovoljan da izazove spike u postsinaptiÄkom neuronu.

â€œJaka sinapsaâ€ = EPSP dovoljno velik da sam digne neuron do spikea.

Pokus pokazao: i slabe i jake veze se mogu ojaÄati, ako se pobrineÅ¡ da postsinaptiÄki spike padne unutar tog prozora (npr. kod slabih sinapsi su ruÄno injektirali malu struju da potaknu spike nakon EPSP).

ZakljuÄak: bitan je timing, a ne samo jaÄina veze.

â€œNMDA receptori su kljuÄniâ€

NMDA receptor = poseban tip glutamatnog receptora koji je osjetljiv na napon i omoguÄ‡uje ulazak CaÂ²âº iona u neuron.

Taj CaÂ²âº signal je â€œmolekularni prekidaÄâ€ koji pokreÄ‡e plastiÄnost (LTP/LTD).

Kad su ih blokirali s lijekom D-AP5 â†’ nije bilo LTP-a â†’ dakle, bez NMDA nema uÄenja.

LTP (long-term potentiation) = trajno jaÄanje sinapse (poveÄ‡ava se vjerojatnost da Ä‡e signal proÄ‡i).

EPSP (excitatory postsynaptic potential) = mali "plusiÄ‡" napona na postsinaptiÄkom neuronu, kao mini podraÅ¾aj.

Evo paralela s event-based kamerom 

---

### U mozgu (neuroni):

* **PresinaptiÄki spike** = dolazni signal â†’ EPSP.
* **PostsinaptiÄki spike** = izlaz neurona.
* **STDP / LTP** = ako ulazni event stigne malo prije nego neuron ispali, veza se jaÄa.
* **NMDA receptor** = â€œgatekeeperâ€ koji kaÅ¾e: *event se raÄuna samo ako su se ulaz i izlaz poklopili u vremenu*.

---

### U event-based kameri:

* **Pixel event** = presinaptiÄki spike (svaki event je mala promjena â†’ mini EPSP).
* **Kamera/algoritam detektira pokret** = postsinaptiÄki spike (output).
* **STDP logika**:

  * Ako viÅ¡e pixela (ulaznih evenata) **u kratkom vremenu i prostoru** â€œokineâ€ i to dovede do registriranog pokreta (output), sustav zakljuÄi: *ti eventi su povezani, pojaÄaj im znaÄaj*.
* **NMDA paralela** = kao filter koji ne puÅ¡ta â€œrandom Å¡umâ€, nego traÅ¾i da se viÅ¡e evenata poklopi u pravom trenutku â†’ tek onda priznaje da je stvarno detekcija.

---

 Ukratko:
U mozgu â€“ sinapsa se jaÄa ako ulaz brzo dovede do izlaza.
U kameri â€“ grupa evenata se tretira kao znaÄajan pokret samo ako se prostorno-vremenski poklope i generiraju detekciju.

---

Pozitivno korelirani spikeovi (pre â†’ post, unutar ~20 ms)
â†’ rezultira LTP (ojaÄavanje sinapse).

Negativno korelirani spikeovi (post â†’ pre, unutar ~20 ms)
â†’ rezultira LTD (slabljenje sinapse).

Prozor djelovanja (temporal window):

Potencijacija = post-sinaptiÄki spike unutar +20 ms nakon EPSP.

Depresija = post-sinaptiÄki spike unutar âˆ’20 ms prije EPSP.

Izvan Â±40 ms = nema znaÄajne promjene.

NMDA receptori su obavezni i za LTP i za LTD (bez njih nema sinaptiÄke plastiÄnosti).

JaÄina poÄetne sinapse utjeÄe na plastiÄnost:

Slabe sinapse = lakÅ¡e jaÄaju (LTP).

Jako jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.

Tip postsinaptiÄkog neurona:

GlutamatergiÄki = pokazuju STDP (LTP/LTD).

GABA neuroni = nema STDP efekta.

Uloga CaÂ²âº kanala:

L-type CaÂ²âº kanali pomaÅ¾u kod LTP, ali nisu nuÅ¾ni.

Za LTD (depresiju) jesu nuÅ¾ni.

STDP je asimetriÄan:

Ako ulaz doÄ‘e prije izlaza â†’ uÄenje = â€œovo je korisnoâ€ (LTP).

Ako izlaz doÄ‘e prije ulaza â†’ uÄenje = â€œovo nije korisnoâ€ (LTD).
Sve to ovisi o NMDA receptorima, vremenskom prozoru (~Â±20 ms) i jaÄini same sinapse.

Ako se viÅ¡e evenata dogodi vrlo brzo jedan nakon drugog (unutar â€œSTDP prozoraâ€ od ~20 ms), sustav ih tretira kao povezane.

Kao posljedica, postsynaptiÄki spike je jaÄi nego kada bi ti eventi doÅ¡li pojedinaÄno i razdvojeni u vremenu.

BioloÅ¡ki mozak â†’ pojaÄava sinapsu (LTP).

Event-based sustav â†’ grupira dogaÄ‘aje i â€œpojaÄava signalâ€, Å¡to olakÅ¡ava detekciju stvarnih objekata/pokreta.

Ok, ovo je sad super saÅ¾eto i profesionalno â€“ ovo su **kljuÄni zakljuÄci cijelog rada**, izvuÄeni za tvoj event-based vision kontekst:

---

### KljuÄne toÄke / natuknice:

1. **STDP vremensko pravilo je vrlo precizno i usko**:

   * Potencijacija (LTP) se dogaÄ‘a kada **postsynaptiÄki spike slijedi EPSP unutar +20 ms**.
   * Depresija (LTD) se dogaÄ‘a kada **postsynaptiÄki spike prethodi EPSP unutar âˆ’20 ms**.
   * Izvan Â±40 ms â†’ nema znaÄajne sinaptiÄke promjene.
   * Prelaz izmeÄ‘u LTP i LTD je **oÅ¡tra, samo ~5 ms**.

2. **JaÄina sinapse utjeÄe na plastiÄnost**:

   * Slabe sinapse = lako potenciraju (LTP).
   * Jako jake sinapse = mogu biti â€œsaturiraneâ€ i ne reagiraju viÅ¡e na pozitivno korelirane spikeove.

3. **Tip postsinaptiÄkog neurona je kljuÄan**:

   * GlutamatergiÄki neuroni â†’ pokazuju LTP i LTD.
   * GABAergiÄki neuroni â†’ nema sinaptiÄke modifikacije (nije osjetljivo).

4. **NMDA receptori i CaÂ²âº su kritiÄni**:

   * NMDA receptori â†’ obavezni i za LTP i za LTD.
   * L-type CaÂ²âº kanali â†’ potrebni za LTD, pomaÅ¾u za LTP.
   * Lokalni CaÂ²âº spikeovi unutar dendrita omoguÄ‡uju preciznu temporalnu detekciju.

5. **Temporalni slijed spikeova implementira Hebbovu logiku**:

   * Ako **ulaz (presynaptiÄki spike) uzrokuje izlaz (postsynaptiÄki spike)** â†’ veza se jaÄa (LTP).
   * Ako je redoslijed obrnut â†’ veza se slabije aktivira (LTD).
   * Ovo je prirodni â€œcausality detectorâ€ â†’ neuronska mreÅ¾a moÅ¾e uÄiti sekvence i predviÄ‘ati dogaÄ‘aje.

6. **Spontana aktivnost moÅ¾e â€œsaturiratiâ€ sinapse** â†’ starije sinapse u kulturi moÅ¾da ne mogu dodatno potencirati.

7. **Implications for event-based systems:**

   * **Brzo slijedeÄ‡i eventi â†’ tretiraju se kao povezani â†’ jaÄi output**.
   * Sustavi poput spiking CNN-a mogu koristiti STDP logiku da detektiraju obrasce u vremenskim eventima i odluÄe Å¡to je relevantno.
   * Temporalna asimetrija omoguÄ‡uje â€œprediktivno kodiranjeâ€ â†’ sliÄno onome Å¡to mozak radi kod navigacije i sekvencijalnog uÄenja.



A million spiking-neuron integrated circuit with a scalable communication network and interface
Paul A.Merolla&co.

- inspirirano strukturom mozga
- efikasna, skalabilna, fleksibilna, non-von Neumannova arhitektura
- suvremena silikonska tehnologija
- Äip od 5.4 milijardi tranzistora s 4096 neurosinaptiÄkih jezgri meÄ‘usobno povezanih preko intrachip networka
- network se sastoji od milijun programabilnih spiking neurona i 256 milijuna konigurabilnih sinapsi (sinapse su veze meÄ‘u neuronima; zato ima viÅ¡e sinapsi nego neurona jer veze nisu 1:1)
- Äipovi se mogu povezati u 2 dimenzije pomoÄ‡u interchip komunikacijskog interfacea -> skaliranje na razinu cortexlike sheeta proizvoljne veliÄine (cortex => vanjski dio mozga..."kora")
- omoguÄ‡ava koriÅ¡tenje kompleksnih neuronskih mreÅ¾a u realnom vremenu (npr. multiobject detekcija i klasifikacija)
- 400 px x 240px video input brzine 30 fps-a na Äipu troÅ¡i 63 miliwatta
Chatgpt:
Da, ako to stavimo u perspektivu, ovo je **priliÄno efikasno**, pogotovo za embedded ili edge AI Äipove. Hajde da to raÅ¡Älanimo:

* Video ulaz: **400 Ã— 240 px** â†’ 96.000 piksela po okviru.
* Brzina: **30 fps** â†’ 2.880.000 piksela obraÄ‘eno u sekundi.
* PotroÅ¡nja: **63 mW** â†’ 0,063 J po sekundi.

Ako raÄunamo **energiju po pikselu**:

E_per_pixel = 0.063 / (400 * 240 * 30) = 21.875e-9 J = 21.875 nJ/pixel

Za usporedbu, moderni edge AI Äipovi (npr. za male kamere ili IoT senzore) Äesto ciljaju **10â€“100 nJ/piksel** za video obrade pri visokoj efikasnosti.

ZakljuÄak: **63 mW za 400Ã—240 @ 30 fps je vrlo dobar rezultat**. Ovo je tipiÄno u rangu ultra-low-power AI kamera Äipova.

Cilj je stvoriti viÅ¡enamjenski kompjuter efikasan u vidu prostora i potroÅ¡nje resursa, skalabilan za velike neuronske mreÅ¾e i sinapse, dovoljno fleksibilan da odraÄ‘uje bihevioralne modele cortexa mozga

Takva raÄunala 2014. nisu postojalaa

Von Neumannova arhitektura je neefikasna i neskalabilna te ne moÅ¾e kvalitetno reprezentirati masivne, meÄ‘usobno povezane neuronske mreÅ¾e
Koristi se miks analognih i digitalnih neuromorfnih signala => imitacija neurobioloÅ¡kih procesa koriÅ¡tenjem:
- silicijskih neurona
- winner-take-all strujnih krugova 
- senzorskih strujnih krugova


Winner-take-all circuits by Gepetto

Apsolutno brate ğŸ’ªğŸ”¥ â€” ajmo to sad sloÅ¾it **jasno, saÅ¾eto i profesionalno**, ali da ti sjedne odmah u glavu kad ÄitaÅ¡.
Evo ti **natuknice o Winner-Take-All (WTA)** koje moÅ¾eÅ¡ doslovno ubacit i u rad ako Å¾eliÅ¡:

---

## ğŸ§  Winner-Take-All (WTA) circuits â€” natuknice

### ğŸ”¹ Osnovna ideja

* WTA (Winner-Take-All) krugovi su **neuromorfni elektroniÄki sustavi** koji oponaÅ¡aju **konkurenciju meÄ‘u neuronima** u mozgu.
* Cilj im je da **odaberu samo najaktivniji (najjaÄi) signal** meÄ‘u viÅ¡e ulaznih neurona ili kanala.
* Samo â€œpobjedniÄkiâ€ neuron ostaje aktivan â†’ ostali se **inhibiraju** (iskljuÄe).

---

### ğŸ”¹ BioloÅ¡ka inspiracija

* Temeljeni su na principu **lateralne inhibicije** u bioloÅ¡kim neuronskim mreÅ¾ama.
* U mozgu aktivni neuron **koÄi (inhibira)** susjedne neurone â†’ rezultat je **pojaÄan kontrast i selektivnost percepcije**.
* Ovaj mehanizam omoguÄ‡uje **fokus paÅ¾nje** i efikasnu obradu informacija (npr. u ljudskoj mreÅ¾nici).

---

### ğŸ”¹ Kako WTA krug radi

1. **Ulaz:** viÅ¡e analognih signala (npr. struja ili napon iz razliÄitih neurona/piksela).
2. **Natjecanje:** svi ulazi se natjeÄu u istom krugu.
3. **Inhibicija:** slabiji ulazi se potiskuju putem inhibicijskog feedbacka.
4. **Izlaz:** samo najjaÄi signal ostaje aktivan â†’ â€œwinner takes allâ€.

---

### ğŸ”¹ Implementacija u hardveru

* Realizira se koriÅ¡tenjem **MOS tranzistora** i **strujnih zrcala** (current mirrors).
* Krug se ponaÅ¡a poput â€œstrujnog trÅ¾iÅ¡taâ€ â€” ulaz s najveÄ‡om strujom **privuÄe sve resurse** i â€œpobijediâ€.
* TipiÄno se koristi u **neuromorfnim procesorima** (npr. Intel Loihi, IBM TrueNorth, DYNAP-SE).

---

### ğŸ”¹ Prednosti

* **Smanjuje redundanciju** â€” aktivan je samo najvaÅ¾niji neuron.
* **PoveÄ‡ava kontrast** i selektivnost u prepoznavanju uzoraka.
* **Å tedi energiju** jer se ne obraÄ‘uju svi ulazi.
* OmoguÄ‡uje **sparse coding** â€” mali broj neurona aktivan u danom trenutku.

---

### ğŸ”¹ Primjene

* **RaÄunalni vid (event-based senzori):** bira piksele s najveÄ‡om promjenom kontrasta.
* **Prepoznavanje uzoraka:** odabir najrelevantnijeg neurona u skupu.
* **Klasifikacija i clustering:** odreÄ‘uje koji neuron najbolje â€œpredstavljaâ€ ulazni uzorak.
* **Roboti i edge sustavi:** koristi se za brze odluke uz minimalnu potroÅ¡nju energije.

---

### ğŸ”¹ Ukratko

| Pojam                     | ObjaÅ¡njenje                                                         |
| ------------------------- | ------------------------------------------------------------------- |
| **Winner-Take-All (WTA)** | Sustav koji aktivira samo najjaÄi ulaz, ostale potiskuje            |
| **BioloÅ¡ki ekvivalent**   | Lateralna inhibicija meÄ‘u neuronima                                 |
| **KljuÄna funkcija**      | Odabir dominantnog signala i smanjenje redundancije                 |
| **Prednosti**             | UÄinkovitost, energetska Å¡tednja, bolja selektivnost                |
| **Upotreba**              | Neuromorfni Äipovi, senzori vida, robotski sustavi, AI akceleratori |

---



- Digitalno implementirani spiking neuroni su efikasniji od svih dosadaÅ¡njih dizajna
- omoguÄ‡avaju one-to-one correspondence izmeÄ‘u softvera i hardvera => ÄŒa znaÄi one-to-one?
Svaka funkcija softvera (npr. odreÄ‘eni algoritam, neuronski sloj, procesiranje piksela) ima direktno odgovarajuÄ‡i hardverski resurs koji ju izvrÅ¡ava.
Nema posrednog sloja ili generiÄkog procesora koji simulira funkciju â€” hardware je dizajniran toÄno za tu operaciju.

- stvoreni su event driven komunikacijski frameworkovi => komunikacija se deÅ¡ava samo kad se dogodi event
- na taj naÄin se emulira unutarnja povezanost unutar mozga

Colocated memory and computation + event driven communication nadilazi von Neumann bottleneck

Colocated memory and computation + event driven communication nadilazi von Neumann bottleneck

Von Neumann bottleneck

* KlasiÄna arhitektura raÄunala (CPU + RAM) ima **odvojen procesor i memoriju**.
* Podaci i instrukcije se stalno Å¡alju izmeÄ‘u memorije i CPU-a preko **jedne sabirnice**.
* **Problem:** sabirnica je usko grlo â†’ CPU Äesto Äeka podatke iz memorije â†’ sporije i manje energetski efikasno.
* To je tzv. **von Neumann bottleneck**.

Colocated memory and computation

* â€œColocatedâ€ znaÄi da **memorija i procesiranje stoje zajedno**, na istom Äipu ili blizu.
* Prednost: podatke **ne treba stalno pomjerati preko sabirnice** â†’ manje Äekanja, manja potroÅ¡nja energije.
* Primjer: **neuromorfni Äipovi**, gdje svaki â€œneuronski elementâ€ ima svoje â€œlocal memoryâ€ i logiku za izraÄun.


Event-driven communication

* Sustav **reagira samo kad se dogodi event** (npr. piksel se promijeni).
* Za razliku od stalnog pollanja, **samo se Å¡alju podaci koji su relevantni**.
* Prednost: joÅ¡ manja potroÅ¡nja i brÅ¾i prijenos informacija.


ZakljuÄak

* Kombinacija **lokalne memorije + event-driven komunikacije** znaÄi:

  * Nema stalnog Äekanja na podatke izmeÄ‘u procesora i memorije.
  * Podaci se Å¡alju **samo kad je potrebno**.
* Dakle, sustav **nadilazi von Neumann bottleneck** â†’ brÅ¾e, efikasnije, manje energije troÅ¡i, posebno kod neuromorfnih i edge AI sustava.

KljuÄna arhitektura => mreÅ¾a neurosinaptiÄkih jezgri koja moÅ¾e izgraditi velike spiking neural networke koji su efikasni, skalabilni i fleksibilni

Osnovna graÄ‘evna jedinica je "core" -> samostojeÄ‡a neuronska mreÅ¾a s 256 inputa (aksona) i 256 outputa (neurona) povezanih preko 256x256 usmjerenih, programabilnih sinaptiÄkih veza
Od viÅ¡e coreva mogu se graditi sloÅ¾enije mreÅ¾e pomoÄ‡u globalne, distribuirane on- and off-chip povezivosti
Svaki neuron na svakom coreu moÅ¾e se povezati s bilo koji aksonom na bilo kojem drugom coreu (jako dobra povezanost viÅ¡e neuronskih mreÅ¾a)

Aksionski branching je implementiran hijerarhijski u 2 stadija:

Najprije 1 konekcija putuje od starta (prvog corea) skoro do cilja (drugog corea), ali se po dolasku do aksona razdvaja u puno manjih konekcija koje prolaze joÅ¡ kratku udaljenost unutar samog corea

Neuroni se kreÄ‡u u stepsima od 1ms (orkestrirano pomoÄ‡u globalnog 1-kHz clocka)

Uz opisani globalni sinkronizacijski clock (koji osigurava 1-1 konekciju softvera i hardvera), coresi koriste i paralelni  i event driven naÄin rada
Osnovni napon upravlja potpuno asiknronom intercore komunikacijom i event-driven intracore komunikacijom. Taj napon radi po principu all-or-nothing spike evenata koji predstavljaju aktivaciju pojednih neurona

Efikasno zato jer se neuroni klasteriraju u klastere koji izvlaÄe svoje inpute iz sliÄnih poolova aksona (neuroni se grupiraju prema aksonima)
Samo spike eventi se Å¡alju komunikacijom izmeÄ‘u jezgri . Å to su eventi jaÄi, to se ÄeÅ¡Ä‡e Å¡alju

Ta je arhitektura skalabilna jer jezgre na Äipu, kao i sami Äipovi imaju moguÄ‡nsot slaganja u 2 dimenzije (sliÄno kao cortex sisavaca)
Svaki spike event  cilja toÄno odreÄ‘eni "pool" neuorna na ciljanoj jezgri i tako smanjuje broj long-range spike evenata koji predstavljaju kljuÄni bottleneck (event se ne Å¡alje svuda nego toÄno odreÄ‘enim neuronima koji ga trebaju primiti)
Fault tolerance -> povremene greÅ¡ke u core-u i na Äipovima ne oslabljuju rad cijelog sustava

Arhitektura je fleksibilna jer je svaki neuron individualno konfigurabilan i imitira prave neurone podrÅ¾avajuÄ‡i razne funkcije i bioloÅ¡ki relevantne spiking mehanike
Svaka sinapsa se moÅ¾e individualno "paliti i gasiti" i moÅ¾e joj se dodjeliti relativna snaga (sliÄno kao weighted metrike)
Svaka neuron-axon veza je programabilna s ukljuÄenim axonal delayom
Neuroni i sinapse mogu prikazivati programirano stohastiÄko (nasumiÄno, ali s predvidivim obrascem) ponaÅ¡anje korsteÄ‡i pseudo-random number generator (1 po jezgri)
Arhitektura podrÅ¾ava imitaciju psiholoÅ¡ke dinaimke i anatomske povezanosti.
Ima: feed-forward, reccurent i lateral veze

---

### **1ï¸. Feed-forward veze**

* Informacija ide **jednosmjerno od ulaza prema izlazu**.
* Nema povratnih veza â†’ signal ne vraÄ‡a se unatrag.
* TipiÄno u **klasiÄnim perceptronima i CNN-ovima**.
* Prednost: jednostavno, stabilno, brzo raÄunanje.
* Mana: ne moÅ¾e modelirati vremenske sekvence ili stanje memorije.

---

### **2ï¸. Recurrent veze**

* Informacija se **vraÄ‡a unatrag unutar mreÅ¾e** â†’ stvaraju **petlje**.
* OmoguÄ‡uju mreÅ¾i da **pamti prethodne ulaze** â†’ modeliranje sekvenci, npr. tekst, govor, vremenske serije.
* Primjeri: RNN, LSTM, GRU.
* Mana: teÅ¾e trenirati (problem â€œexploding/vanishing gradientsâ€).

---

### **3ï¸. Lateral veze**

* Veze **izmeÄ‘u neurona unutar istog sloja**.
* OmoguÄ‡uju **modulaciju aktivnosti susjednih neurona**, konkurenciju ili potporu.
* TipiÄno u **bioloÅ¡kim mreÅ¾ama** â†’ lateralna inhibicija pomaÅ¾e kod detekcije rubova, kontrasta, itd.
* U umjetnim mreÅ¾ama rjeÄ‘e, ali se koristi za **attention, normalizaciju ili interneuron modulaciju**.

---

Core ima individualno adressable aksone, konfigurabilni synaptic crossbar array i programabilne neurone

Core (u neuromorfnom Äipu)

Individualno addressable aksone

Svaki aksone (put kojim ide signal od neurona) moÅ¾e se posebno adresirati i kontrolirati.

ZnaÄi moÅ¾eÅ¡ poslati signal toÄno odreÄ‘enom neuronu ili grupi neurona, bez da utjeÄeÅ¡ na ostatak mreÅ¾e.

Konfigurabilni synaptic crossbar array

MreÅ¾a sinapsi (kao matrica) gdje moÅ¾eÅ¡ konfigurirati teÅ¾ine veze izmeÄ‘u neurona.

OmoguÄ‡uje da jedan neuron Å¡alje signal viÅ¡e neurona s razliÄitim jaÄinama â†’ kljuÄno za uÄenje i prilagodbu.

Programabilni neuroni

Neuroni Äipa se mogu programirati: npr. prag aktivacije, dinamiku spike-a, reakciju na inpute.

To omoguÄ‡uje simulaciju razliÄitih tipova bioloÅ¡kih neurona i razliÄitih algoritama unutar istog hardwarea.

Ukratko:

Aksone = kontrola kamo signal ide

Crossbar = kontrola koliko je signal jak izmeÄ‘u neurona

Programabilni neuroni = kontrola kako neuron reagira na signal

Unutar corea informacija teÄe od presinaptiÄkih aksona kroz aktivne sinapse u crossbaru kako bi stvarala inpute za sve povezane postsynaptic neurone

Aksioni se aktiviraju pomoÄ‡u input spike evenata koje generiraju neuroni bilo gdje u sustavu i Å¡alju se dalje nakon definiranog axonal delaya (od 1 do 15 vremenskih jedinica)
Mozak ima dedicated "Å¾icu" za svaku konekciju; Äip ima time-multiplexed Å¾ice koje povezuju 2-d mesh network rutera
Svaki ruter ima 5 portova (sjeverni, juÅ¾ni, istoÄni, zapadni i lokalni)
Ruteri su osnova 2-d mesh networka koji povezuje 64x64 array coresa

Kada neuron u coreu spike-a, u lokalnoj memoriji traÅ¾i axonal delay (4 bita) i adresu destinacije (8 bitova apsolutne adrese za target aksone i dvije 9-bitne relativne adrese koje predstavlaju core "skokove" u svakoj dimenziji ciljanog corea)
Te se informacije enkodiraju u paket koji se Å¡alje pomoÄ‡u mesha od corea do corea (prvo po x-u, pa po y-u) => takva je komunikacije deadlock free
Za implementaciju feedback veza u coreu, gdje se neuron spaja na akson isto corea, paket se dostavlja koristeÄ‡i lokalne kanale rutera (efikasno jer se ne napuÅ¡ta core)
Za skaliranje opisanog sustava (2-d mesh) u kojem je broj interchip konekcija ograniÄen, koristi se merge-split struktura na 4 ruba mesha da bi se postojeÄ‡i spikeovi serijalizirali, a izlazeÄ‡i deserijalizirali. Svakom spikeu se da labela njegovog reda (ako putuje istok-zapad) ili stupca (ako putuje sjever-jug) prije nego se spoje u shared link koji postoji na Äipu
TakoÄ‘er, spikeovi koji ulaze na Äip iz shared linka, razdvajaju se u odgovarajuÄ‡i redak ili stupac koristeÄ‡i info sa tagova

ObjaÅ¡njenje:

---

### 1ï¸.Osnovni tok informacija unutar corea

* **PresinaptiÄki aksone** Å¡alju spike dogaÄ‘aje kroz **aktivne sinapse u crossbar**.
* Crossbar distribuira signal prema **postsynaptiÄkim neuronima** unutar corea.
* **Input spike event** = signal od nekog neurona bilo gdje u sustavu.
* **Axonal delay** = vremensko kaÅ¡njenje prije nego spike stigne do target neurona (1â€“15 jedinica).

**Ukratko:** neuron spike-a â†’ signal ide kroz aksone i sinapse â†’ dolazi do drugih neurona, uz kaÅ¡njenje.

---

### 2ï¸.Razlika izmeÄ‘u mozga i Äipa

* **Mozak:** svaka veza ima svoju â€œÅ¾icuâ€ â†’ fiziÄki dedicated.
* **ÄŒip:** koristi **time-multiplexed Å¾ice** â†’ jedna fiziÄka veza prenosi spikeove od viÅ¡e neurona koristeÄ‡i redoslijed i vrijeme.
* Spikeovi putuju kroz **2-d mesh network**: mreÅ¾a rutera koji povezuju coreove u x i y dimenziji.

---

### 3ï¸.Ruter i 2-d mesh network

* Svaki ruter ima **5 portova**: sjever, jug, istok, zapad, lokalni (core unutar kojeg se nalazi).
* Spike ide kroz mesh tako da prvo ide **po x osi, pa po y osi** â†’ deadlock-free (nema zastoja u mreÅ¾i).
* MreÅ¾a povezuje **64Ã—64 corea**.

---

### 4ï¸.Paket spike-a

* Kada neuron spike-a:

  * TraÅ¾i se **axonal delay** (4 bita).
  * TraÅ¾i se **adresa destinacije** (8-bit apsolutna + 2Ã—9-bit relativne za target core).
  * Ove informacije se enkodiraju u **paket** i Å¡alju kroz mesh.

* **Feedback veze unutar corea** â†’ spike ostaje unutar corea, koristi lokalni kanal rutera â†’ efikasno.

---

### 5ï¸.Skaliranje i interchip komunikacija

* Problem: broj veza izmeÄ‘u Äipova je ograniÄen.

* RjeÅ¡enje: **merge-split struktura**:

  * Spikeovi se **serijaliziraju** prije slanja kroz shared link.
  * Na odrediÅ¡tu se **deserijaliziraju**.
  * Svakom spikeu se dodaje **labela reda (x)** ili **stupca (y)** â†’ omoguÄ‡uje pravilan routing.

* Spikeovi koji dolaze iz shared linka se **razdvajaju u odgovarajuÄ‡i redak/stupac** prema tagu.

---

###  Ukratko, Å¡to se dogaÄ‘a

1. Neuron spike-a â†’ lokalno traÅ¾i delay i adresu.
2. Spike se enkodira u paket â†’ ide kroz 2D mesh network rutera.
3. Ako je intra-core feedback â†’ koristi lokalni kanal, nema routing po meshu.
4. Ako ide na drugi Äip â†’ spikeovi se serijaliziraju, Å¡alju shared linkom, zatim deserializiraju i rasporede po target coreu.

**Cilj:**

* Efikasna, skalabilna, deadlock-free komunikacija izmeÄ‘u 64Ã—64 coreova + interchip povezanost.
* OmoguÄ‡uje **tisuÄ‡e paralelnih spike dogaÄ‘aja** da se prenesu brzo i precizno.

---

Implementacija: milijun spiking neurona i 256 milijuna sinapsi i 5.4 milijarde tranzistora na prostoru od 4.3 cm2
Ima 428 milijuna bitova on-chip memorije
Svaki core ima 104,448 bitova lokalne memorije za pohranu stanja sinapsi (65,536), stanja neurona i parametre (31,232), adrese destinacija (6656) i axonal delays (1024)
Energija: 20 mW po cm2, dok CPU troÅ¡i 50-100 W po cm2
Active power density je nizak zbog arhitekture
Passive power density je nizak zbog tranzistora s malim leakegom

4096 puta viÅ¡e coreva na 15 puta manje povrÅ¡ine, sa 100 puta manje potroÅ¡nje energije u odnosu na prethodna rjeÅ¡enja

OmoguÄ‡ava event driven asinkrono-sinkroni pristup => implementirano koristeÄ‡i: offline learning (CNN, liquid state machines, restricted Boltzman machines, hidden Markov models, support vector machines, optical flow i multimodal classification)
Offline learning metode

CNN (Convolutional Neural Network)

Ekstrahira prostorne znaÄajke iz slika/video koristeÄ‡i konvolucijske filtere.

Liquid State Machines (LSM)

Vrsta recurrent spiking neural network; pamti kratkoroÄne temporalne obrasce â†’ dobro za vremenske serije i neuromorfne spike podatke.

Restricted Boltzmann Machines (RBM)

ProbabilistiÄki model za uÄenje distribucija i reprezentacija podataka; Äesto se koristi za feature extraction i pretreniravanje dubljih mreÅ¾a.

Hidden Markov Models (HMM)

Model sekvencijalnih podataka gdje stanja nisu direktno vidljiva, ali generiraju opaÅ¾ene dogaÄ‘aje â†’ koristi se za govor, signale i vremenske serije.

Support Vector Machines (SVM)

Supervised learning metoda koja pronalazi optimalnu granicu izmeÄ‘u klasa u feature prostoru.

Optical Flow

Tehnika za praÄ‡enje kretanja objekata u video sekvencama prema promjeni intenziteta piksela kroz vrijeme.

Multimodal Classification

Kombinacija viÅ¡e tipova podataka (npr. video + audio + senzori) za preciznu klasifikaciju.
ÄŒip vrti te iste algoritme bez da ih treba modificirati

Za dodatno testiranje, razvijena je i dodatna multiobject detekcija i klasifikacija s fiksnom kamerom
Zadaci: detekcija ljudi, auti, i ostalih vozila na slikama gdje se pojavljuju rijetko s ciljem minimizacije false detekcija (sustav spikea samo kad se neÅ¡to stvarno pojavi; ne troÅ¡i eneriju bezveze)
Radi na 400x240 piksela. ÄŒip je troÅ¡io 63 mW na 30-fps videu u 3 boje koji je zatim bio skaliran na 1920x1080. Bilo je potrebno konvertirati piksele u spike evente jer je video bio snimljen standarndom kamerom
dobre performanse

MoguÄ‡e koristiti i spike-based retinal cameru
Implementirana je vizualna "mapa" orijentacijsko selektivnih filtera inspiriranih ranim procesiranjem u coretexu sisavaca koji se Äesto koristi u CV za feature extraction

Svih milijun neurona dobilo je feedforward inpute s orientation biasima iz vizualnog prostora skupa s rekurzivnim konekcijama meÄ‘u bliskim featuresima

Standardni benchmark u arhitekturi raÄunala je: energy per operation
U domeni konfigurabilnih neuralnih arhitektura, osnovna operacija je "sinaptiÄki event" koji predstavlja source neuron koji Å¡alje spike event target neuronu putem posebne (non-zero) sinapse
SinaptiÄki eventi su atomiÄne jedinice mjerenja jer se koliÄina raÄunanja, memorija, komunikacija, snaga, povrÅ¡ina i brzina proporcionalno poveÄ‡avaju s brojem sinapsi

KoristeÄ‡i rekurzivno poveane mreÅ¾e, izmjeren je total power i energy per synaptic event
Power consumption  je funkcija spike rate-a, prosjeÄne udaljenosti koju spikeovi prolaze i prosjeÄnog broja aktivnih sinapsi po neuronu (synaptic density)

Ako je "fire" u prosjeku 20 hz uz 128 aktivnih sinapsi, ukupna izmjerena snaga iznosila je 72mW (na naponu od 0.775 V), Å¡to odgovara 26pj po sinaptiÄkom eventu

U usporedbi s standarnim raÄunalom, troÅ¡i se 176000 x manje energije po eventu
OmoguÄ‡ava se individualno programiranje neurona i njihovih konekcijama
SPOS -> sinaptiÄke operacije po sekundi u ovom sustavu
Standardna superraÄunala -> FLOPS (floating point operations per second)

Slaganjem viÅ¡e TrueNorth brainchipova, mogu nastati superraÄunala sa stotinama tisuÄ‡a jezgri, stotinama milijuna neurona i stotinama milijardi sinapsi

Arhitektura -> slika -> svaki node je spojen sa svakim (node = core, edge = neural connection)

#####################################################################################################
- NaÅ¡a san video SNN in 5 minutes...pa zaÅ¡ ne hitit oko
- Mozak jako efikasno procesira informacije
- SNNovi su novi tip AI inspiriran komunikacijom mozga
- ObiÄne neuronske mreÅ¾e baziraju se na kontinuiranim signalima, SNNovi koriste spikeove kao mozak
- Spikes => diskretni eventi koji se javljaju kroz vrijeme
- RealitiÄniji i efikasniji za obradu temporalnih informacija (informacije koji nisu statiÄne, nego imaju vremensku "dimenziju"...videa, signali, Å¾ivÄani signali, eventi za event kamere i sl.)
- Real time procesiranje, event based vision, robotika, autonomna vozila

Komponente SNN-ova:
- meÄ‘usobno povezani neuroni
- svaki neuron prima input od drugih
- inputi su elektriÄni impulsi koje zovemo "spikes"

- Kad neuron primi dovoljno spikeova u kratkom periodu, "fire-a" svoj spike
- Tako neuroni komuniciraju
- Timing spikeova je kljuÄan => enkodira informacije o inputu
- ÄŒa je jaÄi input, jaÄi je i spike
- Sinapse - veze izmeÄ‘u neurona
- Synaptic plasticity - sposobnost da sinapsa jaÄa ili slabi kroz vrijeme => tako se SNN-ovi adaptiraju i uÄe kroz vrijeme
- Primjer: speÄemo se na peÄ‡, pain receptori poÅ¡alju spikeove mozgu, to pojaÄava vezu meÄ‘u neuronima zaduÅ¾enim za toÄno taj proces (osjet boli zbog vruÄ‡e peÄ‡i), iduÄ‡i put kad smo blizu vruÄ‡eg objekta, mozak Ä‡e brÅ¾e prepoznati opasnost i brÅ¾e Ä‡emo reagirati => synaptic plasticity IRL - "neurons that fire together, wire together"

Encoding information => kako pretvorit real-world data u spike patterne?
- Pretvorba naÅ¡eg jezika u jezik neurona



- Rate coding -> frequency spikeova predstavlja intenzitet inputa => Äa je input jaÄi, to ima viÅ¡e spikeova...tipa...video koji prikazuje high-speed let drona stvara viÅ¡e spikeova nego video bijelega zida na kojemu se niÅ¡ ne deÅ¡ava

- NajklasiÄniji i najÄeÅ¡Ä‡e koriÅ¡ten model.

- Frekvencija spikeova = intenzitet podraÅ¾aja.

- Tvoj primjer s dronom je savrÅ¡en â€” ako kamera â€œvidiâ€ puno promjena â†’ neuroni Ä‡e ispucavati puno spikeova. Ako je scena statiÄna (bijeli zid), spikeova gotovo da nema.
ğŸ‘‰ OgraniÄenje: sporije reagira jer se Äeka da se skupi odreÄ‘eni broj spikeova da bi se dobila jasna slika intenziteta.

- Temporal coding -> koristi se precizni timing spikeova za prijenos informacija. ToÄno vrijeme kad se spike dogodi moÅ¾e biti kljuÄno; posebno za taskove gdje je bitno vrijeme i praÄ‡enje sekvenci

- Tu je vaÅ¾an toÄan trenutak kad spike doÄ‘e.

- ÄŒak i ako je broj spikeova isti, razliÄit raspored u vremenu moÅ¾e nositi razliÄite informacije.

- Super za event-based senzore i zadatke gdje redoslijed i precizno vrijeme imaju smisla (npr. prepoznavanje govora, ritma, ili toÄno kada je objekt uÅ¡ao u vidno polje).
ğŸ‘‰ Prednost: moÅ¾e biti ekstremno energetski efikasno, jer mali broj spikeova moÅ¾e nositi puno info.

- Population coding -> koristi se grupa neurona da predstavlja 1 input. Svaki neuron u populaciji predstavlja specifiÄni feature inputa. Potpuni pattern aktivnosti kroz populaciju predstavlja potpunu informaciju; npr. razliÄiti neuroni mogu "fire-ati" za razliÄite boje unutar slike

- Radi se o skupinama neurona â€” svaki neuron se â€œpaliâ€ za odreÄ‘eni feature (npr. specifiÄnu boju, kut linije, smjer kretanja).

- Informacija se dobiva iz kolektivnog uzorka aktivnosti svih neurona.

- Primjer: u vidnom korteksu mozga razliÄiti neuroni su specijalizirani za razliÄite orijentacije linija â†’ cijela populacija ti daje kompletnu reprezentaciju slike.
ğŸ‘‰ Ovo je â€œrobustnijeâ€ jer se informacija ne oslanja na jedan neuron nego na distribuciju aktivnosti kroz cijelu populaciju.

- Neuron model
- LIFT model => matematiÄki model toga kako neuroni procesiraju spikeove
- Kanta s vodom => neuron
- Kapljice vode => nadolazeÄ‡i spikeovi
- Svaki spike dodaje malo vode u kantu/napona u neuron

- Kanta ima malu Å¡kulju koja uzorkuje da sporo gubi vodu kroz vrijeme => to predstavlja slabljenje napona u neuronu s prolaskom vremena (ono kad na kameri event izblijedi)
- Ako se kanta napuni i prelije, to je ekvivalentno temu kad neuron dobije dovoljno napona da postigne spike i resetira se  da bi mogao obraÄ‘ivati novu rundu inputa => neuron fireing

- Moremo prilagoÄ‘avat koliko se voda gubi i potrebnu koliÄinu vode da se kanta napuni (dakle; tunable parametri su threshold za spike i vrijeme slabljenja eventa)

- Za slaganje SNN-ova => neuroni + sinapse + definiranje kako sinapse uÄe + layeri neurona + broj neurona u layeru

RATE VS TEMPORAL: 
https://github.com/AntonioLabinjan/Simulation-of-rate-and-temporal-coding/tree/master




Opportunities for neuromorphic computing algorithms and applications

Catherine D. Schuman & co.

Tehnologije neuromorfnog computinga bit Ä‡e vaÅ¾ne u buduÄ‡nosti. Puno rada posveÄ‡eno je hardverskom djelu
Pregled nedavnih neuromorfnih algoritama i njihovih primjena

BliÅ¾i se kraj Moorovog zakona i Dennardovog scalinga. TraÅ¾e se nove tehnologije za nastavak napredovanja performansi.

Chatgpt explained:
---

### ğŸ’¡ **Moorov zakon (Mooreâ€™s Law)**

**Definicija:**
Gordon Moore (suosnivaÄ Intela) 1965. je primijetio da se **broj tranzistora na integriranom krugu otprilike udvostruÄuje svake dvije godine**, dok se **cijena po tranzistoru smanjuje**.

**Å to to znaÄi:**

* ViÅ¡e tranzistora = **veÄ‡a raÄunalna snaga**
* Manji tranzistori = **manja potroÅ¡nja energije i niÅ¾i troÅ¡kovi**
* Dakle, raÄunala postaju **brÅ¾a, manja i jeftinija** svake 1â€“2 godine

**Primjer:**
Procesor iz 2000. imao je moÅ¾da 30 milijuna tranzistora.
Danas ih high-end Äip ima **preko 100 milijardi!**

**Aliâ€¦**
Danas smo doÅ¡li do **fiziÄkih granica minijaturizacije** â€” tranzistori su veÄ‡ veliÄine par **nanometara** (manji od virusa!), pa se dalje teÅ¡ko ide klasiÄnim litografskim metodama.

---

### âš™ï¸ **Dennardov scaling (Dennard scaling)**

**Definicija:**
Robert Dennard (IBM) 1974. rekao je da kad se tranzistori smanjuju,
**napon i struja se proporcionalno smanjuju**, tako da **snaga po povrÅ¡ini ostaje konstantna**.

**Drugim rijeÄima:**
Ako smanjiÅ¡ tranzistor 2x u svemu â€” visinu, Å¡irinu, napon â€”
on troÅ¡i **isto energije po kvadratnom milimetru**, ali ima **dvostruko viÅ¡e tranzistora** â†’ performanse rastu bez poveÄ‡anja potroÅ¡nje energije ili topline.

**To je omoguÄ‡ilo:**
ğŸ‘‰ ViÅ¡e tranzistora + veÄ‡a brzina + ista potroÅ¡nja = eksplozija performansi od 80-ih do ranih 2000-ih.

**Aliâ€¦**
Oko **2005. scaling se raspao.**

* Naponi viÅ¡e ne mogu padati proporcionalno (fiziÄke granice â€” â€œleakage currentâ€, tuneliranje elektrona kroz tanke gate-oxide slojeve).
* Snaga i temperatura su poÄele **drastiÄno rasti**.
  â¡ï¸ Zbog toga su frekvencije CPU-a stale oko 3â€“4 GHz i pojavila se era **viÅ¡ejezgrenih procesora** i **energetske optimizacije**.

---

### ğŸ§  Ukratko:

| Zakon                 | Ideja                                                 | Å to je omoguÄ‡io                  | ZaÅ¡to viÅ¡e ne vrijedi                      |
| --------------------- | ----------------------------------------------------- | -------------------------------- | ------------------------------------------ |
| **Moorov zakon**      | Broj tranzistora se udvostruÄuje svake 2 god.         | Eksponencijalni rast performansi | FiziÄke granice minijaturizacije           |
| **Dennardov scaling** | Manji tranzistori troÅ¡e proporcionalno manje energije | ViÅ¡e brzine bez viÅ¡e topline     | Gubitak proporcionalnosti, previÅ¡e topline |

---

ğŸ’¥ **Å to sad?**
Kako se pribliÅ¾avamo kraju oba zakona, istraÅ¾uju se nove paradigme:

* **3D Äipovi** (vertikalno slaganje tranzistora)
* **Neuromorfni Äipovi** (poput IBM TrueNorth, Intel Loihi)
* **Kvantno raÄunarstvo**
* **OptiÄki procesori**
* **Spintronika i memristori**

---

Neuromorfna raÄunala su jedna od tih novih tehnologija
Pojam "neuromorphic" je osmislio Carver Mead kasnih '80-ih
Odnosio se na: miks analogno-digitalnih implementacija raÄunarstva inspiriranog mozgom
Sada ipak obuhvaÄ‡a veÄ‡i raspon raznovrsnih hardverskih implementacija

Neuromorfna raÄunala - non-von Neumann raÄunala Äija struktura i funkcionalnosti su inspirirane mozgom i sastoje se od neurona i sinapsi
Von Neumann raÄunala sastoje se od odvojenih jedinica za CPU i memoriju gdje se posebno pohranjuju podaci i instrukcije
U neuromorphic raÄunalima i procesiranjem i memorijom upravljaju neuroni i sinapse
Programi u neuromorphic raÄunalima definirani su strukturom neural networka i njihovih parametara, a ne eksplicitnim instrukcijama kao Å¡to je sluÄaj kod von Neumann raÄunala
Von Neumann raÄunala enkodiraju informacije kao numeriÄke vrijednosti u binarnom sustavu, a neuromorphic raÄunala primaju spikeove kao input
Koristi se vrijeme pojave spikea, intenzitet i oblik za enkodiranje numeriÄkih informacija
Binarne vrijednosti mogu se pretvoriti u spikeove i obratno

Neuromorfna raÄunala se u velikoj mjeri koriste paralelizmom gdje se izraÄuni obavljaju koriÅ¡tenjem viÅ¡e neurona i sinapsi istovremeno
No, izraÄuni koje neuroni i sinapse rade su relativno jednostavni u usporedbi s von Neumann sistemima
Collocated processing and memory (procesi i memorija su na istom mjestu). Iako se nekad neuroni smatraju processing unitima, a sinapse memorijom, u veÄ‡ini implementacija i neuroni i sinapse predstavljaju i memoriju i procese
PomaÅ¾e izbjeÄ‡i von Neumann bottleneck (odvojenost procesora i memorije uzrokuje usporavanje u maksimalnom moguÄ‡em throughputu)
PomaÅ¾e izbjeÄ‡i pristup podacima iz glavne memorije Å¡to inaÄe troÅ¡i puno energije

KljuÄne znaÄajke neuromorfnih raÄunala:

1. Inherentna skalabilnost

Neuromorfna raÄunala su prirodno skalabilna â€“ dodavanjem novih Äipova poveÄ‡ava se broj neurona i sinapsi koje sustav moÅ¾e realizirati.

ViÅ¡e fiziÄkih neuromorfnih Äipova moÅ¾e se povezati u jedan veliki sustav za izvoÄ‘enje veÄ‡ih mreÅ¾a.

To je veÄ‡ uspjeÅ¡no ostvareno kod sustava kao Å¡to su SpiNNaker i Intel Loihi.

2. RaÄunanje temeljeno na dogaÄ‘ajima (event-driven computation)

Sustav obraÄ‘uje samo kada postoje podaci â†’ ogromna energetska uÄinkovitost.

Neuroni i sinapse rade samo kada ima spikeova (impulsa) za obraditi.

Aktivnost mreÅ¾e je vremenski rijetka (temporalno rijetka), Å¡to dodatno Å¡tedi resurse.

3. StohastiÄnost (sluÄajnost)

Neuromorfni sustavi mogu ukljuÄivati elemente nasumiÄnosti u ponaÅ¡anju neurona (npr. u njihovom okidanju).

Ova â€œÅ¡umovitostâ€ (noise) moÅ¾e biti korisna â€“ omoguÄ‡uje robustnije i prirodnije ponaÅ¡anje sustava, sliÄno bioloÅ¡kom mozgu.

Neuromorfna raÄunala troÅ¡e ektremno malo energije => event driven & parallel => u bilo kojoj vremenskoj toÄki, samo mali dio sustava je aktivan, a ostatak je "idle"
Implementiraju "neural-network style" raÄunanja => prirodna platforma za rad s brojnim primjenama machine learninga i AI
Trenutno se iz mozga najviÅ¡e koriste neuroni i sinapse, ali joÅ¡ se istraÅ¾uje mogu li se joÅ¡ neki koncepti mozga koristiti
Tehnologije su silicon-based, ali istraÅ¾uju se novi materijali popur phase-change, ferroelectric, non-filamentary topological insulatora ili chanell-doped biomembrana
Razni neuromorfni ureÄ‘aji imaju razne ciljeve i pristupe koriÅ¡tenja tehnologije


---

### ğŸ§  **SaÅ¾etak â€“ Trenutno stanje i smjer razvoja neuromorfnih raÄunala**

**1. Neuromorfni hardver veÄ‡ postoji i razvija se brzo**

* Za razliku od nekih drugih buduÄ‡ih tehnologija, **neuromorfni Äipovi veÄ‡ postoje** i **dostupni su istraÅ¾ivaÄima**.
* ViÅ¡e **velikih sustava** razvijeno je s razliÄitim pristupima i ciljevima.

---

**2. Glavni postojeÄ‡i sustavi i projekti**

* **EU Human Brain Project** â†’ razvio **SpiNNaker** i **BrainScaleS** za velike neuronske simulacije.
* **ODIN** â€“ digitalni spiking neuromorfni procesor s podrÅ¡kom za sloÅ¾enije neuronske modele.
* **Tianjic chip** â€“ kombinira **neuromorfne SNN-ove** i **klasiÄne umjetne neuronske mreÅ¾e (ANN)** â†’ omoguÄ‡uje Å¡iru primjenu.
* Industrijski primjeri: **IBM TrueNorth**, **Intel Loihi**
* Akademski projekti: **DYNAPs**, **Neurogrid**, **IFAT**, **BrainScaleS-2**
* **BrainScaleS-2** dokazano ubrzava â€œlearning-to-learnâ€ procese â€” **uÄi mnogo brÅ¾e od bioloÅ¡kih mreÅ¾a**.

---

**3. Tehnologije i materijali za implementaciju**

* Svi ovi sustavi su trenutno **temeljeni na siliciju** (klasiÄna CMOS tehnologija).
* IstraÅ¾uju se **nove vrste materijala**, poput:

  * **Phase-change**, **feroelektriÄni** materijali
  * **TopoloÅ¡ki izolatori**
  * **Biomembrane s dopiranim kanalima**
* **Memristori** su posebno popularni â€“ omoguÄ‡uju **spajanje memorije i obrade** (â€œcollocated processing and memoryâ€), Äime se **smanjuje kaÅ¡njenje i potroÅ¡nja energije**.
* Koriste se i **optoelektroniÄki ureÄ‘aji** za joÅ¡ brÅ¾u i energetski efikasniju obradu.

---

**4. Raznolikost ureÄ‘aja = prilagodljivost**

* Svaki materijal i ureÄ‘aj ima **vlastite karakteristike** (brzina, potroÅ¡nja energije, bioloÅ¡ka sliÄnost).
* Ta raznolikost omoguÄ‡uje da se **neuromorfni hardver prilagodi specifiÄnim aplikacijama**.

---

**5. Povezanost s algoritmima i aplikacijama**

* Trenutno se veÄ‡ina istraÅ¾ivanja fokusira na **hardver**, ali pravi napredak zahtijeva **spajanje s algoritmima i primjenama**.
* Da bi se iskoristile sve prednosti neuromorfnog raÄunanja, potrebno je razviti **neuromorfne algoritme** koji u potpunosti koriste potencijal te arhitekture.

---

**6. Definicija koriÅ¡tena u radu**

* Ovaj rad pod pojmom **â€œneuromorfno raÄunanjeâ€** obuhvaÄ‡a sve vrste implementacija:

  * **digitalne**,
  * **mjeÅ¡ovite analogno-digitalne**,
  * **analogne** sustave,
    ali se **posebno fokusira na one koji koriste spikeove** â€” tj. **spiking neuromorphic computers (SNN)**.

---

Programiranje neuromorfnih raÄunala Äesto ukljuÄuje kreiranje spiking neural networka koji se mogu deployati na neuromorfno raÄunalo

---

### âš¡ **KljuÄne znaÄajke Spiking Neural Networks (SNN-ova):**

**1. BioloÅ¡ka inspiracija s dodatnom dimenzijom vremena**

* SNN-ovi su **najbioloÅ¡kiji oblik umjetnih neuronskih mreÅ¾a**.
* Za razliku od klasiÄnih ANN-ova, **ukljuÄuju pojam vremena** u izraÄune.
* Neuroni i sinapse imaju **vremenske konstante i kaÅ¡njenja (delaye)**.

  * Npr. neuron **â€œcuriâ€ (leak)** naboj kroz vrijeme dok ne dosegne prag i ispali â€œspikeâ€.

---

**2. Modeli neurona u SNN-ovima**

* Mogu biti **jednostavni** (npr. *Integrate-and-Fire*) â€“ akumuliraju naboj do praga.
* Ili **sloÅ¾eni i bioloÅ¡ki vjerniji**, poput *Hodgkinâ€“Huxley modela* koji modelira ionske kanale u stvarnim neuronima.
* Dakle, razina bioloÅ¡ke toÄnosti ovisi o potrebama i sloÅ¾enosti sustava.

---

**3. Dvije glavne skupine algoritama u neuromorfnom raÄunanju:**
1ï¸âƒ£ **Algoritmi za uÄenje/trening SNN-a** â€“ optimiziraju mreÅ¾u da bi se koristila na neuromorfnom Äipu (uÄeni pristup).
2ï¸âƒ£ **RuÄno konstruirani SNN-ovi** â€“ dizajnirani bez strojnog uÄenja, veÄ‡ **ruÄno prilagoÄ‘eni za odreÄ‘eni zadatak** (heuristiÄki pristup).

---

**4. SuÅ¡tinska razlika od tradicionalnih ANN-ova:**

* ANN-ovi â†’ rade s **kontinuiranim vrijednostima** i *bez pojma vremena*.
* SNN-ovi â†’ **obraÄ‘uju impulse (spikeove)** koji se dogaÄ‘aju u **vremenu**.
  â¡ï¸ Time bolje **imitiraju naÄin na koji mozak obraÄ‘uje informacije**.

---


---

## âš¡ **Detaljan saÅ¾etak: Funkcioniranje Spiking Neural Networks (SNN)**

---

### ğŸ§© **1. Neuroni u SNN-u**

* **Akumulacija naboja:**

  * Neuroni **skupljaju elektriÄni naboj** tijekom vremena.
  * Naboj dolazi iz:

    * **okoline** â†’ vanjski ulazni podaci, senzori itd.
    * **unutarnjih komunikacija** â†’ spikeovi iz drugih neurona.

* **Prag (threshold):**

  * Svaki neuron ima **definiranu prag-vrijednost**.
  * Kad se akumulirani naboj **dosegne ili premaÅ¡i prag**, neuron **ispali spike** (signal).
  * Spike se Å¡alje **svim izlaznim sinapsama** tog neurona.

* **Leak (curenje naboja):**

  * Ako neuron ne dosegne prag, dio naboja **postupno nestaje kroz vrijeme**.
  * Ova **vremenska degradacija naboja** modelira ponaÅ¡anje stvarnih bioloÅ¡kih neurona.

* **Axonal delay (aksonska odgoda):**

  * Kad neuron ispali spike, signal moÅ¾e biti **odgoÄ‘en** prije nego Å¡to stigne do sinapsi.
  * Ova odgoda simulira **vremensko kaÅ¡njenje u prijenosu impulsa** kroz akson.

---

### ğŸ”— **2. Sinapse u SNN-u**

* **Povezuju neurone:**

  * Svaka sinapsa ima **pre-sinaptiÄki** (izvorni) i **post-sinaptiÄki** (ciljni) neuron.

* **TeÅ¾ina (weight):**

  * Sinapse imaju **numeriÄku teÅ¾inu** koja odreÄ‘uje snagu veze.
  * TeÅ¾ine mogu biti:

    * **pozitivne** â†’ *poticajne (excitatory)*, pojaÄavaju aktivnost
    * **negativne** â†’ *inhibitorne*, smanjuju aktivnost

* **SinaptiÄka odgoda (delay):**

  * Signal iz pre-sinaptiÄkog neurona moÅ¾e imati **kaÅ¡njenje prije nego stigne do post-sinaptiÄkog**.
  * To doprinosi **asinkronom vremenskom ponaÅ¡anju** mreÅ¾e.

* **UÄenje kroz promjenu teÅ¾ina:**

  * Sinapse **mijenjaju svoje teÅ¾ine** ovisno o aktivnosti mreÅ¾e.
  * To omoguÄ‡uje **uÄenje tijekom vremena** (npr. kroz mehanizme poput STDP â€“ Spike-Timing Dependent Plasticity).

* **Rekonfigurabilnost:**

  * Neuromorfni Äipovi omoguÄ‡uju **paljenje/gaÅ¡enje sinapsi** unutar fiziÄke mreÅ¾e, Äime se dinamiÄki definira struktura mreÅ¾e.

* **Programabilni parametri:**

  * U modernim neuromorfnim arhitekturama moguÄ‡e je podeÅ¡avati:

    * **threshold neurona**
    * **teÅ¾ine sinapsi**
    * **aksonske i sinaptiÄke odgode**
  * Time se omoguÄ‡uje **potpuna fleksibilnost** mreÅ¾nih parametara.

---

### ğŸ§  **3. Asinkroni prijenos informacija**

* **Razlika u odnosu na klasiÄne ANN-ove:**

  * U klasiÄnim ANN-ovima â†’ informacije se **sinkrono prenose sloj po sloj**.
  * U SNN-ovima â†’ zbog vremenskih odgoda i razlika u kaÅ¡njenju, **informacije se Å¡ire asinkrono** â€“ svaki spike moÅ¾e stiÄ‡i u drugo vrijeme.

* **Posljedica:**

  * Svaki neuron moÅ¾e reagirati **u razliÄitim trenucima**, ovisno o tome **kad mu spikeovi stignu**.
  * MreÅ¾a tako radi u **realnom vremenu** i ima **vremensku dinamiku** sliÄnu mozgu.

* **Prednost za neuromorfni hardver:**

  * Ova asinkronost **savrÅ¡eno odgovara** neuromorfnim Äipovima koji rade u **event-driven reÅ¾imu** â€“ obraÄ‘uju samo kada spike stigne.
  * Time se **Å¡tedi energija** i omoguÄ‡uje **visoka paralelizacija**.

---

### â±ï¸ **4. Vremenska domena rada mreÅ¾e**

* Aktivnost mreÅ¾e se moÅ¾e promatrati **po vremenskim koracima (t, t+1, t+2, â€¦)**.
* U svakom vremenskom trenutku mijenja se:

  * koji neuroni su â€œispaliliâ€ spike,
  * koliko naboja su drugi neuroni akumulirali,
  * koje sinapse su aktivne i kada njihovi signali dolaze.
* Dakle, mreÅ¾a ima **dinamiÄno stanje koje se evolucijski mijenja kroz vrijeme**.

---

### ğŸ“Š **5. Ukratko â€“ kljuÄni koncepti**

| Element            | Funkcija                     | KljuÄne karakteristike                                  |
| ------------------ | ---------------------------- | ------------------------------------------------------- |
| **Neuron**         | Akumulira i ispuÅ¡ta naboj    | Prag, curenje, aksonska odgoda                          |
| **Sinapsa**        | Povezuje neurone             | TeÅ¾ina (pozitivna/negativna), sinaptiÄka odgoda, uÄenje |
| **Signal (spike)** | Diskretni impuls             | Prenosi informaciju u vremenu                           |
| **Obrada**         | Asinkrona, dogaÄ‘ajima voÄ‘ena | Energetski uÄinkovita, vremenski osjetljiva             |

---
DNN = umjetna neuronska mreÅ¾a s viÅ¡e slojeva koja uÄi iz velike koliÄine podataka pomoÄ‡u backpropagationa i gradijentnog spuÅ¡tanja.
---

## ğŸ”¹ 1. Problem s klasiÄnim treniranjem SNN-ova

* **Backpropagation i SGD (stochastic gradient descent)** su jako uspjeÅ¡ni u deep learningu,
  ali **ne mogu se direktno primijeniti na SNN-ove** jer:

  * Spiking neuroni imaju **nediferencijabilne aktivacijske funkcije** (threshold funkcije).
  * SNN-ovi obraÄ‘uju **vremenske informacije**, Å¡to dodatno komplicira uÄenje.
* Potrebne su **prilagodbe** (npr. surrogate gradients, smoothed activation functions),
  ali to Äesto **smanjuje toÄnost** u odnosu na klasiÄne ANN-ove.

---

## ğŸ”¹ 2. Mapiranje klasiÄnih DNN-ova na SNN-ove

* Umjesto treniranja SNN-a od nule, Äesto se:

  1. **Trenira DNN**,
  2. **Zatim se mapira (pretvori)** u SNN za **inference**.
* Ove metode daju:

  * Blizu **state-of-the-art toÄnost**
  * Uz **veliko smanjenje potroÅ¡nje energije** (jer SNN obraÄ‘uje samo spikeove).
* Dataseti koriÅ¡teni: **MNIST, CIFAR-10, ImageNet**.
* KljuÄne tehnike:

  * Normalizacija teÅ¾ina i aktivacija
  * Zamjena max-poolinga s average poolingom
  * "Few Spikes" neuron model (FS-neuron) â€” sloÅ¾ene aktivacije predstavljene s 1â€“2 spikea.
* Primjene: **keyword spotting, medicinska analiza, detekcija objekata** (na Loihi, TrueNorth).
* Problem: **mapiranje moÅ¾e smanjiti toÄnost** zbog:

  * razlike DNN â†” SNN
  * hardverskih ograniÄenja (npr. **memristori** imaju niÅ¾u preciznost teÅ¾ina i varijacije po ciklusu).

---

## ğŸ”¹ 3. Reservoir computing (Liquid State Machines)

* Ne zahtijeva klasiÄno treniranje SNN-a.
* Sastoji se od:

  * **"tekuÄ‡eg" (liquid) dijela** â€“ nasumiÄna mreÅ¾a spike neurona (recurrent, sparse)
  * **readout sloja** â€“ trenira se (npr. linearnom regresijom)
* Dvije kljuÄne osobine:

  * **Input separability** â€“ razliÄiti ulazi daju razliÄite izlaze
  * **Fading memory** â€“ stari signali nestaju s vremenom
* Prednosti:

  * Nema treniranja samog SNN-a
  * Dobro radi s vremenskim podacima
* Primjene:

  * obrada **bio-signala**, **prosthetic control**, **audio/video analiza**
  * koristi **hijerarhijske slojeve** tekuÄ‡ih mreÅ¾a

---

## ğŸ”¹ 4. Evolucijski pristupi

* Koriste **evolucijske algoritme** (mutacija, selekcija, reprodukcija) za:

  * Optimizaciju **parametara** (thresholds, delays)
  * Dizajn **strukture mreÅ¾e** (koliko neurona, kako su povezani)
* Prednosti:

  * Ne zahtijevaju diferencijabilnost
  * Mogu raditi s bilo kojom topologijom mreÅ¾e
* Nedostatak:

  * **Sporo konvergiraju**
* Primjene:

  * **Kontrola robota**, **video igre**, **autonomna navigacija**

---

## ğŸ”¹ 5. PlastiÄnost (bioloÅ¡ki inspirirano uÄenje)

* Temelji se na **aktivnosti neurona i promjenama sinaptiÄke jaÄine**.
* Najpoznatije: **STDP (Spike-Timing-Dependent Plasticity)**

  * TeÅ¾ine se mijenjaju prema vremenskom odnosu pre- i post-sinaptiÄkih spikeova.
* KoriÅ¡teno na: **MNIST, CIFAR-10, ImageNet**
* Prednosti:

  * MoÅ¾e **pribliÅ¾iti klasiÄne ML metode** (klasteriranje, Bayes inference)
  * Kombinira se s **reservoir computingom** (npr. NeuCube)
* Primjene:

  * **EEG analiza**, **detekcija stanja spavanja**, **prostetiÄke kontrole**
* Varijante:

  * **Rekurentne SNN mreÅ¾e s kaÅ¡njenjima i plastiÄnoÅ¡Ä‡u**
  * **Polychronization networks** â€“ klasifikacija vremensko-prostorno varijabilnih uzoraka
  * **Winner-take-all** modeli
  * UÄenje **tajminga spikeova** (precizna klasifikacija prema vremenu)

---

## ğŸ”¹ 6. Nemachine learning algoritmi

* Neuromorfni hardver moÅ¾e rjeÅ¡avati **ne-ML probleme**:

  * **Graf algoritmi** (npr. shortest path)
  * **Random walks** i **Markov chains**
  * **NP-kompletni problemi** (SAT, QUBO, graph partitioning)
* Primjeri:

  * **IBM TrueNorth**, **Intel Loihi**, **SpiNNaker** rjeÅ¡avaju NP probleme
  * Neuromorfni pristupi ponekad **precizniji od D-Wave kvantnog raÄunala!**
* Prednosti:

  * Paralelna, niskoenergetska obrada
  * OdliÄna primjena u **grafovima, relacijskim strukturama**, **Bayesovim mreÅ¾ama**

---

## ğŸ”¹ 7. Trenutno stanje i izazovi

* **SNN-ovi i neuromorfni hardver joÅ¡ nisu u stvarnim aplikacijama.**
* Fokus je zasad na **benchmark datasetima i demonstracijama**.
* Glavni izazov:

  * JoÅ¡ **nema kombinacije algoritma i aplikacije** gdje SNN nadmaÅ¡uje deep learning u toÄnosti.
  * Prednost je zasad **u energetskoj uÄinkovitosti**, ne u performansama.
* Potrebno:

  * Å iriti fokus **izvan backpropagationa**
  * Razvijati **novije, bioloÅ¡ki inspirirane algoritme**
  * Iskoristiti **vremensku i dogaÄ‘ajnu prirodu** SNN-ova

---

## ğŸ”¹ 8. ZakljuÄna poruka

> Neuromorfni sustavi ne bi trebali pokuÅ¡avati samo *imitirati* deep learning,
> nego razviti **nove algoritme** koji koriste **njihovu bioloÅ¡ku i vremensku prirodu** â€”
> evoluciju, plastiÄnost, dogaÄ‘ajnu obradu i inherentnu paralelizaciju.

---


SavrÅ¡eno â€” ovo je vaÅ¾an dio teksta koji govori o **ograniÄenjima pristupa i skalabilnosti u neuromorfnom raÄunanju**.
Evo ti **jasne i detaljne natuknice** na hrvatskom:

---

### âš™ï¸ **Å iri pristup neuromorfnom hardveru i simulatorima â€“ kljuÄni izazovi i rjeÅ¡enja**

#### ğŸ”’ Trenutni problemi:

* **OgraniÄen pristup hardveru:**

  * Postoji **malo dostupnih neuromorfnih sustava** (poput Loihi, TrueNorth, SpiNNaker).
  * **Dostupni su samo putem ograniÄenog cloud pristupa**, Å¡to usporava istraÅ¾ivanje i razvoj.

* **Softver i simulacije nisu dovoljno pristupaÄni:**

  * Postoji nekoliko **open-source simulatora** (npr. **NEST**, **Brian**, **Nengo**), ali svaki je:

    * specijaliziran za **odreÄ‘enu zajednicu** ili **vrstu zadataka**,
    * teÅ¡ko primjenjiv izvan tih specifiÄnih podruÄja.
  * **NEST** je fokusiran na **raÄunalnu neuroznanost**,
    **Nengo** na **Neural Engineering Framework (NEF)**,
    Å¡to ograniÄava njihovu **Å¡iru upotrebljivost** u raÄunarstvu i industriji.

* **Slaba skalabilnost i performanse simulatora:**

  * Mnogi simulatori **nisu dovoljno brzi** pri radu u velikim razmjerima.
  * Zbog **eksplozije koliÄine podataka**, potrebno je procesirati informacije **brÅ¾e nego Å¡to se generiraju**,
    Å¡to trenutni simulatori **ne mogu pratiti**.
  * Posljedica: **sporo treniranje SNN-ova** i **teÅ¡ko testiranje novih algoritama**.

---

#### ğŸš€ Preporuke i buduÄ‡i smjer:

* **Razviti pristupaÄnije i univerzalnije alate** koji bi omoguÄ‡ili:

  * **Å¡iru upotrebu u raÄunalnoj znanosti i industriji**,
  * **brÅ¾e eksperimentiranje i inovaciju** u algoritmima.
* **PoboljÅ¡ati performanse simulatora** kako bi mogli:

  * **raditi u realnom vremenu**,
  * **skalirati** na **velike podatkovne setove i HPC (high-performance computing)** sustave.
* **OmoguÄ‡iti brÅ¾u evaluaciju algoritama** Äak i kada fiziÄki hardver nije dostupan â€”
  time bi se ubrzao **razvoj i testiranje novih neuromorfnih rjeÅ¡enja**.

---

### ğŸ’¡ Ukratko:

> Napredak neuromorfnog raÄunarstva trenutno koÄi **ograniÄen pristup hardveru** i **slaba skalabilnost simulatora**.
> RjeÅ¡enje je razvoj **brzih, skalabilnih i univerzalnih softverskih alata** koji omoguÄ‡uju brzu inovaciju i Å¡iru dostupnost zajednici.

---

---

### ğŸ”¹ Glavna ideja:

U buduÄ‡nosti, **neuromorfna raÄunala** neÄ‡e raditi sama za sebe, nego Ä‡e biti **dio veÄ‡eg ekosustava** â€” zajedno s **klasiÄnim raÄunalima**, **GPU-ovima**, pa Äak i **kvantnim raÄunalima**.
Svako od njih ima svoju **specijalnost**:

* CPU â€“ dobar za opÄ‡e zadatke
* GPU â€“ moÄ‡an za paralelne izraÄune
* Neuromorfni Äip â€“ izuzetno energetski uÄinkovit za obradu u stilu mozga (event-based, SNN, itd.)
* Kvantni Äip â€“ jak za specifiÄne optimizacijske i probabilistiÄke probleme

Dakle, ideja je: **kombinirati sve njih pametno**, tako da svaka komponenta radi ono Å¡to najbolje zna.

---

### ğŸ”¹ Problem:

Ali â€” postoji **ogroman izazov** u tome da sve te razliÄite arhitekture **rade zajedno**.

Trenutno:

* Neuromorfna raÄunala **ovise o klasiÄnim raÄunalima** (tzv. *host machines*) za:

  * programiranje samog neuromorfnog Äipa (definiranje mreÅ¾e i pravila)
  * komunikaciju sa senzorima i ureÄ‘ajima u stvarnom svijetu
  * primanje i slanje podataka

Ta ovisnost ima **visoku cijenu** â€” i **u vremenu** i **u energiji**.
Dakle, Äak i ako neuromorfni Äip radi ultraefikasno, ako mora stalno Äekati ili komunicirati s klasiÄnim raÄunalom, **gubi se njegova prednost**.
Na kraju, kad se uraÄunaju svi â€œoverheadiâ€ (komunikacija, prijenos podataka, CPU obrada), koristi od neuromorfnog pristupa mogu **potpuno nestati**.

---

### ğŸ”¹ RjeÅ¡enje koje autori predlaÅ¾u:

Treba razviti **nove modele programiranja i arhitekture** koje Ä‡e:

* **smanjiti ovisnost** neuromorfnih raÄunala o klasiÄnim hostovima,
* **optimizirati komunikaciju** izmeÄ‘u njih (da ne troÅ¡i viÅ¡e nego Å¡to vrijedi),
* i omoguÄ‡iti **jedinstveno programiranje** heterogenog sustava â€” tako da programer ne mora ruÄno "spajati" CPU + GPU + neuromorfni Äip.

---

### ğŸ”¹ Ukratko:

â¡ï¸ BuduÄ‡a raÄunala neÄ‡e biti samo "brÅ¾a", nego **pametno organizirana** kombinacija razliÄitih tehnologija.
â¡ï¸ Glavni izazov: **kako natjerati neuromorfna, kvantna i klasiÄna raÄunala da uÄinkovito suraÄ‘uju** bez da troÅ¡e previÅ¡e energije i vremena na meÄ‘usobnu komunikaciju.

ğŸ”¹ Glavna ideja:

Ovaj dio govori o nedostatku standardiziranih benchmarka i metrika u podruÄju neuromorfnog raÄunarstva.
To je OGROMAN problem â€” jer bez njih ne moÅ¾eÅ¡ objektivno usporediti:

koji hardver radi bolje,

koji algoritam je uÄinkovitiji,

ili koja metoda ima stvarne prednosti u praksi.

ğŸ”¹ ZaÅ¡to su benchmarki vaÅ¾ni?

Usporedi to s deep learningom:

Kad se pojavio ImageNet dataset, svi su znali:
â€œAko tvoj model pobijedi na ImageNetu â€” imaÅ¡ dobru arhitekturu.â€

Taj izazov je pokrenuo eksploziju napretka â€” AlexNet, ResNet, EfficientNet...
Benchmark je bio zajedniÄki cilj cijele zajednice.

â¡ï¸ Neuromorfno raÄunarstvo nema takav â€œImageNet momentâ€.
Ne postoji jedan zajedniÄki izazov ili set jasnih metrika koji bi usmjerio istraÅ¾ivanja i omoguÄ‡io fer usporedbe.

ğŸ”¹ Trenutna situacija:

Postoji nekoliko pokuÅ¡aja benchmark setova i datasetova specifiÄnih za spike-based i event-based pristupe:

Neuromorphic MNIST (N-MNIST) â€” spike verzija klasiÄnog MNIST-a

DVS Gesture Dataset â€” gesta prepoznata pomoÄ‡u Dynamic Vision Sensor (event kamera)

Spiking Heidelberg Audio Dataset (SHD) â€” zvuÄni dogaÄ‘aji za spike mreÅ¾e

Ali...
â¡ï¸ nisu Å¡iroko prihvaÄ‡eni u zajednici,
â¡ï¸ nemaju status â€œstandardnog testaâ€,
â¡ï¸ i Äesto ne iskoriÅ¡tavaju pravu prednost neuromorfnih sustava â€” temporalnu obradu dogaÄ‘aja u stvarnom vremenu.

Zato se Äesto koriste stari ML datasetovi poput MNIST, CIFAR-10 i ImageNet, ali oni:

nemaju vremensku dimenziju,

nisu event-based,

pa zapravo ne pokazuju pun potencijal neuromorfnih sustava.

ğŸ”¹ Problem jedinstvenog benchmarka:

Autori upozoravaju â€” nije ni idealno imati samo jedan zadatak (kao Å¡to je bio ImageNet u ML-u).
ZaÅ¡to?
Jer to moÅ¾e dovesti do â€œuske optimizacijeâ€ â€” svi algoritmi se prilagoÄ‘avaju samo da bi bili bolji na tom jednom zadatku, a gubi se Å¡ira primjena.

ğŸ”¹ RjeÅ¡enje:

ğŸ‘‰ Umjesto jednog â€œsvetog gralaâ€ benchmarka,
treba napraviti suite (set) razliÄitih izazova i metrika koji Ä‡e:

pokrivati razne tipove zadataka (vizualne, auditivne, motorne, bioloÅ¡ke simulacije itd.),

ukljuÄivati razliÄite tipove algoritama (ML i non-ML pristupe),

i omoguÄ‡iti fer usporedbe izmeÄ‘u razliÄitih arhitektura (CPU, GPU, neuromorfni, kvantni...).

ğŸ”¹ Ukratko:

ğŸ§  Problem: Nema zajedniÄkih benchmarka â†’ teÅ¡ko usporediti performanse i napredak.

âš™ï¸ Posljedica: Razvoj ide sporije jer svatko radi na svom datasetu, s vlastitim metrikama.

ğŸš€ RjeÅ¡enje: Napraviti skup razliÄitih izazova koji potiÄu inovaciju u viÅ¡e smjerova â€” ne samo jedan â€œImageNet za neuromorfneâ€.

Brutalan i vaÅ¾an odlomak â€” ovo ulazi pravo u **â€œsoftverskeâ€ izazove neuromorfnog raÄunarstva**! ğŸ’¥
Evo ti **detaljno, ali jasno strukturirane natuknice** koje hvataju sve bitno:

---

## ğŸ§  KljuÄna tema: â€œDefining programming abstractionsâ€

â¡ï¸ Problem: **Nema jednostavnog, apstraktnog naÄina za programiranje neuromorfnih sustava.**
Trenutno programeri moraju **ruÄno definirati svaki neuron, sinapsu, parametre i veze**.
To je:

* sporo,
* komplicirano,
* sklono pogreÅ¡kama,
* i potpuno drugaÄiji naÄin razmiÅ¡ljanja od klasiÄnog programiranja.

---

### ğŸ”¹ 1. Trenutni naÄin rada

* Programer mora **ruÄno dizajnirati SNN (Spiking Neural Network)** za zadatak.
* Definira se:

  * svaki neuron,
  * svaka sinapsa,
  * njihove veze,
  * parametri (threshold, delay, weightâ€¦).
* To traÅ¾i **mikro-razinu kontrole** â†’ usporedivo s pisanjem â€œassembly koda za mozakâ€.

â¡ï¸ **Posljedica:** ogroman trud, mala fleksibilnost, visoka moguÄ‡nost greÅ¡ke.
â¡ï¸ Zato razvoj *non-ML* algoritama na neuromorfnim sustavima ide jako sporo.

---

### ğŸ”¹ 2. ZaÅ¡to se najviÅ¡e koriste graf algoritmi

* Neuromorfne mreÅ¾e imaju prirodnu analogiju s grafovima:

  * **ÄŒvorovi (nodes)** â†’ neuroni
  * **Bridovi (edges)** â†’ sinapse
* Zato je **jednostavno mapirati graf strukturu** u SNN.
  â¡ï¸ Zato su mnogi *non-machine learning* algoritmi fokusirani upravo na graf probleme (npr. pretraÅ¾ivanje grafa, optimizacija).

---

### ğŸ”¹ 3. PostojeÄ‡i pokuÅ¡aji apstrakcije (viÅ¡a razina)

Postoje neki modeli koji pokuÅ¡avaju â€œolakÅ¡atiâ€ programiranje:

* **Neural Engineering Framework (NEF)** â†’
  omoguÄ‡uje definiranje apstraktnih izraÄuna pomoÄ‡u neurona (Äesto koriÅ¡ten za bioloÅ¡ki realistiÄne modele).
* **Dynamic Neural Fields (DNF)** â†’
  fokusiran na *embodied cognition* (npr. simulacije kognitivnih procesa u robotici).

â¡ï¸ Ali problem:
Ovi pristupi su **ograniÄeni na specifiÄne sluÄajeve**.
Ne postoji **opÄ‡a apstrakcija** koja bi omoguÄ‡ila programiranje neuromorfnih raÄunala za *razne* zadatke (ne samo neuronske modele ili robotiku).

---

### ğŸ”¹ 4. MoguÄ‡e rjeÅ¡enje: Subnetworks kao â€œprogramske primitiveâ€

ZamiÅ¡lja se ideja da bi se mogli definirati **mali, standardizirani â€œspike subnetworksâ€** koji obavljaju osnovne zadatke poznate programerima:

* logiÄke operacije (**AND, OR, XOR**),
* uvjeti (**if / else**),
* petlje (**loops**),
* binarne operacije itd.

â¡ï¸ Takvi â€œneuronski blokoviâ€ mogli bi se **sastavljati u veÄ‡e sustave**, baÅ¡ kao Å¡to se funkcije i moduli spajaju u normalnim programima.

* Postoji istraÅ¾ivanje (Plank et al.) koje pokazuje kako spike mreÅ¾e mogu realizirati **AND, OR, XOR** logiku.
* Ali to je tek poÄetak â€” ogroman prostor za razvoj **â€œneuromorfnih programskih konstrukataâ€**.

---

### ğŸ”¹ 5. Problem: nedostatak svijesti u Å¡iroj zajednici

Dok ne postoje jasne apstrakcije i dok se Å¡ira programska zajednica **ne upozna s konceptima spike-raÄunarstva**, razvoj *non-ML* neuromorfnih algoritama bit Ä‡e spor.

â¡ï¸ Dakle, **nije samo hardverski problem**, veÄ‡ i **problem edukacije i alata**.

---

### ğŸ”¹ 6. Bitno upozorenje: Neuromorfno â‰  za sve

Autori naglaÅ¡avaju:

* Da, moguÄ‡e je implementirati razne algoritme na neuromorfnim raÄunalima,
  **ali ne znaÄi da sve treba**.
* Neuromorfni sustavi su **specijalizirani procesori**, ne â€œopÄ‡e namjeneâ€ (kao CPU).
* Treba ih koristiti tamo gdje imaju **prirodnu prednost** â€” u:

  * real-time obradi dogaÄ‘aja,
  * energetski uÄinkovitim simulacijama,
  * bioloÅ¡kim modelima,
  * adaptivnim i vremenski ovisnim sustavima.

---

### ğŸ”¹ 7. ZakljuÄak:

* ğŸ§© **Problem:** nema jednostavnog naÄina za programiranje neuromorfnih sustava.
* âš™ï¸ **Trenutno:** sve se definira ruÄno, na neuronskoj razini.
* ğŸ’¡ **Postoje pokuÅ¡aji:** NEF i DNF â€” ali ograniÄeni.
* ğŸš€ **BuduÄ‡nost:** stvaranje â€œneuromorfnih programskih apstrakcijaâ€ (npr. neuronskih modula za osnovne operacije).
* âš ï¸ **Napomena:** neuromorfni Äipovi su specijalizirani â€” nisu za svaki problem.

---

## ğŸ§© **OUTLOOK â€” BuduÄ‡nost neuromorfnog raÄunarstva**

### ğŸ”¹ 1. Ogroman potencijal izvan Mooreovog zakona

* Neuromorfni procesori su:

  * **energetski izuzetno uÄinkoviti**,
  * **sposobni za strojno uÄenje i neke nestrojne (non-ML) izraÄune**,
  * **velika nada za post-Moore eru** â€“ omoguÄ‡uju napredak performansi bez tradicionalnog skaliranja tranzistora.
* Nude **nove paradigme obrade podataka** inspirirane biologijom (asinkrono, dogaÄ‘ajno, paralelno).

---

### ğŸ”¹ 2. Tri glavna buduÄ‡a **use-casea** za neuromorfne procesore

#### ğŸŸ¢ (1) **Edge computing** â€” ureÄ‘aji na rubu mreÅ¾e

* Idealni zbog **niskog energetskog troÅ¡ka**.
* Primjene:

  * autonomna vozila i dronovi,
  * robotika,
  * udaljeni senzori,
  * nosivi ureÄ‘aji,
  * Internet of Things (IoT).
* Fokus: **ekstremno niska potroÅ¡nja i real-time obrada**.

#### ğŸŸ  (2) **AI akceleratori i koprocesori** u osobnim ureÄ‘ajima

* Mogu postati **ko-akceleratori** u:

  * pametnim telefonima,
  * laptopima,
  * stolnim raÄunalima.
* SliÄni danaÅ¡njim GPU/NPU akceleratorima, ali s **reda veliÄine manjom potroÅ¡njom energije**.
* Mogu znaÄajno **produÅ¾iti trajanje baterije** i ubrzati AI zadatke.

#### ğŸ”µ (3) **Koprocesori u heterogenim HPC sustavima**

* U buduÄ‡im **heterogenim superraÄunalima**, neuromorfni Äipovi Ä‡e:

  * izvrÅ¡avati **spike-based simulacije**,
  * pokretati **graf algoritme**,
  * **rjeÅ¡avati diferencijalne jednadÅ¾be**,
  * **aproksimirati NP-kompletne probleme** uÄinkovito.
* Fokus: **reconfigurability** i **trening ubrzanje** za kompleksne znanstvene izraÄune.

â¡ï¸ **Napomena:** implementacije Ä‡e se razlikovati:

* Edge ureÄ‘aji â€“ visoka specijalizacija, minimalna potroÅ¡nja.
* HPC okruÅ¾enja â€“ veÄ‡a fleksibilnost i moguÄ‡nost treniranja.

---

### ğŸ”¹ 3. Trenutno stanje i smjer razvoja

* VeÄ‡ postoji **nekoliko velikih neuromorfnih sustava** dostupnih istraÅ¾ivaÄima (npr. Loihi, SpiNNaker).
* Aktivno se razvijaju i **nove vrste materijala i ureÄ‘aja** za fiziÄku implementaciju (npr. memristori, analogni elementi).
* Ovo stvara **ogromnu priliku za â€œhardwareâ€“software co-designâ€** â€” zajedniÄki razvoj od materijala do aplikacija.

---

### ğŸ”¹ 4. **Hardwareâ€“software codesign pristup**

Trenutno:

* Razvoj ide **odozdo prema gore** â†’ prvo materijali i ureÄ‘aji, pa tek onda algoritmi.

Bolji pristup:

* **â€œCijeli stack codesignâ€** â€“ paralelno oblikovati sve slojeve:

  * materijali i ureÄ‘aji,
  * arhitektura,
  * algoritmi,
  * aplikacije.

â¡ï¸ Time bi algoritmi mogli **utjecati na dizajn samog hardvera** i obrnuto.

---

### ğŸ”¹ 5. **Primjeri suvremenog codesign pristupa**

* **Bayesian optimization** i **Neural Architecture Search (NAS)** koriste se za optimizaciju cijelog sustava.
* Primjer:

  * kod **memristive crossbar** akceleratora,
  * automatski se odreÄ‘uje broj i veliÄina crossbara kako bi se **maksimizirala toÄnost i energetska uÄinkovitost**.

---

###  6. **Biologija â†”ï¸ Materijali: novi smjer razvoja**

* Trenutno se u sinaptiÄkoj plastiÄnosti ide â€œodozgo prema doljeâ€:

  * inspiracija iz biologije â†’ implementacija u ureÄ‘ajima â†’ prilagodba algoritma.
* Novi smjer:

  * **uÄiti iz fiziÄkih svojstava novih materijala** kako bi se razvili *novi algoritmi plastiÄnosti* (bottom-up).
* Ideja: moÅ¾da postoje **fiziÄke pojave u materijalima** koje mogu nadahnuti *potpuno nove modele uÄenja*.

---

###  7. **Paradigm shift â€“ promjena naÄina razmiÅ¡ljanja**

* UspjeÅ¡no koriÅ¡tenje neuromorfnih raÄunala zahtijevat Ä‡e **promjenu paradigme programiranja**.
* IstraÅ¾ivaÄi moraju **razmiÅ¡ljati u terminima dogaÄ‘aja, vremena i paralelizma**, a ne samo sekvencijalnog koda.

---

###  8. **Potencijalni najveÄ‡i dobitnici**

* Osim klasiÄnog ML-a, dvije skupine algoritama koje bi mogle **najviÅ¡e profitirati**:

  * **Graf algoritmi** (dijagrami, mreÅ¾e, optimizacija veza)
  * **Optimizacijski zadaci** (posebno NP-teÅ¡ki problemi)
* Oboje imaju koristi od:

  * **masivne paralelizacije**,
  * **asinkronosti**,
  * **stohastiÄne prirode neuromorfnih sustava**.

---

###  9. **ZakljuÄna vizija**

* Neuromorfno raÄunarstvo je joÅ¡ u ranoj fazi, ali:

  * ima **ogroman potencijal** za redefiniranje raÄunarstva,
  * omoguÄ‡uje **energetski uÄinkovite i paralelne izraÄune**,
  * **nadopunjuje** postojeÄ‡e paradigme (ne zamjenjuje ih).
* Vrijeme je da **Å¡ira raÄunalna znanstvena zajednica** poÄne ukljuÄivati neuromorfne raÄunare kao **dio buduÄ‡e raÄunalne infrastrukture**.

---

Event-based vision: A Survey, Guillermo Gallego & co.
- Event kamere - bio-inspired senzori koji, za razliku od standarnih frame-based kamera, asinkrono mjere per-pixel promjene svjetline i kao output izbacuju stream evenata (svaki se sastoji od: vremena, lokacija i oznake promjene svjetline)
- Features: high temporal resolution, high dynamic range, low power consumption, high pixel bandwith, reduced motion blur, low latency, high speed
- Koriste se za sve levele CV-a (od feature detectiona i trackinga, optical flowa do rekonstrukcije, segmentacije i recognitiona)
- Postoje posebne tehnologije za to (npr. SCNNs)


- ZapoÄelo 1986. - Carver Mead => spoj inÅ¾enjerske i bioliÅ¡ke perspektive
- 1991. - Silicijska zjenica => oponaÅ¡anje prirodne arhitekture oka
- Cilj: shvatiti kako mozak radi i sloÅ¾iti ga na raÄunalnom Äipu
- Bio-inspired tehnologija silikonskih zjenica/event kamera
- Vid je najdominantniji ljudski osjet => najjaÄi signali
- Event based senzori rijeÅ¡avaju neke probleme frame-based visiona (high speed motion estimation; high dynamic range)
- Asinkroni senzori => sampling scene na temelju dinamike u istoj, a ne na temelju internog clocka koji nema veze s dogaÄ‘ajima na sceni (kao kod frame based di se koristi sampling u k fps)
- Visok temporal resolution; niska latencija; visok dynamic range, niska potroÅ¡nja energije
- Robotika, wearable ureÄ‘aji + situacije di standarnde kamere ne delaju dobro (high speed&dynamic range)...nekontrolirano osvjetljenje, latencija + podruÄja di je vaÅ¾no oÄuvanje elektriÄne energije
- AR/VR, video igre

- Rade znatno drukÄije nego standarne kamere (asinkrono mjere promjene u intenzitetu svjetlosti by-pixel) pa su potrebne nove metode za procesiranje outputa

- Object tracking, surveillance and monitoring, object/gesture recognition, depth estimation, structured light 3d scanning, optical flow estimation, image reonstruction, localization&mapping, image deblurring, star tracking

Glavna razlika u odnosu na standardne frame based kamere:
- standardne kamere koriste full images at a rate specified by external clock (npr. 30fps)
- event kamere reagiraju na promjene svjetlosti u sceni asinkrono i neovisno za svaki piksel
- output event kamere je varijabilna data-rate sekvenca digitalnih evenata (spikeova)

- Svaki spike predstavlja promjenu osjvetljenja u odreÄ‘enom pikselu u odreÄ‘enom vremenskom trenutku => spiking nature bioloÅ¡kog vida
- Svaki piksel pamti log intenziteta za svaki eent i kontinuirano prati promjenu intenziteta u odnosu na upamÄ‡enu vrijednost
- Kada promjena preÄ‘e threshold, kamera Å¡alje event koji se Å¡alje (x,y koordinate lokacije, t timestamp, 1-bitni polaritet promjene (ON ako se svjetlost poveÄ‡ala, OFF ako se smanjila)
- Eventi se Å¡alju od pixel arraya prema periferiji i onda van iz kamere koristeÄ‡i shared digital output bus (Address-event representation; AER)
- Rate od 2 MHz do 1200 Mhz ovisno o Äipu i hardveru

- Event kamere su data-driven senzori (output im ovisi o koliÄini kretanja ili promjeni svjetlosti u sceni)
- ÄŒa je kretanje brÅ¾e/ÄeÅ¡Ä‡e/intenzivnije, viÅ¡e evenata po sekundi se generira
- Svaki piksel ima vlastiti sampling rate i prati intenzitet evenata koji signalizira
- Eventi imaju timestampove na razini mikrosekunde => Å¡alju se s latencijom manjom od milisekunde
- Senzori brzo reagiraju na stimulans 

- Incident light => produkt osvjetljenja scene i odsjaja povrÅ¡ine koja se "snima"
- Ako je osvjetljenje otprilike konstantno, incident light je minimalan i nastaje samo kada se ovjekt gledanja pomiÄe
- DVS pikesli imaju konaÄan bandwith; ako su nadolazeÄ‡e promjene u intenzitetu preÄeste, photoreceptor "filtrira" varijacije u njima i ne registrira ih => ukratko; dvs pikseli imaju fiziÄki limit maksimalne brzine kojom reagiraju na promjene
- Ako su eventi prebrzi; senzor praktiÄki lovi manje evenata nego ako su u "normalnoj brzini"

- NajÄeÅ¡Ä‡i event camera dizajni:
- first silicon retina: Mahowald&Mead (1986-1992)
- logaritamski pikesli => output spike eventi nastaju koristeÄ‡i AER protokol
- Problem: treba precizno uÅ¡zimavati svaku pojedinu Å¾icu (bias parametri); mismatch u responsevima za razliÄite piksele; pikseli su preveliki

- DVS event camera => utemeljena na frame-based silicon mreÅ¾nici (continous-time fotoreceptor + redout circle koji se resetira svaki put kad se pixel samplira)
- UviÄ‘eno je da je potreban i neki oblik statiÄkog outputa ("absoulute brightness")
- Ideja: kamera koje concurrently daju i statiÄki i dinamiÄki output)

- ATIS => asinkroni time based image sensor => pikesli sa DVS subpikselima
- OkidaÄ resetira kondenzator na visoki napon; sturja se odvodi iz kondenzatora pomoÄ‡u diode; Å¡to je input svjetliji, to se kondenzator brÅ¾e prazni
- Samo pikseli koji se stvarno mijenjaju imaju utjecaj na napon
- ÄŒa je svjetliji event; to su promjene ÄeÅ¡Ä‡e
- Neodostatak: jako veliki pikesli; u mraku je jako sporo i novi eventi mogu prekinuti oÄitavanje starih...nepraktiÄno

- DAVIS => spoj aktivnog pixel senzora (APS) i DVS-a
- puno manji pikseli
- dijeljena fotodioda
- frameovi se obraÄ‘uju u konstantom rateu
- problem: ograniÄeni dynamic range; redundancija ako se pikseli ne promjene

Prednosti event kamera
High temporal resolution:
 - praÄ‡enje promjena osvjetljenja je brzo
 - iÅ¡Äitavanje evenata je digitalno, s 1MHz clockom (eventi su detektirani i timestampirani u roku mikrosekunde)
 - mogu snimati jako brze pokrete, bez da dolazi do blura koji je standardan za frame-based kamere

Low latency:
 - svaki piksel radi zasebno; ne treba se Äekati global exposure za cijeli frame
 - Äim se event detektira, transmitted je (latencija ispod milisekunde u realnom okruÅ¾enju)

Low power:
 - transmitaju se samo promjene u osvjetljenju; nema redundantnih podataka
 - struja se troÅ¡i samo za procesiranje piksela koji se mijenjaju

High dynamic range:
 - i viÅ¡e nego duplo bolje nego kod najkvalitetnijih frame-based kamera
 - mogu captureati informacije u svim uvjetima..od mjeseÄine do sunca
 - fotoreceptori rade logaritamski i svaki piksel radi zasebno, bez da Äeka "zatvaraÄ" kamere
 - poput zjenice, prilagodljivi su i jakom mraku i jakoj svjetlosti

Izazovi:
- dizajn novih korisnih softverskih algoritama i hardverskih metoda
1) space-time output
   Output event kamera je fundamenatalno drukÄiji od outputa standardnih kamera; eventi su asinkroni i prostorno sparse (rijetki), dok su frameovi sinkroni i dense (frame toÄno prati tijek onoga ispred kamere)
2) different photometric sensing
   Standardne kamere daju grayscale info, dok eventi u sebi sadrÅ¾e binarni (increase/decrease) info o promjeni svjetlosti. Promjene svjetlosti ne ovise samo o trenutnom osvjetljenju scene nego i o trenutnim i proÅ¡lim kretnjama u sceni
3) noise and dynamics
   Svi vision senzori su noisy jer postoji neizbjeÅ¾an noise u Äesticama sjvetlosti i u samim el. krugovima u tranzistorima. Problem ze event based kamere: kako kvantizirati temporal contrast

---

### **Kvantizacija temporalnog kontrasta â€“ saÅ¾etak**

**1. Temporalni kontrast (C):**

* Mjeri promjenu svjetline kroz vrijeme:
  [
  C(t) = \frac{I(t) - I(t - Î”t)}{I(t - Î”t)}
  ]
* DVS piksel reagira samo kad ta promjena prijeÄ‘e odreÄ‘eni prag (Î¸).

**2. Generiranje eventa:**

* Ako |C(t)| > Î¸ â†’ generira se event (ON za porast, OFF za pad svjetline).
* Male promjene ispod praga se ignoriraju.

**3. Problem kvantizacije:**

* Potrebno je definirati kako pretvoriti kontinuirane promjene svjetline u diskretne dogaÄ‘aje.
* KljuÄno je odabrati prag koji daje dovoljno informacija, ali bez previÅ¡e Å¡uma.

**4. Izazovi:**

* **Previsok prag:** gube se male, ali vaÅ¾ne promjene.
* **Prenizak prag:** nastaje previÅ¡e Å¡uma (previÅ¡e eventova).
* **FiziÄko ograniÄenje:** pikseli imaju ograniÄen odziv (RC krug â†’ bandwidth limit), pa ne mogu detektirati ekstremno brze promjene.

**5. Logaritamska kvantizacija:**

* U praksi se koristi logaritamska razina svjetline:
  [
  \log(I(t)) - \log(I(t - Î”t))
  ]
* Time se postiÅ¾e bolja stabilnost u razliÄitim uvjetima osvjetljenja.

**6. ZakljuÄak:**
Kvantizacija temporalnog kontrasta je proces kojim DVS senzor pretvara kontinuirane promjene svjetline u diskretne, informativne dogaÄ‘aje pomoÄ‡u praga i logaritamske transformacije, uz fiziÄko ograniÄenje brzine odziva piksela.

---

Nove metode trebaju uzeti u obzir: space-time, photometriÄku i stohastiÄku prirodu podataka
Kako najefikasnije izvuÄ‡i info iz evenata da bude relevantno za task koji se rijeÅ¡ava?
Kako se noisy i neidealni efekti mogu modificirati da se lakÅ¡e izvlaÄe korisne informacije



---

## ğŸ”¹ Osnovni koncept

Event-based kamera (DVS) ima piksele koji **ne snimaju frameove**, nego reagiraju *neovisno i asinkrono* na **promjene u logaritmu svjetlosnog toka** (fotostruke).

Definicija:
[
L = \log(I)
]
gdje je ( I ) â€“ fotostruja (intenzitet svjetlosti), a ( L ) logaritamska svjetlina (â€œbrightnessâ€).

---

## ğŸ”¹ Kada se generira event

Svaki piksel ima svoju zadnju pohranjenu vrijednost svjetline.
Event se generira kad promjena svjetline **od zadnjeg eventa** prijeÄ‘e odreÄ‘eni prag ( C ):

[
L(x_k, t_k) - L(x_k, t_k - \Delta t_k) = p_k C \quad (1)
]

* ( x_k ): koordinate piksela koji je ispalio event
* ( t_k ): trenutak dogaÄ‘aja
* ( p_k \in {+1, -1} ): **polarnost** eventa

  * ( +1 ) = porast svjetline (**ON event**)
  * ( -1 ) = pad svjetline (**OFF event**)
* ( C ): **temporalni kontrastni prag** (threshold) â€” minimalna promjena log-svjetline potrebna da piksel reagira

Dakle:
svaki piksel *pamti zadnju vrijednost L* i *emitira event* kad se promijeni za Â±C.

---

## ğŸ”¹ ZnaÄenje praga C

* Prag ( C ) postavljaju **bias struje** u tranzistorima piksela.
* Te struje definiraju **osjetljivost** i **brzinu detekcije**.
* Prag se moÅ¾e softverski podesiti (tipiÄno 10â€“50% promjene osvjetljenja).
* NiÅ¾i prag â†’ veÄ‡a osjetljivost, ali i viÅ¡e Å¡uma.
* Donja granica (~1%) postiÅ¾e se samo pri jakom svjetlu i niskom Å¡umu.

---

## ğŸ”¹ Povezanost s derivacijom svjetline

Ako su promjene male (tj. kratko vrijeme izmeÄ‘u dva eventa), promjenu svjetline moÅ¾eÅ¡ aproksimirati derivacijom (Taylorova ekspanzija):

[
L(x_k, t_k) - L(x_k, t_k - \Delta t_k) \approx \frac{\partial L}{\partial t}(x_k, t_k) , \Delta t_k
]

Ubacimo to u prethodnu formulu (1):

[
\frac{\partial L}{\partial t}(x_k, t_k) \approx \frac{p_k C}{\Delta t_k} \quad (3)
]

To znaÄi da **frekvencija eventova (1/Î”t)** indirektno kodira **brzinu promjene svjetline**.
Drugim rijeÄima: viÅ¡e eventova u jedinici vremena = brÅ¾a promjena u sceni.

---

## ğŸ”¹ Fizikalno znaÄenje

* DVS ne mjeri **apsolutnu svjetlinu**, nego **promjene** u njoj.
* KlasiÄna kamera daje â€œkadrove svjetlineâ€, dok DVS daje â€œspikeove kontrastaâ€.
* To je *asinkrono mjerenje derivacije u vremenu*.

---

## ğŸ”¹ Povezanost s gibajuÄ‡im rubovima

Ako pretpostavimo da je ukupna svjetlina scene konstantna, promjene svjetline proizlaze iz **kretanja rubova**.
Linearizacijom i primjenom *brightness constancy assumption* dobijeÅ¡:

[
\frac{\partial L}{\partial t} = -\nabla L \cdot v
]

* ( \nabla L = (\partial_x L, \partial_y L) ) je **gradijent svjetline** (smjer ruba).
* ( v = (v_x, v_y) ) je **brzina kretanja toÄke na slici**.

Dakle:

* Ako je gibanje **paralelno s rubom** ((v \perp \nabla L)) â†’ nema promjene â†’ nema eventa.
* Ako je gibanje **okomito na rub** ((v \parallel \nabla L)) â†’ maksimalna promjena â†’ mnogo eventova.

To objaÅ¡njava zaÅ¡to DVS detektira **ruba u pokretu**, a ne teksture koje miruju.

---

## ğŸ”¹ ProbabilistiÄki model generiranja eventa

Idealna jednadÅ¾ba (1) pretpostavlja savrÅ¡en senzor bez Å¡uma.
U stvarnosti postoje:

* **SluÄajni Å¡um** (shot noise u fotostruji)
* **mismatch** izmeÄ‘u tranzistora
* **varijacije praga** izmeÄ‘u piksela

Zbog toga je prag **stohastiÄan**, tj. nije uvijek toÄno C, nego varira oko njega prema **normalnoj raspodjeli**:

[
P(C) \sim \mathcal{N}(C, \sigma_C)
]
gdje je tipiÄna Å¡irina distribucije (Ïƒ) oko 2â€“4% kontrasta.

---

## ğŸ”¹ Dodatni efekti

* **Refraktorni period:** kratko vrijeme nakon emitiranja eventa u kojem piksel *ignorira nove promjene* (ograniÄava brzinu).
* **Bus congestion:** kad previÅ¡e piksela istovremeno Å¡alje evente, nastaje â€œzaguÅ¡enjeâ€ na sabirnici.
* **Fixed Pattern Noise (FPN):** varijacija praga i odziva izmeÄ‘u piksela (standardna devijacija 2â€“4%).

---

## ğŸ”¹ ZakljuÄak

Event-based kamera:

1. Radi u log-svjetlosnoj domeni.
2. Generira event kad promjena svjetline prijeÄ‘e prag ( C ).
3. ( p_k ) oznaÄava polaritet (ON/OFF).
4. Derivacija svjetline ( \frac{\partial L}{\partial t} ) povezana je s frekvencijom eventova.
5. Eventi nastaju najviÅ¡e na pokretnim rubovima, kad je ( v \parallel \nabla L ).
6. Prag ( C ) je stohastiÄan zbog Å¡uma, a fiziÄki ga ograniÄavaju bias struje, shot noise i osvjetljenje.

---



---

### **Napredne event kamere â€“ saÅ¾etak kljuÄnih toÄaka**

**1. OpÄ‡i kontekst**

* Trenutno su dostupne samo kroz **znanstvene suradnje** s razvojnim timovima.
* Fokus istraÅ¾ivanja je na **proÅ¡irenju funkcionalnosti**: boja, osjetljivost, dinamiÄki raspon.

---

**2. Event kamere s bojom (Color event cameras)**

* Cilj: omoguÄ‡iti *color vision* u event kamerama (kao kod ljudi i obiÄnih kamera).
* **Rani pokuÅ¡aji** koristili â€œ*vertacolor principle*â€ (razliÄite valne duljine svjetla razliÄito prodiru u silicij).

  * Pionir: **Foveon senzori**.
  * Problem: **slaba separacija boja** (nema Äiste razlike izmeÄ‘u R, G, B kanala).
* **Noviji pristupi:**

  * **Color Filter Arrays (CFA)** â€“ integrirani RGB filteri iznad piksela.
  * **Color-splitter prizme** â€“ optiÄki razdvajaju boje na odvojene senzore.

    * Prednost: bolja separacija boja.
    * Mana: **veÄ‡a cijena** i sloÅ¾enost.

---

**3. PoveÄ‡ana kontrastna osjetljivost (Higher Contrast Sensitivity)**

* Cilj: **detektirati manje promjene svjetline** (veÄ‡a osjetljivost).
* Eksperimentalni senzori postigli osjetljivost do **~1% promjene osvjetljenja** (u laboratorijskim uvjetima).
* Tehnika:

  * Temeljeno na ideji **bolometra** â€“ pojaÄanje signala *prije detektora promjene*.
  * To smanjuje **Fixed Pattern Noise (FPN)** i poveÄ‡ava preciznost detekcije.
* Problem: preamplifikacija zahtijeva **aktivnu kontrolu pojaÄanja** da se izbjegne zasiÄ‡enje (â€œclippingâ€).
* Kompromis: **veÄ‡a osjetljivost â†’ manji dinamiÄki raspon**.

---

**4. KljuÄna ograniÄenja**

* Trenutni napredni modeli su **eksperimentalni**, nisu komercijalno dostupni.
* Balans izmeÄ‘u **osjetljivosti, dinamiÄkog raspona i troÅ¡ka** joÅ¡ nije optimalno rijeÅ¡en.

---


---

### **Ekstrakcija informacija iz event podataka â€“ saÅ¾etak kljuÄnih toÄaka**

**1. KljuÄno pitanje:**
Kako izvuÄ‡i *znaÄajne informacije* iz asinkronih, rijetkih i vremenski preciznih event podataka â€” ovisi o konkretnoj **aplikaciji** (npr. praÄ‡enje, rekonstrukcija, prepoznavanje).
To pitanje odreÄ‘uje **dizajn algoritma**.

---

**2. Svojstva event podataka:**

* **Asinkroni** â€“ svaki piksel Å¡alje event neovisno.
* **Sparse** â€“ veÄ‡ina piksela u datom trenutku ne generira event.
* **Visoka vremenska rezolucija** i **niska latencija**.

---

**3. Dvije osnovne kategorije algoritama:**

| Kategorija                            | Opis                                                  | Latencija | Napomena                                  |
| ------------------------------------- | ----------------------------------------------------- | --------- | ----------------------------------------- |
| **(i) Event-by-event**                | Svaki dolazni event odmah aÅ¾urira stanje sustava      | Minimalna | NajniÅ¾a latencija, ali veÄ‡a sloÅ¾enost     |
| **(ii) Event-packet (grupne metode)** | Obrada blokova (paketa) dogaÄ‘aja u vremenskom prozoru | ViÅ¡a      | Uvodi kaÅ¡njenje, ali stabilniji rezultati |

*Napomena:*
Granica izmeÄ‘u kategorija nije stroga â€“ prozori mogu â€œklizitiâ€ po jedan event, pa se stanje moÅ¾e aÅ¾urirati i kontinuirano.

---

**4. KljuÄna spoznaja:**
Jedan event sam po sebi **nije dovoljan** za pouzdanu procjenu â€”
potrebno je dodatno znanje ili povijest proÅ¡lih dogaÄ‘aja.

---

**5. Orijentacijska (ortogonalna) klasifikacija algoritama:**
Prema **naÄinu obrade dogaÄ‘aja:**

| Tip pristupa                 | Opis                                                                            |
| ---------------------------- | ------------------------------------------------------------------------------- |
| **Model-based**              | Koristi fizikalne ili geometrijske modele (npr. optiÄki tok, geometriju kamere) |
| **Model-free / Data-driven** | UÄi reprezentacije iz podataka (npr. deep learning, ML pristupi)                |

---

**6. Prema tipu funkcije cilja (loss function):**

* **Geometrijska** â€“ temelji se na poloÅ¾aju i pokretu toÄaka u prostoru.
* **Vremenska (temporal)** â€“ koristi vremenski slijed i kaÅ¡njenja izmeÄ‘u eventova.
* **Fotometrijska** â€“ temelji se na polaritetu i aktivnosti dogaÄ‘aja (ON/OFF).

---

**7. Trenutni fokus istraÅ¾ivanja:**
IstraÅ¾uju se prednosti i mane svake kategorije (event-by-event vs. group, model-based vs. ML) te kombinacije koje optimiziraju balans izmeÄ‘u **toÄnosti, brzine i robusnosti**.

---
KONCEPT POSITIVE I NEGATIVE EVENATA:
| Type           | Meaning            | Triggered when  | Color in visualization |
| -------------- | ------------------ | --------------- | ---------------------- |
| Positive Event | Pixel got brighter | Î”L â‰¥ +threshold | Green                  |
| Negative Event | Pixel got darker   | Î”L â‰¤ -threshold | Red                    |


Eventi se procesiraju i Äesto se transformiraju u alternativne reprezentacije (npr. events in space time, event frames, time surface s timestampovima po pikselu, voxel grid, motion compensated event image, reconstrcted intensity image itd.)

---

### **1. Events in spaceâ€“time (prostorno-vremenski dogaÄ‘aji)**

* Svaki event se predstavlja trojkom *(x, y, t, p)* â†’ pozicija, vrijeme i polaritet.
* Vizualno: â€œtoÄkiceâ€ u 3D prostoru gdje je Z-os vrijeme.
* Koristi se za analizu *temporalne dinamike* (kretanje objekata, optical flow).
* To je najosnovnija forma â€” niÅ¡ta agregirano, Äista sirova temporalna informacija.

---

### **2. Event frame (akumulirani dogaÄ‘aji u sliku)**

* Najjednostavnije: â€œbrojiâ€ koliko se pozitivnih i negativnih dogaÄ‘aja dogodilo u odreÄ‘enom vremenskom prozoru.
* DobijeÅ¡ 2D sliku (kao frame) gdje intenzitet piksela = broj dogaÄ‘aja.
* GubiÅ¡ preciznu vremensku informaciju, ali moÅ¾eÅ¡ koristiti standardne CNN-ove.
* Korisno za vizualizaciju ili klasiÄne detekcijske mreÅ¾e.

---

### **3. Time surface**

* Svaki piksel sadrÅ¾i **vrijeme posljednjeg dogaÄ‘aja**.
* DobijeÅ¡ â€œmapu svjeÅ¾ineâ€ â€” noviji eventi imaju veÄ‡e vrijednosti.
* Koristi se za *motion detection* i *feature tracking*, jer pokazuje gdje se *nedavno* neÅ¡to promijenilo.
* MoÅ¾e se eksponencijalno â€œzaboravljatiâ€ starije evente â†’ time decay.

---

### **4. Voxel grid**

* DogaÄ‘aje rasporediÅ¡ u 3D mreÅ¾u (x, y, vrijeme).
* Vremenska dimenzija se diskretizira u N binova (npr. 5â€“10 vremenskih slojeva).
* DobijeÅ¡ â€œ3D tensorâ€ koji CNN ili transformer moÅ¾e direktno obraÄ‘ivati.
* Zlatni standard u deep-learning pristupima za event kamere (npr. EV-FlowNet, E2VID).

---

### **5. Motion-compensated event image**

* PokuÅ¡ava â€œporavnatiâ€ dogaÄ‘aje tako da izgleda kao da su snimljeni istovremeno.
* Radi *kompenzaciju gibanja* objekata ili kamere na temelju pretpostavljenog optic flow-a.
* Kad to ispravno napraviÅ¡, svi eventi od istog ruba poravnaju se â†’ oÅ¡tra rekonstruirana slika.
* Koristi se kod rekonstrukcije scene i odvajanja pozadine/predmeta u pokretu.

---

### **6. Reconstructed intensity image**

* Koristi sve dogaÄ‘aje (Äesto + poÄetni â€œkey frameâ€) da rekonstruira standardnu RGB ili grayscale sliku.
* Ideja: integrira promjene svjetline tijekom vremena.
* Koristi se u **E2VID** i sliÄnim mreÅ¾ama koje rade â€œframe-like outputâ€ iz event streama.
* Super za situacije s visokim dinamiÄkim rasponom ili slabim osvjetljenjem.


Metode za event processing

Preprocessing (input adaptation)
Core processing (feature extraction and analysis)
Postprocessing (output creation)

U preprocessingu koristi se event packet
Motion-compensated event images se koriste u core processingu

Metoda obrade ovisi o tome kako su eventi reprezentirani i koji je hardver dostupan

| **Aspekt**                 | **Event-by-Event obrada**                                                | **Event-Packet obrada**                                                       |
| -------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------- |
| **Opis**                   | Svaki dogaÄ‘aj se procesira individualno, odmah po dolasku.               | DogaÄ‘aji se grupiraju u vremenske pakete i procesiraju zajedno.               |
| **TipiÄne reprezentacije** | Sparse (rijetke) reprezentacije, vremenski toÄne (x, y, t, p).           | Dense reprezentacije poput event framea, voxel grida, time surfacea.          |
| **Hardverska platforma**   | Neuromorfni Äipovi i SNN arhitekture.                                    | Standardni CPU/GPU procesori.                                                 |
| **TipiÄni algoritmi**      | Spiking neuronske mreÅ¾e (SNN), deterministiÄki i probabilistiÄki filtri. | DNN-ovi, CNN-ovi, ruÄno dizajnirani feature extractori.                       |
| **Prednosti**              | Vrlo niska latencija, energetska uÄinkovitost, prirodno asinkrono.       | Jednostavnije za implementaciju, kompatibilno s postojeÄ‡im ML frameworkovima. |
| **Nedostaci**              | Zahtijeva specijalizirani hardver i kompleksniju arhitekturu.            | Gubi vremensku preciznost i poveÄ‡ava latenciju.                               |
| **TipiÄne primjene**       | Real-time kontrola, robotika, edge sustavi, ultra-brzi odziv.            | Analiza scene, rekonstrukcija slike, uÄenje iz dogaÄ‘ajnih podataka.           |

---


---

## ğŸ§  Event-by-Event metode

### ğŸ”¹ 1. DeterministiÄki filteri

* **Primjeri:** prostorno-vremenske konvolucije, activity filteri.
* **Koriste se za:**

  * Redukciju Å¡uma
  * Ekstrakciju znaÄajki (feature extraction)
  * Rekonstrukciju slike
  * Filtriranje svjetline
* **Prednost:** savrÅ¡eno prirodni za asinkrone podatke â€” omoguÄ‡uju minimalnu latenciju i iskoriÅ¡tavaju svojstva senzora.

---

### ğŸ”¹ 2. ProbabilistiÄki (Bayesovski) filteri

* **Primjeri:** Kalman filter, particle filter.
* **Koriste se za:**

  * PraÄ‡enje poloÅ¾aja i orijentacije (pose tracking) u SLAM sustavima.
* **Zahtijevaju dodatne informacije:**

  * Npr. grayscale slike, mapu scene ili povijesne evente.
* **NaÄin rada:** svaki novi event usporeÄ‘uje se s postojeÄ‡om "appearance" informacijom â†’ razlika (innovation) aÅ¾urira stanje filtra.
* **Prednosti:** mogu kombinirati podatke iz viÅ¡e izvora i raditi s djelomiÄnim informacijama.

---

### ğŸ”¹ 3. ViÅ¡eslojni neuronski modeli (ANN / SNN)

* **Dvije glavne grane:**

  * **SNN (Spiking Neural Networks)** â€“ prirodno procesiraju evente jedan po jedan.
  * **KlasiÄne DNN mreÅ¾e** â€“ Äesto trenirane na event-paketima, kasnije konvertirane u SNN.

---

### ğŸ”¹ 4. UÄenje i treniranje

* **Nesupervizirano uÄenje:**

  * Koristi se za ekstrakciju znaÄajki (feature extraction).
  * Rezultat se Äesto Å¡alje u klasiÄni klasifikator (npr. SVM).
  * Ipak, i dalje je potrebna odreÄ‘ena koliÄina oznaÄenih podataka (labeled data).

* **Supervizirano uÄenje:**

  * Ako ima dovoljno oznaÄenih podataka, moÅ¾e se direktno trenirati ANN/SNN bez dodatnog klasifikatora.
  * **Rezultat:** viÅ¡a toÄnost nego kod nesuperviziranog pristupa.

---

### ğŸ”¹ 5. Kombinirani pristupi

* Tijekom treniranja: koriste **pakete eventa** (frame-based deep learning).
* Nakon treniranja: model se pretvara u **SNN koji procesira evente jedan po jedan**.
* Ova kombinacija koristi prednosti i klasiÄnih GPU mreÅ¾a i neuromorfnih sustava.

---

### ğŸ”¹ 6. Glavne primjene

* **Klasifikacija objekata**
* **Prepoznavanje akcija / pokreta**
* **Embedded sustavi** â€“ optimizirani za efikasnost i nisku latenciju, Äesto koriste **custom SNN hardver**.

---

### ğŸ”¹ 7. Trendovi i buduÄ‡i razvoj

* PoveÄ‡an interes za:

  * **Supervizirano uÄenje direktno u SNN-ovima**
  * **Ugradnju takvih sustava u embedded ureÄ‘aje** radi brzine i energetske uÄinkovitosti.

---

Naravno â€” ovo je jako bogat odlomak, pa sam ti izvukao **sve kljuÄne koncepte i ideje** u pregledne, tematski grupirane natuknice u **markdown formatu**.
Sve bitno o **"Methods for Groups of Events"** (tj. grupnom procesiranju eventa) je ovdje saÅ¾eto i jasno ğŸ‘‡

---

## âš™ï¸ Methods for Groups of Events

*(Metode koje procesiraju viÅ¡e dogaÄ‘aja zajedno â€” grupno, a ne pojedinaÄno)*

---

### ğŸ”¹ 1. Osnovna ideja

* **Razlog:** pojedinaÄni eventi nose premalo informacija i puno Å¡uma.
* **RjeÅ¡enje:** grupiranjem viÅ¡e eventa postiÅ¾e se bolji **signal-to-noise ratio**.
* **Proces:** viÅ¡e eventa se kombinira u **reprezentacije** poput:

  * event packet
  * event frame
  * time surface (TS)
  * voxel grid
* Takve reprezentacije omoguÄ‡uju koriÅ¡tenje klasiÄnih CV (computer vision) metoda.

---

### ğŸ”¹ 2. Event Frames

* Vrlo praktiÄna reprezentacija jer omoguÄ‡uje ponovnu upotrebu klasiÄnih CV alata.
* **Koristi se za:**

  * stereo viziju (dobri, ali skromni rezultati)
  * estimaciju poloÅ¾aja kamere (pose estimation)
  * optical flow (block matching)
  * input za DNN, SVM, Random Forest klasifikatore
* **Posebna prednost:** adaptivni frame rate (ovisno o sceni).
* **Napomena:** rijetki radovi uzimaju u obzir fotometrijsko znaÄenje eventa (npr. promjenu svjetline).

---

### ğŸ”¹ 3. Intensity Increment Images

* Koriste **inkremente svjetline** izmeÄ‘u dogaÄ‘aja.
* **Primjene:**

  * praÄ‡enje znaÄajki (feature tracking)
  * deblurring (odstranjivanje zamuÄ‡enja slike)
  * praÄ‡enje kamere (camera tracking)

---

### ğŸ”¹ 4. Time Surfaces (TS)

* **Opis:** mapa koja biljeÅ¾i *vrijeme zadnjeg eventa po pikselu*.
* **Osjetljive su na:** rubove i smjer gibanja objekta.
* **Primjene:**

  * analiza gibanja i prepoznavanje oblika
  * iz TS-a se moÅ¾e izvesti **optical flow** (fitanjem ravnina kroz prostor-vrijeme)
  * ulaz za **CNN-e** koji raÄunaju optical flow i brzinu
  * **corner detection** (Harris, FAST, ili noviji ML pristupi)
  * stereo vizija pomoÄ‡u **temporalnog podudaranja** (event concurrence & timestamp similarity)
* **Problem:** degradacija performansi u teksturiranim scenama â†’ **motion overwriting** (novi eventi briÅ¡u tragove starih).

---

### ğŸ”¹ 5. Voxel Grids

* **Opis:** 3D volumetrijska reprezentacija (x, y, t).
* **Prednosti:** bolje Äuva vremensku informaciju.
* **Nedostatak:** troÅ¡i viÅ¡e memorije i raÄunske snage.
* **Koristi se za:**

  * optical flow (varijacijska optimizacija)
  * DNN ulaze/izlaze s viÅ¡e kanala (multi-channel input/output)
* **NaÄin obrade:**

  * konvolucije nad voxelima
  * optimizacija po kriteriju minimalne greÅ¡ke (objective function)

---

### ğŸ”¹ 6. KoriÅ¡tenje konvencionalnih CV alata

* Kad se eventi pretvore u grid/frame formu â€” mogu se koristiti svi klasiÄni alati:

  * **CNN feature extractori**
  * **SliÄnosne metrike (cross-correlation, event alignment)** za:

    * klasifikaciju (SVM, CNN)
    * klasteriranje
    * detekciju pokreta (motion estimation)
* U **neuroscience** zajednici postoje i metriÄki pristupi koji rade direktno na *spikeovima* â€” bez konverzije u slike.

---

### ğŸ”¹ 7. Deep Learning pristupi

* Koriste **DNN** nad razliÄitim reprezentacijama:

  * event images
  * time surfaces (TS)
  * voxel grids
  * point sets
* **Primjene:**

  * klasifikacija
  * rekonstrukcija slike
  * predikcija kuta upravljanja (steering angle)
  * optical flow, depth, ego-motion estimacija
* **Supervizirano uÄenje:**

  * koriste *ground truth* (npr. pozu kamere, grayscale sliku)
  * mjere *photoconsistency*
* **Nesupervizirano uÄenje:**

  * koristi samo input evente (nema oznaka)
  * loss funkcije za to su istraÅ¾ene u [99]
* **Arhitektura:**

  * najÄeÅ¡Ä‡e *encoder-decoder*
  * koristi samo konvolucije (manje parametara)
  * gubitak (loss) se moÅ¾e primijeniti na svaku razinu dekodera.

---

### ğŸ”¹ 8. Motion Compensation

* **Ideja:** pronaÄ‡i parametre gibanja koji najbolje "poravnaju" skup eventa u vremenu.
* **Prednost:** koristi *kontinuirani vremenski model* â€” iskoriÅ¡tava visoku temporalnu rezoluciju senzora.
* **Primjene:**

  * ego-motion estimacija
  * optical flow
  * procjena dubine
  * segmentacija pokreta
  * feature motion za VIO (Visual-Inertial Odometry)
* **Algoritmi:** koriste optimizacijske metode kao Å¡to su **Gauss-Newton** i **Conjugate Gradient**.

---

### ğŸ”¹ 9. Odabir veliÄine grupe eventa

* KljuÄni **hiperparametar** â€“ koliko eventa ulazi u jednu grupu.
* **Strategije odabira:**

  1. **Fiksni broj eventa**
  2. **Fiksno vrijeme promatranja** (konstantni frame rate)
  3. **Adaptivni pristupi** â€” npr. threshold prema gustoÄ‡i eventa u regiji.
* **Trade-off:**

  * Fiksni broj eventa = jednostavno, ali ne uzima u obzir varijacije po slici.
  * Fiksno vrijeme = broj eventa se mijenja (nekad premalo, nekad previÅ¡e).
  * Adaptivno = najbolje rjeÅ¡enje, ali sloÅ¾enije za dizajnirati.

---

* Dizajn event kamera temelji se na bioloÅ¡kim principima i raÄunalnim primitivima, poput Spiking Neural Networks (SNN).
* DVS (Dynamic Vision Sensor) je inspiriran bioloÅ¡kim vizualnim putevima, posebno â€œtransientâ€ (privremenim) putevima koji obraÄ‘uju dinamiÄke vizualne informacije u â€œwhereâ€ (gdje) putu.
* Transient put postoji kod mnogih Å¾ivotinja, ukljuÄujuÄ‡i ljude, i Äini oko 30% ljudskog vizualnog sustava.
* PoÄinje s transient ganglijskim stanicama u retini (izvan fovee), zatim prolazi kroz magno slojeve talamusa i pod-slojeve podruÄja V1, te zavrÅ¡ava u podruÄjima MT i MST (dio dorzalnog puta, povezanog s prepoznavanjem pokreta).
* DVS senzor odgovara dijelu tog transient puta do razine retinalnih ganglijskih stanica.
* ATIS (senor koji biljeÅ¾i i svjetlinu) generira grayscale dogaÄ‘aje koji odgovaraju â€œsustainedâ€ ili â€œwhatâ€ (Å¡to) putu kroz parvo slojeve mozga.

Transient - dio vizualnog sustava koji reagira na brze promjene i pokret u vidnom polju; obraÄ‘uje dinamiÄke informacije poput gibanja ili promjene kontrasta; brza, ali kratkotrajna reakcija.
Fovea - srediÅ¡nji dio mreÅ¾nice oka gdje je vidna oÅ¡trina najveÄ‡a; sadrÅ¾i gusto rasporeÄ‘ene ÄunjiÄ‡e koji detektiraju boje; odgovorna za detaljno i precizno gledanje.
Magno slojevi talamusa - dio lateralnog genikulatnog tijela (LGN) u talamusu; obraÄ‘uju informacije o pokretu, kontrastu i svjetlini; povezani su s transient putem (gdje put).
V1 - primarno vidno podruÄje u okcipitalnom reÅ¾nju mozga; prvi korak obrade vizualnih informacija iz oka; analizira osnovne znaÄajke slike kao Å¡to su rubovi, orijentacija i smjer kretanja.
MT - podruÄje srednjeg temporalnog reÅ¾nja (Middle Temporal area); specijalizirano za percepciju kretanja; sadrÅ¾i stanice osjetljive na smjer i brzinu gibanja.
MST - podruÄje medijalno od MT (Medial Superior Temporal area); obraÄ‘uje sloÅ¾enije oblike kretanja poput rotacije, ekspanzije i optiÄkog toka (npr. kretanje kroz prostor).
Ganglijske stanice - stanice mreÅ¾nice koje primaju signale od fotoreceptora (ÄunjiÄ‡a i Å¡tapiÄ‡a) i prosljeÄ‘uju ih mozgu putem vidnog Å¾ivca; postoje razliÄiti tipovi (npr. transient i sustained).
What put - ventralni (Å¡to) vizualni put; obraÄ‘uje informacije o obliku, boji i identitetu objekata; odgovoran za prepoznavanje i kategorizaciju onoga Å¡to vidimo.
Parvo slojevi mozga - parvocelularni slojevi LGN-a u talamusu; prenose informacije o boji i finim detaljima slike; povezani s what putem i sporijom, ali preciznijom obradom.

Umjetni neuroni, poput Leaky-Integrate and Fire ili Adaptivnih Eksponencijalnih su inspirirani neuronima pronaÄ‘enima u vizualnom kortexu sisavaca
Oni su osnovne gradivne jedinice SNN-ova
Neuron prima input spikeove (evente) iz malog podruÄja vidokruga (receptive field)
Spikeovi modificiraju membranski potencijal i stvaraju output spike (action potencijal) kada napon nadmaÅ¡i threshold
Neuroni su povezani hijerarhijski i stvaraju SNN-ove
Spikeove mogu stvarati ili pikseli event kamere ili neuroni SNN-a

* Prvi slojevi vizualnih modela koriste receptive fields temeljene na **Difference of Gaussians** (osjetljivost na kontrast izmeÄ‘u srediÅ¡ta i okoline), **Gabor filterima** (osjetljivost na orijentirane rubove) ili njihovim kombinacijama.
* Kako informacija prolazi dublje kroz mreÅ¾u, receptive fields postaju **sve sloÅ¾eniji**.
* U umjetnim neuronskim mreÅ¾ama (ANN), obrada u unutarnjim slojevima Äesto se **aproksimira konvolucijom**.
* U umjetnim spiking neuronskim mreÅ¾ama (SNN), Äesto se pretpostavlja da neuron **ne generira izlazne spikeove** ako nije primio ulazne spikeove iz prethodnog sloja.
* Ta pretpostavka omoguÄ‡uje **preskakanje izraÄuna** za neaktivne neurone, Äime se poveÄ‡ava uÄinkovitost.
* Rezultat vizualne obrade u takvim sustavima pojavljuje se **gotovo istovremeno s podraÅ¾ajem**, za razliku od klasiÄnih CNN-ova gdje se konvolucije raÄunaju istodobno u svim toÄkama i u fiksnim vremenskim intervalima.

* Bio-inspirirani modeli koriste se za **niz niskorazinskih vizualnih zadataka**.
* **Event-based optical flow** moÅ¾e se izraÄunati pomoÄ‡u **spatio-temporalno orijentiranih filtera** koji oponaÅ¡aju rad receptive fields u primarnom vidnom korteksu.
* Ti isti filteri koriste se i za **spike-based modele selektivne paÅ¾nje**, temeljene na bioloÅ¡kim principima.
* **Modeli inspirirani binokularnim vidom** (s rekurzivnim lateralnim vezama te ekscitacijsko-inhibicijskim neuronskim vezama) primijenjeni su za **event-based stereo korespondenciju** i **kontrolu konvergencije oÄiju kod humanoidnih robota**.
* Vizualni korteks posluÅ¾io je kao inspiracija za **hijerarhijski model ekstrakcije znaÄajki**, implementiran u SNN-ovima i koriÅ¡ten za **prepoznavanje objekata**.
* UÄinkovitost takvih mreÅ¾a raste ako **bolje iskoriÅ¡tavaju precizno vremensko usklaÄ‘ivanje spikeova**.
* Rani modeli bili su **ruÄno dizajnirani** (npr. pomoÄ‡u Gabor filtera), dok noviji koriste **uÄenje temeljeno na STDP-u (Spike-Timing Dependent Plasticity)** za samostalno formiranje receptive fields, Å¡to daje bolje rezultate.
* Novija istraÅ¾ivanja ukljuÄuju i **supervizirane metode uÄenja** poput **backpropagationa** za implementaciju **spiking dubokih konvolucijskih mreÅ¾a**.
* Prednosti bio-inspiriranih metoda u odnosu na klasiÄne: **niÅ¾a latencija** i **veÄ‡a uÄinkovitost**.
* **Vid kukaca** takoÄ‘er je izvor inspiracije â€” razvijeni su **event-based sustavi za izbjegavanje prepreka i brzo prepoznavanje meta** u malim robotima, temeljeni na neuronima koji reagiraju na nadolazeÄ‡e objekte i pokreÄ‡u **reflekse izbjegavanja**.


Primjene:
	Low-level:
		- detekcija znaÄajki
		- praÄ‡enje objekata
		- optical flow estimation
	3d scene structure related:
		- procjena dubine
		- vizualna odometrija
		- intensity image reconstruction
	Higher-level:
		- segmentacija gibanja
		- prepoznavanje i povezivanje percepcije s kontrolom pokreta
		
* **Detekcija i praÄ‡enje znaÄajki** kljuÄni su elementi mnogih vizualnih zadataka poput **vizualne odometrije** (Odometrija je metoda za **mjerenje prijeÄ‘enog puta i poloÅ¾aja u prostoru** na temelju informacija o **kretanju senzora ili kamere**.

U kontekstu **vizualne odometrije**, to znaÄi da se **raÄuna koliko se kamera (ili robot) pomaknula** analizom promjena u slikama â€” dakle, prati se kako se toÄke u okolini pomiÄu izmeÄ‘u kadrova ili dogaÄ‘aja, pa se iz toga procijeni **putanja i orijentacija**.
), **segmentacije objekata** i **razumijevanja scene**.
* **Event kamere** omoguÄ‡uju **asinkrono praÄ‡enje** koje se prilagoÄ‘ava dinamici scene, uz **nisku latenciju**, **velik dinamiÄki raspon** i **malu potroÅ¡nju energije**.
* Time se omoguÄ‡uje **praÄ‡enje i tijekom â€œslijepog vremenaâ€** izmeÄ‘u okvira standardne kamere.
* Za to je potrebno razviti metode koje uzimaju u obzir **prostorno-vremenske** i **fotometrijske** karakteristike event podataka, jer oni biljeÅ¾e samo **promjene svjetline**.
* **Glavni izazovi:**

  * Promjene u izgledu scene uzrokovane **ovisnoÅ¡Ä‡u o smjeru gibanja**, Å¡to oteÅ¾ava detekciju i praÄ‡enje znaÄajki.
  * Potreba za **povezivanjem dogaÄ‘aja kroz vrijeme** (data association) unatoÄ promjenama izgleda.
  * **Å um senzora** i **event clutter** (viÅ¡ak dogaÄ‘aja) uzrokovan **pokretom kamere**.

* **Rani event-based algoritmi** za detekciju znaÄajki bili su vrlo jednostavni i sluÅ¾ili su za demonstraciju **niske latencije** i **male raÄunske sloÅ¾enosti** event sustava.
* Pretpostavljali su **statiÄnu kameru** i pratili **pokretne objekte** kao skupove dogaÄ‘aja (blobs), **krugove** ili **linije**.
* Obrada se radila samo na pikselima koji su generirali dogaÄ‘aje.
* **Gaussian filteri** i **mjeÅ¡avine Gaussovih funkcija** koristili su se za detekciju i praÄ‡enje takvih blobova.
* Svaki novi dogaÄ‘aj bio je **povezan s najbliÅ¾im postojeÄ‡im blobom** i asinkrono je **aÅ¾urirao njegove parametre** (poziciju, veliÄinu, itd.).
* Ovi pristupi koriÅ¡teni su u **nadzoru prometa**, **praÄ‡enju robota visoke brzine** i **praÄ‡enju Äestica u tekuÄ‡inama ili mikrorobotici**, ali su **ograniÄeni na jednostavne oblike**.
* Kasnije su razvijene metode za **praÄ‡enje sloÅ¾enijih, visokokontrastnih oblika**, temeljene na algoritmima kao Å¡to su **ICP (Iterative Closest Point)**, **gradient descent**, **Mean-Shift**, **Monte Carlo metode** i **particle filtering**.
* **Iterativne metode** (npr. ICP) koristile su **najbliÅ¾eg susjeda** za povezivanje dogaÄ‘aja s ciljanim oblikom i aÅ¾uriranje njegove transformacije, omoguÄ‡ujuÄ‡i **vrlo brzo praÄ‡enje (do 200 kHz)**.
* Drugi radovi koristili su **rotirane i skalirane verzije oblika (kernels)** s ugraÄ‘enim mehanizmom **odbijanja** kako se ne bi preklapali.
* **SloÅ¾eni objekti** poput lica ili tijela praÄ‡eni su pomoÄ‡u **modela sastavljenih od viÅ¡e dijelova** povezanih elastiÄnim â€œopruÅ¾nimâ€ vezama koje simuliraju fiziÄki sustav.
* VeÄ‡ina metoda tretira dogaÄ‘aje kao **pojedinaÄne toÄke bez polariteta** i aÅ¾urira stanje sustava **asinkrono**, s vrlo **malom latencijom**.
* UspjeÅ¡nost metoda ovisi o **finoj prilagodbi parametara**, koji se obiÄno podeÅ¡avaju **eksperimentalno** za odreÄ‘eni objekt.
* Ove metode traÅ¾e **prethodno znanje ili korisniÄki unos** o tome Å¡to se prati, Å¡to je pogodno za specifiÄne zadatke (npr. automobili ili lopte), ali nije praktiÄno za opÄ‡enite scene.
* Noviji pristupi definiraju **realistiÄnije znaÄajke** temeljene na **lokalnim rubnim uzorcima** (edge patterns), predstavljene kao skupovi toÄaka.
* Dolazni dogaÄ‘aji se s njima **usklaÄ‘uju pomoÄ‡u ICP-a**.
* Neki pristupi koriste **klasiÄne detektore i trackere** na **motion-compensated event slikama**, Å¡to daje dobre rezultate u prirodnim scenama i omoguÄ‡uje **procjenu vlastitog gibanja (ego-motion)**.
* ZnaÄajke izvedene iz **motion-compensated dogaÄ‘aja** pruÅ¾aju dobru reprezentaciju rubova, ali su **ovisne o smjeru kretanja**, pa s vremenom dolazi do **drifta (odmicanja praÄ‡enja)**.
* Za **praÄ‡enje bez drifta** potrebne su **motion-invariant znaÄajke** koje nisu osjetljive na promjenu smjera kretanja.



* **Kombinacija dogaÄ‘aja i frameova** (npr. kod senzora poput **DAVIS-a**) omoguÄ‡uje **jednostavnije povezivanje podataka (data association)**, jer su dostupne **apsolutne vrijednosti svjetline** â€” dakle, â€œmapaâ€ znaÄajke ne ovisi o smjeru kretanja.
* Ovi pristupi koriste **prednosti oba svijeta**: stabilnost i kontekst frameova + brzinu i nisku latenciju event podataka.
* Algoritmi automatski **detektiraju rubne uzorke (edge patterns)** na frameovima, a zatim ih **asinkrono prate dogaÄ‘ajima**.
* **Pozicija znaÄajke** dobiva se pomoÄ‡u **Harris corner detektora**, a **deskriptor znaÄajke** temelji se na **rubovima oko tog kuta**.
* U nekim metodama (npr. [125], [126]) **Canny rubovi** se pretvaraju u **skupove toÄaka (templates)** koje se koriste za **ICP praÄ‡enje** â€” pretpostavlja se da se dogaÄ‘aji javljaju **na jakim rubovima**.
* U radu [64], rubni uzorci se temelje izravno na **intenzitetima framea**, a praÄ‡enje se provodi tako da se traÅ¾e **parametri gibanja** koji **minimiziraju fotometrijsku pogreÅ¡ku** izmeÄ‘u dogaÄ‘aja i predviÄ‘ene slike iz generativnog modela.
* Usporedba pet metoda praÄ‡enja (iz [64]) pokazuje da **generativni model** daje **najveÄ‡u toÄnost (Äak i sub-pikselnu)**, ali je **raÄunski zahtjevan**.
* KljuÄno otkriÄ‡e: **frameovi nisu nuÅ¾ni** â€” mogu se **rekonstruirati iz samih dogaÄ‘aja**, a rezultati detekcije i praÄ‡enja ostaju **gotovo jednako dobri**.

Ukratko:
â†’ **Spajanje event + frame podataka** daje toÄno, robusno i brzo praÄ‡enje znaÄajki.
â†’ **Generativni pristupi** nude najbolju preciznost.
â†’ **Event-only sustavi** mogu postiÄ‡i sliÄne rezultate rekonstrukcijom frameova iz dogaÄ‘aja â€” Å¡to otvara put potpuno **frame-free sustavima**.

* **Event kamere** prirodno reagiraju na **rubove** u sceni, Å¡to ubrzava **detekciju niÅ¾erazinskih znaÄajki** poput **kljuÄnih toÄaka (keypoints)** ili **kutova (corners)**.
* Takve toÄke omoguÄ‡uju **pouzdano praÄ‡enje** jer ne pate od **aperture problema** i sluÅ¾e kao lokalni orijentiri za ekstrakciju znaÄajki.
* Metoda iz [186] detektira kutove kao **sjeciÅ¡ta dvaju pokretnih rubova**, dobivenih **aproksimacijom ravnina** u **prostorno-vremenskom toku dogaÄ‘aja**.

  * Za ublaÅ¾avanje Å¡uma koristi se **least-squares + RANSAC-sliÄna metoda uzorkovanja**.
  * Ta lokalna aproksimacija ravnina korisna je i za **procjenu optiÄkog toka** i **trajanja dogaÄ‘aja** (event lifetime).
* Razvijene su i **event inaÄice poznatih detektora kutova**, poput **Harris** i **FAST**, koje rade nad **time surface (TS)** reprezentacijom dogaÄ‘aja.

  * U [114] se **TS binarizira**, pa se na nju primjenjuju **derivacijski filtri Harris detektora**.
  * U [115] se derivacijski filtri zamjenjuju **piksel-po-piksel usporedbama** na **dvije koncentriÄne kruÅ¾nice** oko dogaÄ‘aja; kutovi se detektiraju tamo gdje **TS pokazuje dvije odvojene regije** (nova vs. stara dogaÄ‘anja).
* **[111]** poboljÅ¡ava ovaj pristup i uvodi **praÄ‡enje kutova** â€” pretpostavlja da kutovi prate **kontinuirane putanje**, a povezuju se po **blizini** pomoÄ‡u **grafova hipoteza**.
* Glavni problem TS-baziranih metoda: **ovisnost o smjeru gibanja**, jer promjena smjera mijenja izgled TS-a.
* **[112]** uvodi **data-driven pristup** â€” uÄi izgled TS-a za kutove koristeÄ‡i **nadzirano uÄenje** (labeliranje prema sivim slikama iz DAVIS/ATIS kamere).

  * Kao kompromis izmeÄ‘u toÄnosti i brzine koristi se **random forest klasifikator**.
* **Kutovi iz dogaÄ‘aja** imaju praktiÄne primjene u **vizualnoj odometriji** i **segmentaciji vlastitog gibanja (ego-motion segmentation)**, iako ih je zasad **relativno malo primijenjenih rjeÅ¡enja**.

* Opisane metode zahtjevaju da toÄno znamo Äa pratimo + joÅ¡ se traÅ¾i neki standardni naÄin evaluacije performansi

Optical flow estimation
IzraÄun brzine objekata na image planeu bez da znamo iÅ¡ta o geometriji scene ili samom kretanju objekta
PokuÅ¡ava izraÄunati brzinu kretanja piksela izmeÄ‘u 2 framea (kako se svjetlina piksela mijenja)
Problem: samo iz promjene svjetline ne moÅ¾emo znati kako se objekt stvarno kreÄ‡e
Ne znamo stvarnu brzinu ni smjer (aperture problem)
Treba nam neka regularizacija (npr. pretpostavka da se susjedni pikseli miÄu sliÄnu, da se brzina glatko mijenja, da se svjetlina ne mijenja tijekom kretanja itd.)

Kod standardnih frame based kamera optical flow saznajemo iz analize 2 uzastopna framea (dobijemo prostorne (promjena svjetline u prostoru) i vremenske derivacije(promjena svjetline u vremenu))
U kombinaciji s:

Pretpostavkom konstantne svjetline (brightness constancy assumption - piksel zadrÅ¾ava istu svjetlinu dok se kreÄ‡e)

Pretpostavkom glatkoÄ‡e (susjedni pikseli imaju sliÄan flow)

Daje dovoljno jednadÅ¾bi za izraÄun flowa u svakoj toÄki slike.

Event kamere:

Ne daju apsolutnu svjetlinu â€” samo dogaÄ‘aje (evente) kad se promijeni svjetlina.

Podaci nisu kontinuirani u prostoru â€” samo diskretni eventi (x, y, t, polaritet).

Jedan event sam po sebi ne nosi dovoljno informacija da se izraÄuna flow.
MoraÅ¡ grupirati viÅ¡e evenata (u vremenu i prostoru) da dobijeÅ¡ procjenu smjera i brzine.

Postavlja se pitanje:
â€œGdje u x-y-t prostoru uopÄ‡e raÄunati flow?â€

Idealno: flow polje kroz cijeli prostor (skupo!).

U praksi: raÄuna se na lokacijama evenata ili na umjetno odabranim vremenskim presjecima.

Prednosti event-based flowa:

Eventi predstavljaju rubove (edges) â€” mjesta gdje je kretanje najmanje dvosmisleno.

Imaju vrlo precizno vremensko oznaÄavanje (timestamp) â†’ mogu mjeriti vrlo brze pokrete.

Cilj istraÅ¾ivanja:
Napraviti bioloÅ¡ki plauzibilan algoritam, tj. da imitira obradu pokreta u vizualnom korteksu primata (V1, MT) i da se moÅ¾e efikasno izvesti na neuromorfnom hardveru.

Raniji radovi pokuÅ¡avali su primjeniti klasiÄne CV pristupe na event based podatke
Utemeljeno na pretpostavci o konstantnom osvjetljenju
Diskusija o tome imaju li pojedini eventi u sebi dovoljno info. za procjenu flowa

---

##  **Optical Flow u event-based viziji â€” saÅ¾etak kljuÄnih ideja**

---

###  **1. Osnovni problem**

* Cilj: IzraÄunati **brzinu kretanja objekata** u ravnini slike â€” **bez poznavanja geometrije scene**.
* Problem je **ill-posed** â†’ nema dovoljno informacija, pa se mora **regularizirati** (dodati pretpostavke).

---

###  **2. Razlike naspram klasiÄnih metoda**

* KlasiÄne metode koriste **prostorne i vremenske derivacije svjetline (Lx, Ly, Lt)** i **pretpostavku konstantne svjetline**.
* Kod **event kamera**, nema apsolutne svjetline ni kontinuiranih podataka â†’ teÅ¡ko je dobiti stabilne derivacije.
* RjeÅ¡enje: **agregirati viÅ¡e evenata** kroz prostor i vrijeme da bi se procijenio pokret.

---

###  **3. Geometrijski pristupi â€” timesurface & plane fitting (npr. metoda [21])**

* Promatra se **lokalna distribucija evenata** u 3D prostoru (x, y, t).
* Kako se rub (edge) miÄe, generira **timesurface** (povrÅ¡inu u prostoru-vremenu).
* **Nagib povrÅ¡ine (slope)** u x-t i y-t presjecima daje smjer i brzinu kretanja.
* Flow se raÄuna **fittingom ravnine (plane fitting)** na lokalni skup evenata â†’ koeficijenti ravnine = komponente brzine.
* Dobiva se **normalni flow** (okomit na rub).
* Kvaliteta ovisi o veliÄini lokalne regije:

  * premala â†’ nepouzdan fit
  * prevelika â†’ gubi se lokalnost.

---

###  **4. BioloÅ¡ki inspirirani pristupi**

* Metoda inspirirana **vizualnim sustavom primata** (V1â€“MT).
* Koristi **spatio-temporalne filtre** (poput **Gabor filtera**) za detekciju:

  * razliÄitih **brzina** i **smjerova** gibanja
  * uz **rijetku (sparse)** reprezentaciju evenata.
* Filtri djeluju kao **korelacijski detektori pokreta**.
* Primjeri:

  * SNN s **odgodom signala** kroz sinapse â†’ neuroni kao **coincidence detektori**

    * osjetljivi na **8 brzina Ã— 8 smjerova = 64 vektora brzina**
    * receptive field: 5Ã—5 piksela
    * moguÄ‡e implementirati na **neuromorfnom hardveru** (low-power, real-time)
  * postoji i metoda koja koristi **STDP (Spike-Timing-Dependent Plasticity)** za *uÄenje filtera iz event podataka*
  * u drugim metodama postoje ruÄno dizajnirani filteri, ali konceptualno jednaki princip.

---

###  **5. Gabor + Event frame pristupi (klasiÄna signalna obrada)**

* Metoda:

  * Pretvara evente u **event frame** (projekciju dogaÄ‘aja).
  * Primjenjuje **Gabor filter bank** â†’ dobiva **fazu**.
  * Optical flow = **gradijent faze** filter banke.
  * OgraniÄenje: moÅ¾e izraÄunati samo **komponentu brzine u smjeru gradijenta** (zbog aperture problema).

---

###  **6. Kombinirani pristupi â€” optical flow + druge veliÄine**

* metode procjenjuju optical flow **zajedno s intenzitetom slike** (brightness).

  * Koriste viÅ¡e jednadÅ¾bi (brightness constancy, smoothness, penalizacija, varijacijski pristup).
  * Cilj: pronaÄ‡i **flow + intenzitet** koji **najbolje objaÅ¡njava distribuciju evenata**.
  * Rezultat: **gusto (dense)** flow polje (vrijednost za svaki piksel).
  * Flow u zonama bez evenata je **manje pouzdan** (jer proizlazi samo iz glatkoÄ‡e).

---

###  **7. Block-matching pristupi (video encoding analogija)**

* raÄuna optical flow usporeÄ‘ujuÄ‡i **dva skupa evenata (â€œblokoveâ€)**.

  * Pretvara ih u **event frameove** na adaptivnoj stopi.
  * Mjeri sliÄnost blokova (npr. suma apsolutnih razlika).
  * Radi u stvarnom vremenu, moÅ¾e se implementirati na **FPGA-u** (velika efikasnost, manja preciznost).

---

###  **8. Motion compensation i â€œsharpness maximizationâ€**


  * Warpaju (transformiraju) *cuboid* evenata tako da budu oÅ¡triji (motion-compensated images).
  * Maksimiziraju **oÅ¡trinu slike** â†’ time pronalaze pravilan smjer gibanja.
  * PonaÅ¡aju se kao **adaptivni filteri** koji uÄe optimalnu spatio-temporalnu orijentaciju.

---

###  **9. Deep learning pristupi**

* Pojavom veÄ‡ih datasetova + DAVIS senzora:

  *  **Encoder-decoder CNN**, treniran **self-supervised**, koristi **time surfaces + event frames**.

    * Loss = greÅ¡ka izmeÄ‘u grayscale frameova poravnatih pomoÄ‡u predviÄ‘enog flowa.
    * MoÅ¾e predvidjeti gusti flow samo iz evenata.
  * prva **monokularna ANN arhitektura** koja istodobno uÄi:

    * **gusti optical flow**,
    * **dubinu (depth)** i
    * **ego-motion** (vlastito gibanje kamere).
    * Ulaz: viÅ¡eslojni eventi (frames + TS s prosjeÄnim timestampovima).
    * Trenirano **unsupervised**, koristi **motion compensation loss**.
  *  postoje i metode koje su takoÄ‘er unsupervised, ali koriste **time-surface loss**.

---

###  **10. Evaluacija & izazovi**

* Optical flow = **raÄunski skup zadatak**:

  * Deep metode â†’ zahtijevaju **GPU**.
  * LakÅ¡e metode â†’ **manje toÄne**, ali real-time.
* Nekoliko metoda je implementirano u **hardverskoj logici** za **minimalnu latenciju**.
* Nedostatak:

  * **Nema dovoljno datasetova s toÄnim ground truth flowom** u razliÄitim uvjetima (tekstura, brzina, parallax, svjetlo itd.).
  * TeÅ¡ko dobiti **realne ground truth podatke** â€” pogotovo za pokretne objekte koji se ne kreÄ‡u istim smjerom kao kamera.
* ZakljuÄak:

  * Potrebna **standardizacija evaluacijskih metoda** i **kvantitativna usporedba** postojeÄ‡ih pristupa.
  * Cilj: pronaÄ‡i kljuÄne ideje koje vode prema **efikasnijem i toÄnijem optical flowu iz evenata**.

---

3D rekonstrukcija (MONO I STEREO)
Firstly, zabija san koja je razlika izmeÄ‘u mono i stereo, pa Ä‡u pitat Gepetta

Monocular ANN (npr. [153]) â†’ koristi samo jedan event senzor, ali uÄi dubinu i pokret kroz vrijeme.

Stereo event kamera (npr. DVS stereo setup) â†’ koristi dva event senzora i moÅ¾e direktno dobiti disparity + depth iz sinkroniziranih evenata.

 Mono vs. Stereo u kontekstu kamera i vizije
 Monokularni sustav (mono)

Koristi jednu kameru.

Gleda svijet iz jedne perspektive â†’ nema direktnu informaciju o dubini (koliko je neÅ¡to daleko).

Sve Å¡to moÅ¾e vidjeti su projekcije 3D toÄaka na 2D sliku.

Da bi procijenio dubinu, mora â€œnagaÄ‘atiâ€ pomoÄ‡u:

gibanja kamere (motion parallax),

perspektive (veliÄine objekata),

nauÄenih uzoraka (deep learning).

TipiÄno koristi se kod:

ego-motion estimacije (koliko se kamera sama pomaknula),

monokularne depth estimacije (predviÄ‘a dubinu â€œnauÄenoâ€ iz podataka),

SLAM (monokularni varijant koristi samo jednu kameru i temporalne tragove).

 Ukratko: jeftinije, jednostavnije, ali dubina nije direktno mjerljiva â€” mora se procjenjivati.

 Stereoskopski sustav (stereo)

Koristi dvije kamere postavljene jedna pored druge (poput naÅ¡ih oÄiju ğŸ‘€).

Obje vide istu scenu iz malo razliÄitih kutova.

Time se moÅ¾e izraÄunati paralaksna razlika (disparity) â†’ razlika u poziciji iste toÄke na dvije slike.

Iz disparityja se izravno dobiva dubina (Z-koordinata) pomoÄ‡u jednostavne geometrije.

Stereo sustavi su idealni za:

depth map rekonstrukciju,

3D scene understanding,

autonomnu voÅ¾nju, robote itd.

 Ukratko: skuplje i sloÅ¾enije za kalibraciju, ali daju preciznu 3D dubinu u realnom vremenu.

 SaÅ¾etak razlika
ZnaÄajka	Monokularni	Stereoskopski
Broj kamera	1	2 (ili viÅ¡e)
Dubina	Neizravno, procjenjuje se	Izravno, iz geometrije
Kalibracija	Jednostavna	Potrebna precizna stereo kalibracija
TroÅ¡ak	Manji	VeÄ‡i
Primjeri upotrebe	Mobilni telefoni, monokularni SLAM	Autonomna vozila, 3D rekonstrukcija, industrijski roboti

Stereo direktno more skuÅ¾it dubinu, mono ne more nikako


---

###  **Instantaneous Stereo (s event kamerama)**

* Cilj: **Procjena dubine (3D rekonstrukcija)** pomoÄ‡u **dva ili viÅ¡e sinkroniziranih event kamera**.
* Rekonstrukcija se radi u **vrlo kratkom vremenu** â€” idealno **po svakom eventu**.
* Kamere su **rigidno spojene** i **sinkronizirane** â†’ dijele **zajedniÄki sat (clock)**.

---

### **KlasiÄna dvostupanjska stereo metoda:**

1. **Event correspondence problem** â€” pronaÄ‡i koji event s jedne kamere odgovara eventu s druge (tzv. **epipolar matching**).
2. **Triangulacija** â€” iz tih parova izraÄunati 3D poloÅ¾aj toÄke.

---

###  **Glavni izazov:**

* **PronalaÅ¾enje korespondencija** izmeÄ‘u eventova â†’ vrlo **raÄunalno zahtjevno**.

---

###  **NaÄini podudaranja (matching):**

* (i) KoriÅ¡tenje **klasiÄnih stereo metrika** poput:

  * *Normalized Cross-Correlation (NCC)*
  * primijenjeno na **event frameove** ili **time surfaces**.
* (ii) **IskoriÅ¡tavanje vremenske simultanosti i korelacija** izmeÄ‘u senzora.

---

###  **Dodatne znaÄajke metoda:**

* Pristup je **lokalan** â€” usporeÄ‘uju se **susjedstva eventova**, jer pojedini timestamp nije dovoljan za podudaranje.
* Dodaju se **ograniÄenja** kako bi se smanjila dvosmislenost:

  * **Epipolarno ograniÄenje**
  * **Redoslijed dogaÄ‘aja (ordering)**
  * **Jedinstvenost (uniqueness)**
  * **Orijentacija rubova (edge orientation)**
  * **Polarnost (polarity)**

---

###  **PoboljÅ¡anja:**

* Radi se i **usporedba lokalnih deskriptora** koji opisuju **prostornu raspodjelu eventova** na obje slike.

---
Global Approaches for Event-Based Stereo Depth Estimation
Osnovna ideja:

Globalni pristupi daju toÄnije i manje dvosmislene procjene dubine od lokalnih.

To postiÅ¾u dodavanjem regularizacijskih ograniÄenja (regularity constraints).

 KljuÄne metode i inspiracija:

Temelje se na proÅ¡irenju Marr & Poggio cooperative stereo algoritma za event kamere.

UkljuÄuju mreÅ¾u neurona osjetljivih na disparitet koji:

primaju evente s obje kamere

provode operacije poput pojaÄanja (amplification) i inhibicije (inhibition)

implementiraju ograniÄenja podudaranja:

jedinstvenost (uniqueness)

kontinuitet (continuity)

rezultat je globalno optimalno rjeÅ¡enje nakon iterativnih nelinearnih operacija.

 Ostale globalne metode:

KoriÅ¡tenje Belief Propagation na Markov Random Field (MRF) modelima.

Semi-global matching tehnike.

Sve se temelje na optimizaciji â€” definiranju energetske funkcije Äiji je minimum ispravna mapa korespondencija.

 Prednosti i kompromisi:

VeÄ‡a robusnost i manja osjetljivost na dvosmislenosti od lokalnih metoda.

Cijena: veÄ‡a raÄunalna sloÅ¾enost (viÅ¡e resursa i vremena).

 Ostali doprinosi i eksperimenti:

U [214] predloÅ¾en je brute-force space-sweeping pristup na GPU-u:

Dubina se oÄituje kao â€œin-focusâ€ voxeli u Disparity Space Image.

Drugi pristupi koriste neuromorfne procesore â†’ niska potroÅ¡nja (100 mW), visoka brzina (1 kHz).

JoÅ¡ nije kvantificiran trade-off izmeÄ‘u toÄnosti i efikasnosti.

 OgraniÄenja eksperimentalnih radova:

Testovi uglavnom na statiÄnim kamerama i jednostavnim scenama (malo pokretnih objekata).

Time se olakÅ¡ava traÅ¾enje korespondencija zbog manje â€œÅ¡umaâ€ u eventima.

 ZakljuÄak:

Event kamere omoguÄ‡uju brze (1 kHz), energetski uÄinkovite i precizne 3D rekonstrukcije,
posebno pogodne za pokretne objekte i nezaÄepljene (uncluttered) scene.

Multi-perspective panoramas:
Cilj: Instantaneous stereo â†’ dobivanje dubinskih mapa (depth maps) u vrlo kratkim vremenskim intervalima.

Razlika od standardnog instant stereo: kamere nisu sinkronizirane, tj. dogaÄ‘aji se ne biljeÅ¾e u isto vrijeme.

Metoda koristi kontrolirani hardverski setup: dvije rotirajuÄ‡e event kamere s poznatom putanjom/motion.

Takav setup omoguÄ‡uje:

(i) Rekonstrukciju intenzitetskih slika (brightness images)

Na tim slikama se zatim moÅ¾e primijeniti klasiÄni stereo algoritam.

Ukratko:
Umjesto dvije paralelne, sinkronizirane kamere, koristi se konfiguracija s rotacijom i poznatom putanjom kamera da bi se dobile dubinske informacije Äak i kad kamere ne snimaju u isto vrijeme. Ovo omoguÄ‡uje panoramske i multi-perspektivne dubinske rekonstrukcije.

Monocular depth estimation
Koristi se 1 event kamera
Ne moÅ¾e se uoÄiti temporal correlation izmeÄ‘u evenata kroz viÅ¡e image planesa
Potrebna je semi-dense 3d rekonstrukcija scene (3D edge map) => intergracija informacija iz evenata dobivenih iz kamere koja se micala kroz vrijeme (zato nam treba info o tome kako se kamera micala)
Kombinacija: pozicija event kamere + 3d mapa scene + intenzitet slike

Intenzitet slike (brightness image) nije neÅ¡to Å¡to event kamera izravno biljeÅ¾i u obliku â€œklasiÄne slikeâ€ (jer ona registrira samo promjene svjetline, tj. evente).

Ovdje intenzitet slike znaÄi aproksimaciju ili rekonstruiranu sliku svjetline scene u tom trenutku, koju se moÅ¾e koristiti za klasiÄne stereo algoritme.

Drugim rijeÄima:

Eventi daju samo promjene svjetline (delta),

Pozicija kamere + prethodni eventi + model scene â†’ moÅ¾e se â€œnapunitiâ€ slika s intenzitetom piksela koja je najbliÅ¾a onome Å¡to bi obiÄna kamera snimila.

Ta rekonstruirana slika ne prikazuje pokrete kao dogaÄ‘aje, veÄ‡ apsolutnu svjetlinu svakog piksela, Å¡to omoguÄ‡uje primjenu klasiÄnih stereo metoda (poput epipolar matching, block matching).

Ukratko: intenzitet slike = rekonstruirana â€œklasiÄnaâ€ slika iz event streama, koja sadrÅ¾i apsolutnu svjetlinu piksela za trenutni snapshot scene.

* **Stereo Depth za SLAM:**

  * Nova metoda inspirirana **small-baseline multi-view stereo**.
  * Dobiva **semi-dense 3D rekonstrukciju scene** optimiziranjem **lokalne spatio-temporalne konzistentnosti eventa** preko slika (time surfaces).
  * Ne koristi klasiÄni pristup **event matching + triangulacija**, veÄ‡ **forward-projection** za procjenu dubine bez eksplicitnih korespondencija eventa.
  * OmoguÄ‡uje primjenu prednosti **event kamera u stereo SLAM** sustavima, npr. autonomna vozila.

* **Procjena dubine koristeÄ‡i strukturirano svjetlo (Structured Light):**

  * Aktivne metode: emitiraju svjetlo i mjere refleksiju event kamerom.
  * Primjer: **DVS + pulsni laserski linijski skener** â†’ brza 3D rekonstrukcija terena (3D line scanner).
  * **Motion Contrast 3D scanning:** visoka rezolucija, brzina i robusnost u izazovnim uvjetima (jako osvjetljenje, reflektivne ili pokretne povrÅ¡ine).
  * Aktivni sustavi koriste **visoku vremensku rezoluciju i suppression redundancije** event kamera.
  * OgraniÄenje: specifiÄne primjene i moguÄ‡e sigurnosne zabrane (ovisno o laserskoj snazi).

* **Opportunities / izazovi:**

  * TeÅ¡ko je usporediti metode jer nisu evaluirane na istim datasetovima.
  * Potrebno:

    * Sveobuhvatan **dataset i testbed** za event-based depth evaluaciju.
    * Benchmarking postojeÄ‡ih metoda radi usporedbe performansi.


* **Izazov:**

  * Konvencionalne metode za kamere (feature detection, matching, iterative alignment) **ne rade** s event kamerama.
  * Potrebno je razviti **nove SLAM tehnike** koje koriste prednosti event kamera: **niska latencija, asinkrono aÅ¾uriranje stanja** po svakom eventu.

* **Karakteristike event-based SLAM:**

  * Svaki event **ne sadrÅ¾i dovoljno informacija** za procjenu stanja od nule (npr. 6-DOF kamera).
  * Cilj: svaki event **asinkrono aÅ¾urira stanje sustava**.
  * Popularni pristupi: **probabilistiÄki/Bayesian filtri**, prilagoÄ‘eni event generation procesu.

* **Mapiranje scene:**

  * VeÄ‡ina mapa iz event-based SLAM sustava su **semi-dense maps** â†’ samo rubovi scene.
  * Event kamera mjeri **temporalne promjene**, ne direktno intenzitet.
  * Potrebno je **procijeniti prisutnost, orijentaciju i jaÄinu rubova** zajedno s kretanjem kamere.
  * JaÄina intenziteta rubova korelira s **firing rate** eventa â†’ pouzdano praÄ‡enje.

* **Kompleksnost problema:**

  * Tri osi kompleksnosti:

    1. **Dimenzionalnost problema** (3-DOF vs. 6-DOF)
    2. **Tip kretanja** (rotacija, planarno, slobodno 6-DOF)
    3. **Tip scene** (umjetna vs. prirodna, photometry i struktura)
  * Literaturu dominiraju metode koje prvo rjeÅ¡avaju **lokalizaciju/motion estimation**, jer je jednostavnija.
  * Neke metode zahtijevaju dodatne senzore (RGB-D), ali to uvodi **latenciju i motion blur**.

* **Cilj istraÅ¾ivanja:**

  * Postepeno rjeÅ¡avanje problema s **rastom kompleksnosti** scena i kretanja.
  * Razvoj metoda koje omoguÄ‡uju **full 6-DOF SLAM u prirodnim 3D scenama** koristeÄ‡i event kamere.

Radi se o **praÄ‡enju poloÅ¾aja (pose tracking)** pomoÄ‡u **event kamera**.
Cilj je znati **kako se kamera (ili robot) kreÄ‡e kroz prostor**, koristeÄ‡i samo dogaÄ‘aje (events) umjesto obiÄnih frameova.

---

### ğŸ“˜ Glavne metode iz teksta

1. **Prva metoda ([101])**

   * Koristi **particle filter** (statistiÄki model) za praÄ‡enje kretanja robota.
   * Scena je **plosnata (planarna)** i sadrÅ¾i **crno-bijele linije**.
   * Glavna inovacija: **likelihood funkcija** raÄuna vjerojatnost da su detektirani eventi u skladu s trenutnim poloÅ¾ajem robota.
   * To radi usporedbom izmeÄ‘u **mjesta eventa i najbliÅ¾eg ruba** u mapiranoj sceni (reprojection error).

2. **Druga metoda ([75])**

   * Kombinira **standardnu grayscale kameru** i **DVS (event kameru)**.
   * Koristi **Bayesov filter** za procjenu malih pomaka izmeÄ‘u dogaÄ‘aja i prethodnog framea s obiÄne kamere.
   * OgraniÄeno na **planarno kretanje** i **crno-bijele scene**.
   * Likelihood funkcija proporcionalna je **jaÄini gradijenta slike** na lokaciji eventa â†’ Å¡to je jaÄi rub, veÄ‡a vjerojatnost da event ima smisla.

3. **TreÄ‡a metoda ([227])**

   * Radi **pose tracking** pod **planarnim i ne-holonomnim kretanjem** (znaÄi kretanje s ograniÄenjima, kao auto ili robot s kotaÄima).
   * PodrÅ¾ava **loop closure** (zatvaranje petlje) i **topoloÅ¡ki toÄne trajektorije**.
   * Pretvara **evente u frameove** i onda koristi klasiÄni **SeqSLAM** algoritam (poznat iz vizualne navigacije) da prepozna poznate lokacije.

---

### ğŸ§  Ukratko u 3 natuknice:

* Sve metode pokuÅ¡avaju **procijeniti poloÅ¾aj kamere (pose)** koristeÄ‡i **evente umjesto klasiÄnih frameova**.
* Koriste **statistiÄke filtre (particle / Bayesian)** i pametno dizajnirane **likelihood funkcije** koje procjenjuju koliko su eventi konzistentni s mapom.
* Neke metode Äak **kombiniraju event kameru s obiÄnom kamerom** ili **pretvaraju evente u frameove** da iskoriste postojeÄ‡e SLAM tehnike (npr. SeqSLAM).

---

znaÄi mi imamo k dogaÄ‘aja i njihove pozicije i cilj je skuÅ¾iti kako se objekt kretao na temelju promjene poloÅ¾aja dogaÄ‘aja?

Bravo! ğŸ’¥ ToÄno to!
Pogodio si srÅ¾ cijelog koncepta **pose trackinga s event kamerama**.

Event kamera ti ne daje frameove kao klasiÄna kamera, nego niz **dogaÄ‘aja (events)**:
ğŸ‘‰ svaki event = `(x, y, t, polarity)` â†’ lokacija piksela, vrijeme, i smjer promjene svjetline.

---

### ğŸ” Cilj:

Na temelju **tih dogaÄ‘aja kroz vrijeme** Å¾eliÅ¡ **procijeniti kako se kamera (ili objekt) pomicala**.
Drugim rijeÄima, gledaÅ¡ **kako se uzorak dogaÄ‘aja â€œpomaknuoâ€** izmeÄ‘u trenutaka â†’ to ti otkriva **translaciju, rotaciju i orijentaciju** kamere.

---

### ğŸ§© Kako to funkcionira (intuicija):

1. **Eventi nastaju kad se neÅ¡to pomakne** â†’ znaÄi dogaÄ‘aji veÄ‡ implicitno sadrÅ¾e info o pokretu.
2. Ako imaÅ¡ **mapu scene** (npr. gdje su rubovi, linije, kontrasti), moÅ¾eÅ¡ izraÄunati:

   * Ako je kamera bila na poziciji A i sada vidi dogaÄ‘aje na poziciji B â†’ pomak je Î”pose.
3. KoristiÅ¡ **matematiÄki model** (npr. particle filter, Kalman filter ili Bayesian filter) da testiraÅ¡:

   * "Ako pretpostavimo da se kamera pomaknula ovako, koliko bi vjerojatno generirala baÅ¡ ove evente?"
   * To je tzv. **likelihood funkcija**.
4. Na temelju toga se **aÅ¾urira procjena poloÅ¾aja (pose)**.

---

### âš™ï¸ U praktiÄnim terminima:

* ImaÅ¡ niz dogaÄ‘aja `[(x1, y1, t1), (x2, y2, t2), ..., (xk, yk, tk)]`.
* Cilj je pronaÄ‡i **trajektoriju kamere** koja **najbolje objaÅ¡njava** gdje i kada su ti dogaÄ‘aji nastali.

---

### ğŸš Primjena (npr. u dronu):

* Dron leti iznad tla s uzorkom (npr. crne linije).
* Kamera biljeÅ¾i dogaÄ‘aje svaki put kad linija proÄ‘e ispod nekog pixela.
* Iz pomaka tih dogaÄ‘aja kroz vrijeme, dron moÅ¾e **procijeniti vlastitu brzinu, smjer i rotaciju** â€“ bez klasiÄne kamere i frameova!

---

PokuÅ¡avaju procijeniti orijentaciju (rotaciju) kamere samo iz dogaÄ‘aja, bez frameova.

Koriste particle filter, minimizaciju photometric errora i motion compensation optimizaciju.

OgraniÄeni su na rotacijsko gibanje, ali su vaÅ¾ni jer otvaraju put prema punim 3D motion estimation metodama.

---

### ğŸ”¹ 1. **Particle filter**

* Radi se o **probabilistiÄkom pristupu** â€” umjesto da izraÄunaÅ¡ toÄno rjeÅ¡enje, generiraÅ¡ **viÅ¡e moguÄ‡ih hipoteza** (tzv. Äestice = â€œparticlesâ€) o poloÅ¾aju/orijentaciji kamere.
* Svaka Äestica ima svoju â€œvjerojatnostâ€ da predstavlja stvarni poloÅ¾aj kamere.
* Likelihood funkcija govori koliko se dobro *trenutni dogaÄ‘aji* slaÅ¾u s mapom scene â€” tj. ako kamera u toj orijentaciji â€œvidiâ€ iste rubove gdje su eventi nastali â†’ velika vjerojatnost.
* Na kraju se prosjeÄno (ili najvjerojatnije) stanje Äestica uzima kao rezultat.
  â¡ï¸ Ukratko: koristi **nasumiÄno uzorkovanje i vjerojatnosti** da procijeni rotaciju kamere.

---

### ğŸ”¹ 2. **Minimizacija photometric errora**

* Ovdje se radi o **deterministiÄkom optimizacijskom pristupu** â€” traÅ¾iÅ¡ onu rotaciju kamere kod koje je **razlika izmeÄ‘u oÄekivane i stvarne svjetline (intenziteta)** najmanja.
* Koristi se **mapa vjerojatnosti rubova** scene, a eventi (koji nastaju kod promjena svjetline) se usporeÄ‘uju s tim mapiranim rubovima.
* Ako je event tamo gdje bi, prema pretpostavljenoj rotaciji, trebao biti jaki rub â†’ mala greÅ¡ka, dobra orijentacija.
  â¡ï¸ Ukratko: traÅ¾i **rotaciju koja minimizira fotometrijsku pogreÅ¡ku** izmeÄ‘u dogaÄ‘aja i modela scene.

---

### ğŸ”¹ 3. **Motion compensation optimizacija**

* Ovaj pristup ne procjenjuje izravno rotaciju, nego **kutnu brzinu** (tj. kako se orijentacija mijenja u vremenu).
* Ideja: ako znaÅ¡ kutnu brzinu, moÅ¾eÅ¡ â€œkompenziratiâ€ kretanje â€” tj. pomaknuti dogaÄ‘aje unatrag u vremenu tako da bi se svi poravnali ako je model toÄan.
* Ako su svi dogaÄ‘aji poravnati u istu strukturu (rubovi izgledaju â€œoÅ¡triâ€) â†’ pronaÅ¡ao si dobru kutnu brzinu.
  â¡ï¸ Ukratko: traÅ¾i **brzinu rotacije** koja najbolje â€œporavnavaâ€ dogaÄ‘aje kroz vrijeme.

---

ğŸ’¡ **Razlika ukratko:**

| Pristup             | Å to traÅ¾i    | Kako radi                         |
| ------------------- | ------------ | --------------------------------- |
| Particle filter     | Rotaciju     | ProbabilistiÄki, s mnogo hipoteza |
| Photometric error   | Rotaciju     | Optimizacija greÅ¡ke svjetline     |
| Motion compensation | Kutnu brzinu | Poravnava dogaÄ‘aje kroz vrijeme   |

---

---

## ğŸ”¹ Å to znaÄi **6-DOF**?

â€œ6 Degrees of Freedomâ€ = kamera se moÅ¾e kretati:

* **3 translacije:** naprijedâ€“nazad (x), goreâ€“dolje (y), lijevoâ€“desno (z)
* **3 rotacije:** pitch (nagib), yaw (okretanje lijevo-desno), roll (kotrljanje osi)

ZnaÄi, **puno praÄ‡enje poze (pose tracking)** = znamo *i gdje je kamera u prostoru* + *kako je okrenuta* u svakom trenutku.
To je daleko teÅ¾e nego samo rotacija jer ukljuÄuje i **dubinu i perspektivu**.

---

## ğŸ”¹ Ukratko Å¡to rade pojedini pristupi iz odlomka:

### ğŸ§© [226] â€“ *Hand-crafted metoda, B&W linije*

* Radi s **umjetnim crno-bijelim mapama s linijama** (nema probabilistike, sve ruÄno podeÅ¡eno).
* Pretpostavlja da **svaki event dolazi s najbliÅ¾e linije** u mapi.
* Te linije se **prate i njihovi presjeci daju 3D toÄke**.
* Zatim se koristi **PnP (Perspective-n-Point)** algoritam za raÄunanje **poze kamere** iz poznatih toÄaka.
  â¡ï¸ Ukratko: *ruÄno izraÄ‘ena metoda* koja koristi geometriju linija da prati kameru kroz 3D prostor.

---

### ğŸ§  [228] â€“ *Continuous-time nadogradnja prethodne*

* Umjesto da raÄuna svaku pozu posebno, modelira **kontinuiranu putanju** kamere kroz vrijeme.
* Optimizira **event-to-line reprojection error** â†’ znaÄi: prilagoÄ‘ava cijelu putanju da bi svaki event â€œsjeoâ€ Å¡to bliÅ¾e svojoj liniji u mapi.
  â¡ï¸ Ukratko: *kontinuirana optimizacija putanje kamere*, preciznija i glaÄ‘a od frame-by-frame pristupa.

---

### âš™ï¸ [7] i [65] â€“ *Realni 6-DOF tracking u prirodnim scenama*

* Ovi su veÄ‡ **real deal** â€” rade s **prirodnim scenama**, ne samo crno-bijelim linijama.
* [7] koristi **generativni probabilistiÄki filter** (kao particle filter, ali robusniji):

  * Likelihood funkcija je **mjeÅ¡avina gustoÄ‡a (mixture densities)** â†’ bolje hvata nesigurnost i Å¡um eventa.
* [65] koristi **nelinearnu optimizaciju photometric errora** izmeÄ‘u:

  * â€œBrightness increment imagesâ€ (sinteza dogaÄ‘aja u slike svjetline)
  * i njihove predikcije prema mapi scene.
* [65] daje malo bolje rezultate jer photometric optimizacija bolje hvata fine detalje svjetline.
  â¡ï¸ Ukratko: *moderni 6-DOF trackeri* koji kombiniraju fiziku eventa + optimizaciju slike za full 3D tracking.

---

## ğŸ”¸ Ukratko sve skupa:

| Pristup | Tip                                 | KljuÄna ideja                                                  | OgraniÄenje                  |
| ------- | ----------------------------------- | -------------------------------------------------------------- | ---------------------------- |
| [226]   | Hand-crafted                        | Pretpostavlja da eventi dolaze s najbliÅ¾e linije i koristi PnP | Radi samo za B&W linije      |
| [228]   | Continuous optimization             | Optimizira cijelu trajektoriju pomoÄ‡u reprojekcije dogaÄ‘aja    | JoÅ¡ uvijek jednostavne scene |
| [7]     | ProbabilistiÄki model               | Filter s mjeÅ¡avinom gustoÄ‡a za robustnost                      | Zahtjevan za implementaciju  |
| [65]    | Nelinearna photometric optimizacija | UsklaÄ‘uje svjetlosne promjene s mapom scene                    | Zahtjeva mapu scene          |

---

6 DOF ima odreÄ‘ene izazove:
- promjena orijentacije mijenja kut gledanja,

- promjena pozicije mijenja paralaksu i dubinu,

- sve to moraÅ¡ povezati s asinkronim eventima koji ne dolaze u â€œframeovimaâ€ nego neprekidno.

---


Ovaj tekst pokriva **evoluciju SLAM algoritama** za **event kamere** â€“ od jednostavnih 2D verzija (samo rotacija, crno-bijele mape) do **pravih 3D 6-DOF sustava** koji rade u **realnim scenama bez pomoÄ‡i dodatnih senzora** (RGB-D, IMU itd.).

Cilj svih:
ğŸ‘‰ Istovremeno **pratiti pozu kamere** (tracking)
ğŸ‘‰ I **graditi mapu scene** (mapping)
s pomoÄ‡u *samo dogaÄ‘aja* umjesto frameova.

---

## ğŸ”¹ Rani radovi (2D SLAM i rotacijski modeli)

### ğŸ§  Cook et al. [23]

* Koristili **message-passing algoritam** za zajedniÄku procjenu:

  * kretanja kamere (ego-motion),
  * slike (intensity),
  * i optical flowa.
* Ali: ograniÄeno samo na **rotacije**.
  â¡ï¸ Ideja: simultana procjena viÅ¡e povezanih veliÄina â†’ viÅ¡e jednadÅ¾bi = bolja stabilnost.

---

### ğŸ“ [224] â€“ 2D Event-based SLAM

* Baziran na [101], ali sad **gradi mapu scene dok prati kameru**.
* Koristi **particle filter** za praÄ‡enje poze.
* Likelihood = obrnuto proporcionalan **reprojection erroru** dogaÄ‘aja prema mapi.
* Mapa = **occupancy map** (vjerojatnost da je pixel aktivan/edge).
  â¡ï¸ Prvi pravi â€œSLAMâ€ korak za event kamere, ali joÅ¡ **planarni (2D)** i za **visoki kontrast** scene.

---

### ğŸ§â€â™‚ï¸ [225] â€“ 3D SLAM, ali uz pomoÄ‡ RGB-D senzora

* Nadogradnja [224], ali sad s **3D mapom** (dubina iz RGB-D senzora).
* Problem: RGB-D **ubija prednost event kamere** (sporo, visoka latencija).
  â¡ï¸ Dakle, radi, ali *viÅ¡e nije pravi event-based sistem* jer se oslanja na vanjski senzor.

---

## ğŸ”¹ Bolji modeli za rotaciju i panorame

### ğŸŒ€ [24] â€“ Filter-based pristup

* Dva **probabilistiÄka filtera** rade paralelno:

  1. PraÄ‡enje orijentacije kamere.
  2. Gradnja panoramske mape.
* Koristi **Kalman filter po pixelu** â†’ svaka toÄka ima svoju procjenu orijentacije i jaÄine edgea.
* Zatim se ta panorama pretvara u **HDR intenzitetnu mapu** (Poisson integracija).
  â¡ï¸ Ultra-pametno: koristi evente da izgradi **super-resolution HDR panoramu** i orijentaciju istovremeno!

---

### ğŸ§­ [103] â€“ Photometric error pristup

* Koristi **minimizaciju photometric errora** izmeÄ‘u eventa i probabilistiÄke edge mape.
* I mapa i praÄ‡enje rade zajedno (SLAM).
  â¡ï¸ Stvara **panoramsku occupancy mapu** â€” svaki â€œmap pointâ€ ima vjerojatnost stvaranja dogaÄ‘aja (koliko je jaka ivica).

---

## ğŸ”¹ Pravi 3D Event-based SLAM (6-DOF napokon!)

### ğŸ’¥ [25] â€“ Full probabilistic 6-DOF SLAM

* ProÅ¡irenje [24], sad s **tri filtera** koji istovremeno rade:

  1. PraÄ‡enje poze (pose tracking).
  2. Procjena dubine.
  3. Procjena svjetline (intensity).
* Problem: slabija robusnost kod inicijalizacije.
* Pretpostavlja da su dubina, intenzitet i gibanje **nekorelirani**, Å¡to nije toÄno.
* Radi u realnom vremenu, ali traÅ¾i **GPU**.
  â¡ï¸ Prvi â€œall-in-oneâ€ SLAM koji radi sve â€” ali skup i osjetljiv.

---

### âš™ï¸ [26] â€“ Geometrijski (semi-dense) SLAM

* Dokazuje da **nije nuÅ¾no rekonstruirati intenzitet slike** da bi se dobila dubina i poza.
* Koristi:

  * **Space sweeping** za 3D rekonstrukciju (Äista geometrija).
  * **Edge-map alignment** (nelinearna optimizacija izmeÄ‘u dogaÄ‘aja i mapa).
* Radi **u realnom vremenu na CPU-u!**
  â¡ï¸ UÄinkovit, precizan i jednostavniji â€” *vjerojatno najpraktiÄniji pristup za dronove*.

---

## ğŸ”¹ ZakljuÄci i izazovi

* JoÅ¡ uvijek **nema loop-closurea** (popravljanje pogreÅ¡ke kad se kamera vrati na istu lokaciju).
* Radi samo na **malim scenama** (za sada).
* Ali! Cilj nije nuÅ¾no zamijeniti frame-based SLAM, nego **biti komplementaran**:

  * Event kamera = visoka brzina, bez zamuÄ‡enja, velika dinamika.
  * Frame kamera = precizni detalji i teksture.
* **Stereo event SLAM** joÅ¡ je neistraÅ¾eno podruÄje.
* **Fusion s IMU-om** (Å¾iroskop, akcelerometar) znaÄajno bi poveÄ‡ao robusnost.

---

## âš¡ TL;DR â€“ Mega saÅ¾etak

| Pristup | Glavna ideja                                 | Prednosti               | OgraniÄenja                 |
| ------- | -------------------------------------------- | ----------------------- | --------------------------- |
| [23]    | Joint estimation (motion + flow + intensity) | Teoretski elegantno     | Samo rotacija               |
| [224]   | 2D particle filter SLAM                      | Simple i efektno        | Samo 2D, visoki kontrast    |
| [225]   | 3D SLAM + RGB-D                              | Radi u 3D               | Spor i kompleksan           |
| [24]    | ProbabilistiÄki filter + panorame            | HDR mapa i orijentacija | Samo rotacija               |
| [103]   | Photometric error + edge mapa                | UÄinkovito mapiranje    | Nema translaciju            |
| [25]    | 6-DOF probabilistiÄki SLAM                   | Full SLAM               | GPU heavy, nestabilan start |
| [26]    | Geometrijski semi-dense SLAM                 | Brz i robustan          | JoÅ¡ nema loop closure       |

---
---

### ğŸ’¡ Å to je Visual-Inertial Odometry (VIO)?

VIO = **fuzija kamere i IMU-a (akcelerometar + Å¾iroskop)** â†’ zajedno daju **pouzdaniju procjenu kretanja u 6-DOF-u**.

---

### 1ï¸âƒ£ Visual Odometry (VO) sama po sebi...

* Koristi samo kameru da procijeni **kako se kamera pomaknula** izmeÄ‘u frameova.
* Dobra je kad ima dovoljno teksture, svjetla i stabilnog videa.
* Ali ako kamera brzo rotira, ako je scena monotona ili zamagljena â†’ *VO gubi tracking*.

---

### 2ï¸âƒ£ A Visual-Inertial Odometry (VIO)â€¦

* Dodaje **IMU podatke (akceleracije, brzine rotacije)**.
* Kad kamera â€œoslijepiâ€ (npr. u mraku ili pri velikim brzinama), **IMU i dalje zna da se tijelo kreÄ‡e**.
* Zato **VIO nikad ne padne potpuno** â€” uvijek ima izlaz, iako s vremenom moÅ¾e **driftati** (lagano odlutati od stvarne pozicije).

---

### 3ï¸âƒ£ KljuÄni izazov â†’ *Temporalna fuzija*

Event kamera daje **asinkrone evente** (svaki pixel ima svoj timestamp),
dok IMU daje **sinkrone uzorke** npr. svakih 1 ms (1000 Hz).
ğŸ‘‰ Problem: *kako spojiti ta dva izvora vremena u zajedniÄki model?*

---

### 4ï¸âƒ£ Tri pristupa koja koriste znanstvenici:

#### (i) **Asinkroni probabilistiÄki filter**

* Koristi se **Bayesov filter (npr. EKF)** koji asinkrono prima evente i IMU mjerenja.
* Svaki novi podatak aÅ¾urira procjenu stanja â†’ *state = pozicija, brzina, orijentacija*.
* Super precizan, ali raÄunalno zahtjevan.

#### (ii) **Pre-integracija IMU-a**

* IMU podatke integriraÅ¡ unaprijed izmeÄ‘u dva eventa ili framea â†’ dobijeÅ¡ â€œkompaktneâ€ podatke.
* Time se smanji uÄestalost IMU updatea i lakÅ¡e ih sinkroniziraÅ¡ s eventima.
* Koristi se u veÄ‡ini modernih VIO sustava (npr. VINS-Mono, OKVIS, Basalt).

#### (iii) **Continuous-time model**

* Umjesto da imaÅ¡ diskretne frameove, modeliraÅ¡ poziciju kamere kao **kontinuiranu funkciju vremena**.
* Svi senzori (kamera, IMU, event kamera) se referenciraju na tu zajedniÄku vremensku os.
* Idealno za event kamere, jer i one rade kontinuirano.
* Ali zahtjeva napredne nelinearne optimizacije (spline modeli, Gaussian Processes itd.).

---

### 5ï¸âƒ£ ZakljuÄak

* VO = brza, ali moÅ¾e â€œpuknutiâ€.
* VIO = otpornija, radi i bez slike, ali lagano drift-a.
* U event-based kamerama VIO je **game changer**, jer:

  * Eventi su brzi (mikrosekunde)
  * IMU je brz (1 kHz)
  * Kombinacijom dobivaÅ¡ **precizno praÄ‡enje i pri ludim brzinama, bez zamuÄ‡enja!** âš¡




---

### ğŸš€ 1ï¸âƒ£ Å to znaÄi *feature-based* VIO

* Umjesto da se koristi svaki pojedinaÄni event (Å¡to bi bilo kaotiÄno), sustav **detektira i prati feature toÄke** kroz vrijeme.
* Te toÄke su â€œsidraâ€ â€” stabilni detalji u slici (rubovi, kutovi, uzorci) koji se mogu pratiti kroz sekvence eventa.

---

### âš™ï¸ 2ï¸âƒ£ Dvije glavne faze

1. **Frontend** â†’ iz eventa se izvuku i prate feature toÄke (npr. Harris corneri ili FAST featurei).
2. **Backend (VIO fuzija)** â†’ te trajektorije featurea se kombiniraju s IMU podacima da bi se procijenila 6-DOF putanja kamere i mapa okoline.

---

### ğŸ“¸ 3ï¸âƒ£ Frontend: pretvaranje eventa u â€œfeature trakoveâ€

* Event kamera ne daje frameove, nego samo promjene osvjetljenja (x, y, t, polaritet).
* Sustavi poput [130] koriste algoritme za praÄ‡enje tih promjena kroz vrijeme â†’ dobivaÅ¡ **feature tracks** (trajektorije toÄaka kroz frameove).
* To je kao kad u obiÄnom videu gledaÅ¡ kako se kut zgrade miÄe kroz frameove â€” samo Å¡to se ovdje to radi *event po event*.

---

### ğŸ§  4ï¸âƒ£ Backend: spajanje s IMU-om pomoÄ‡u Kalman filtera

* Svaki track ima svoju procijenjenu poziciju i brzinu â†’ to se kombinira s IMU mjerenjima (ubrzanje, rotacija).
* Kalman filter ili njegova varijanta (Extended/Unscented KF) koristi oba izvora informacija da bi â€œispeglaoâ€ Å¡um i procijenio precizniji poloÅ¾aj.
  ğŸ‘‰ Ovo je kao kad kombiniraÅ¡ *oÄi (kamera)* i *unutarnji osjet ravnoteÅ¾e (IMU)* da znaÅ¡ gdje si u prostoru.

---

### ğŸ”„ 5ï¸âƒ£ Motion-compensated event images (spominje se u [129])

* Umjesto da koristi â€œrawâ€ evente, metoda ih **kompenzira za gibanje** â€” znaÄi â€œzarotiraâ€ i â€œpomakneâ€ ih tako da se sve toÄke usklade s trenutnim kretanjem kamere.
* Time se dobiva **oÅ¡trija, stabilnija slika** iz niza eventa â†’ i tada se mogu koristiti klasiÄni feature detektori (npr. FAST, Harris).

---

### ğŸ§© 6ï¸âƒ£ Keyframe-based optimizacija

* Sustav ne optimizira svaki frame â†’ prevelik troÅ¡ak.
* Umjesto toga, koristi **keyframe pristup** â†’ uzme kljuÄne frameove i meÄ‘u njima optimizira:

  * Poze kamere (R, t)
  * 3D pozicije landmarka (toÄke u prostoru)
* Sve to radi preko **nelinearne optimizacije** (npr. Bundle Adjustment) kako bi smanjio ukupnu reprojection greÅ¡ku.

---

### ğŸ“ˆ 7ï¸âƒ£ Spajanje i event + intensity frameova

* Kasniji radovi ([27]) spajaju event kameru i obiÄnu (intensity) kameru u isti sustav.
* Time dobijeÅ¡ najbolje od oba svijeta:

  * Event kamera = visoka brzina i HDR (ne zaslijepljuje se)
  * ObiÄna kamera = bogata tekstura
* Zajedno omoguÄ‡uju rad i u **mraku, jakoj svjetlosti, ili brzoj rotaciji** (npr. dron koji leti u sumrak).

---

### ğŸ§® 8ï¸âƒ£ Optimizacija = procjena putanje i mape

* Cilj sustava:

  * Rekonstruirati **trajektoriju kamere** u 6-DOF-u (pozicija + orijentacija)
  * Stvoriti **sparse 3D mapu** svijeta oko nje (landmarki u prostoru).
* Sve se optimizira kako bi **reprojection error bio minimalan** â†’ da se projekcije 3D toÄaka poklapaju s njihovim promatranim mjestima na slici.

---

### ğŸ“Š 9ï¸âƒ£ Benchmarking

* Sve te metode se testiraju na **6-DOF datasetima** (npr. [98]) â€” obiÄno realni pokreti kamere s ground truthom.
* Svaka nova verzija metode poboljÅ¡ava prethodnu po brzini, preciznosti i otpornosti na Å¡um.

---

### âš¡ 10ï¸âƒ£ Glavni takeaway

Feature-based event VIO =
â¡ï¸ *pretvori evente u toÄke koje moÅ¾eÅ¡ pratiti*,
â¡ï¸ *spoji s IMU-om da dobijeÅ¡ robustnu procjenu kretanja*,
â¡ï¸ *optimiziraj poze i mapu kroz keyframe-based nelinearnu optimizaciju.*
â¡ï¸ Rezultat: **precizan, robustan, high-speed 3D tracking â€” Äak i u mraku ili ekstremnim uvjetima!**

---

Continuous-time framework â€“ kamera se modelira kao kontinuirana funkcija vremena, ne samo diskretne frameove, Å¡to je prirodnije za event kamere koje daju asinkrone dogaÄ‘aje.

Reprojection error â€“ umjesto samo feature trackova, svaka predviÄ‘ena lokacija dogaÄ‘aja se reprojektira u sliku, i razlika izmeÄ‘u stvarnih i predviÄ‘enih dogaÄ‘aja je mjera pogreÅ¡ke.

Fuzija s IMU â€“ inertialni podaci se ukljuÄuju u istu optimizaciju, tj. objektivna funkcija minimizira i vizualnu (event) i inercijalnu pogreÅ¡ku.

Event-based bundle adjustment â€“ sliÄno klasiÄnom BA za standardne kamere, ali sada optimiziramo trajektoriju kamere i poziciju toÄaka (scene structure) iz samih eventa.

Izbjegavanje konverzije u feature tracks â€“ klasiÄni feature-based pristup prvo pretvara evente u geometrijske featuree; reprojection-based metoda direktno koristi raw evente, Å¡to potencijalno daje precizniju rekonstrukciju.

Photometric error / firing rate â€“ dogaÄ‘aji imaju intenzitet pokretanja (event rate) koji se moÅ¾e koristiti kao fotometrijski signal za optimizaciju, sliÄno VI-DSO za standardne kamere.

Stereo event VIO â€“ joÅ¡ nije istraÅ¾eno, ali kombiniranje stereokamera + event-based depth moÅ¾e dovesti do full SLAM + VIO sistema s real-time mapiranjem.

Learning-based alternative â€“ trenutno literatura je model-based (klasiÄne optimizacijske metode), ali deep learning bi mogao direktno mapirati raw evente + IMU u 6-DOF poziciju.

KljuÄna prednost â€“ kontinuirana optimizacija po segmentima trajektorije daje glatkije i robusnije pozicije, drastiÄno smanjujuÄ‡i drift u usporedbi sa Äistim feature-based ili jednostavnim Kalman filter pristupom.

Izazov implementacije â€“ zahtjeva sloÅ¾enije numeriÄke metode, nelinearnu optimizaciju, te dobar model kamere i IMU kalibracije. Ovo nije trivialno za real-time CPU implementaciju, ali GPU i batch optimizacije Äine to izvedivim.

Image reconstruction

Event = promjena svjetline â€“ svaki event kodira samo kada se svjetlina promijeni iznad nekog praga, s polaritetom (+/-).

Ne-redundantno kodiranje â€“ unlike obiÄna kamera koja zapisuje cijeli frame, event kamera Å¡alje samo promjene, pa je podatak â€œkomprimiranâ€ po prirodi.

Integracija eventa = vraÄ‡anje svjetline â€“ kad integriraÅ¡ sve promjene po pikselima kroz vrijeme, dobijeÅ¡ â€œaproksimativnuâ€ originalnu svjetlinu scene.

Rekonstrukcija slika â€“ ovaj proces integracije eventa naziva se image reconstruction; efektivno decompressaÅ¡ event stream natrag u brightness mapu.

Visoka temporalna rezolucija â€“ eventi dolaze u mikrosekundama, pa moÅ¾eÅ¡ rekonstruirati frameove na tisuÄ‡e Hz (2â€“5 kHz) ili kontinuirano.

Prednosti â€“ nema motion blur-a jer se integrira u realnom vremenu; moÅ¾eÅ¡ dobiti â€œtrenutnu slikuâ€ Äak i pri velikim brzinama objekata.

Metode rekonstrukcije â€“ od jednostavne akumulacije eventa (dodan +1/-1 po pikselu) do sofisticiranih algoritama koji ukljuÄuju regularizaciju, optimizaciju i rekonstrukciju visoke kvalitete.

Continuous-time reconstruction â€“ neke metode (npr. [62]) ne Äekaju frame, nego kontinuirano aÅ¾uriraju brightness mapu dok dolaze eventi.

Noise & sensor limitations â€“ u stvarnom svijetu eventi imaju Å¡um, dead pixels, i neidealni response, pa rekonstrukcija Äesto koristi filtering i denoising.

Primjena â€“ high-speed tracking, HDR scena u realnom vremenu, robotika, AR/VR, pa Äak i predobuka za SLAM ili VIO sustave.

Event = promjena svjetline â€“ svaki event kodira samo kada se svjetlina promijeni iznad nekog praga, s polaritetom (+/-).

Ne-redundantno kodiranje â€“ unlike obiÄna kamera koja zapisuje cijeli frame, event kamera Å¡alje samo promjene, pa je podatak â€œkomprimiranâ€ po prirodi.

Integracija eventa = vraÄ‡anje svjetline â€“ kad integriraÅ¡ sve promjene po pikselima kroz vrijeme, dobijeÅ¡ â€œaproksimativnuâ€ originalnu svjetlinu scene.

Rekonstrukcija slika â€“ ovaj proces integracije eventa naziva se image reconstruction; efektivno decompressaÅ¡ event stream natrag u brightness mapu.

Visoka temporalna rezolucija â€“ eventi dolaze u mikrosekundama, pa moÅ¾eÅ¡ rekonstruirati frameove na tisuÄ‡e Hz (2â€“5 kHz) ili kontinuirano.

Prednosti â€“ nema motion blur-a jer se integrira u realnom vremenu; moÅ¾eÅ¡ dobiti â€œtrenutnu slikuâ€ Äak i pri velikim brzinama objekata.

Metode rekonstrukcije â€“ od jednostavne akumulacije eventa (dodan +1/-1 po pikselu) do sofisticiranih algoritama koji ukljuÄuju regularizaciju, optimizaciju i rekonstrukciju visoke kvalitete.

Continuous-time reconstruction â€“ neke metode (npr. [62]) ne Äekaju frame, nego kontinuirano aÅ¾uriraju brightness mapu dok dolaze eventi.

Noise & sensor limitations â€“ u stvarnom svijetu eventi imaju Å¡um, dead pixels, i neidealni response, pa rekonstrukcija Äesto koristi filtering i denoising.

Primjena â€“ high-speed tracking, HDR scena u realnom vremenu, robotika, AR/VR, pa Äak i predobuka za SLAM ili VIO sustave.

Image reconstruction iz evenata zahtjeva regularizaciju. 
Event kamere imaju neovisne piksele koji "reportiraju" promjene u osvjetljenju. Per-pixel integracija takvih promjena kroz vrijeme rezultira samo slikama s inkrementiranom svjetloÅ¡Ä‡u

kljuÄni detalj u image reconstruction iz eventa â€“ sam event stream ti daje samo promjene svjetline, ne apsolutne vrijednosti. Evo kako to moÅ¾emo objasniti u natuknicama:

Event = brightness change, ne apsolutna vrijednost â€“ svaki piksel Å¡alje +1/-1 ili neku sliÄnu oznaku promjene.

Integracija po pikselu daje brightness increment image, tj. koliko se svjetlina promijenila u nekom vremenskom intervalu, ali ne i stvarnu svjetlinu scene.

Offset image = poÄetna svjetlina â€“ da bi dobio stvarnu brightness mapu, trebao bi dodati poÄetnu sliku intervala na integrirane promjene.

Problem â€“ u praksi Äesto nemamo tu poÄetnu sliku (offset), posebno u potpuno event-based sustavima.

RjeÅ¡enje: regularizacija â€“ koristi se prostorno i/ili vremensko glatkanje (smoothing) kako bi se rekonstruirala brightness slika iz nule.

Spatial smoothing â€“ pikseli se â€œpomaÅ¾uâ€ susjedima; izbjegava se ekstremno Å¡um i lokalne nepravilnosti.

Temporal smoothing â€“ koristi informacije iz prethodnih intervala; stabilizira brightness mapu kroz vrijeme.

Learning-based regularization â€“ deep learning modeli mogu nauÄiti statistiku prirodnih scena i rekonstruirati realistiÄne brightness slike iz event streama.

Prednosti â€“ omoguÄ‡uje HDR rekonstrukciju, pod visokim brzinama i u sceni s velikim kontrastom (npr. izlazak iz tunela, eksplozija).

Rezultat â€“ dobivaÅ¡ kontinuiranu brightness mapu, visoke dinamiÄke Å¡irine, bez motion blur-a i s oÄuvanjem detalja, Å¡to je kljuÄno za event-based SLAM, VIO ili tracking.

Summary:

Kvaliteta slike â€“ jako ovisi o noise-u u contrast threshold-u piksela; pikseli nisu savrÅ¡eno identiÄni zbog manufacturing mismatcha i promjena svjetla/dinamike.

Spatial resolution â€“ viÅ¡a rezolucija senzora â†’ bolja reconstructed slika, niÅ¾a â†’ gubi detalje.

Integracija events â†’ brightness image â€“ principijelno se evente moÅ¾e â€œdekomprimiratiâ€ u brightness frame koji se koristi kao obiÄna slika.

Mature CV pipelines â€“ rekonstruirani frameovi omoguÄ‡uju koriÅ¡tenje svih standardnih computer vision algoritama (prepoznavanje objekata, SLAM, optical flowâ€¦).

Prednosti â€“ moÅ¾e hvatati high-speed motion i HDR scene; scene koje bi obiÄna kamera teÅ¡ko snimila.

TroÅ¡ak â€“ rekonstrukcija je raÄunalno intenzivna, ima latenciju i poveÄ‡anu potroÅ¡nju energije.

Nije uvijek nuÅ¾no â€“ za neke zadatke poput feature tracking, SLAM-a ili optical flowa, ne mora se rekonstruirati frame; eventi sami Äesto daju dovoljno informacije.

Scenska reprezentacija â€“ rekonstruirane slike daju stabilniji prikaz scene od same sekvence eventa; manje osjetljiv na noise i kratkotrajne promjene.

Facilitacija korrespondencija â€“ rekonstruirani frameovi pomaÅ¾u u povezivanju istih featurea izmeÄ‘u eventa, Å¡to je kljuÄno za tracking i VIO.

Dodatna vrijednost â€“ osim praktiÄnih zadataka, rekonstruirane slike sluÅ¾e i kao appearance maps, Å¡to je korisno za vizualizaciju scene i eventualnu fuziju s drugim senzorima.

Motion segmentation

Segmentacija pokretnih objekata koje promatra stacionarna event kamera je jednostavna
Eventi su vezani samo uz kretanje objekata (pod pretpostavkom konstantnog osvjetljenja)
U sluÄaju pokretne kamere javljaju se izazovi jer se eventi dogaÄ‘aju svuda u vidokrugu kamere
Stvaraju ih pokretni objekti i prividno pokretna scena (scena je statiÄna, ali se Äini da se miÄe zbog micanja kamere)
Cilj je za svaki event razaznati je li uzrokovan pokretom objekta na sceni ili pokretom scene zbog kamere
Izazovno je to odraditi jer svaki event u sebi nosi jako malo informacija
Ukratko: vidimo kako se globalno kreÄ‡e scena (global flow) i onda to oduzmemo od pojedinih kretanja u svakom eventu

NaÄin istraÅ¾ivanja: segmentacija motiona u scenarijima koji postaju progresivno sve kompleksniji, zbog smanjivanja dodatnih informacija za rjeÅ¡avanje problema
Primjeri dodatnih informacija: algoritam ima info o tome koji oblik ili koji naÄin kretanja mora oÄekivati (Äa oÄekujen vidit i kako Ä‡e se kretat)

Ako nemaÅ¡ dodatne informacije (kao Å¡to su flow kamere ili dubinska mapa), problem postaje unsupervised â€“ moraÅ¡ se osloniti samo na eventi.

Osnovna ideja: pokretni objekti stvaraju distinktivne tragove eventa na slici. Ti tragovi se mogu pratiti kroz vrijeme da bi se rekonstruirale putanje objekata.

Rezultat: segmentacija objekata se dobiva istovremeno s procjenom njihove putanje.

Ovo je u osnovi joint optimization problem:

traÅ¾iÅ¡ parametre pokreta objekata (kao â€œklastereâ€)

dok istovremeno odreÄ‘ujeÅ¡ koji event pripada kojem objektu.

U praksi se ovo Äesto rjeÅ¡ava iterativno:

prvo inicijalna grupa eventa u klastere

zatim optimizacija parametara pokreta i reassignment eventa

ponovi dok se ne konvergira

Ukratko: Äak i bez dodatnih senzora, segmentacija moÅ¾e uspjeti tako Å¡to iskoristi prostorno-vremenske obrasce eventa.

Poznavanje oblika objekta pomaÅ¾e:

[13] detektira i prati krug Äak i kad pokret kamere stvara puno â€œclutteraâ€.

Koristi Hough transform i optical flow iz vremenskih prozora eventa.

Robusnost praÄ‡enja:

[181] proÅ¡iruje metodu s particle filterom, dinamiÄki prilagoÄ‘ava trajanje prozora za praÄ‡enje naglih promjena gibanja.

OpÄ‡eniti oblici objekata:

[188] koristi event corners kao geometrijske primitive.

Zahtijeva dodatno znanje o robot joints koji pokreÄ‡u kameru.

Segementacija pomoÄ‡u motion-compensated event images:

[132], [154], [155] koriste ovu ideju: evente warpaju prema hipotezi pokreta da bi se dobile oÅ¡tre konture objekata.

Jednostavne hipoteze pokreta:

Linearni modeli (konstantni optical flow) Äesto su dovoljni za kratka vremena.

Scene se opisuju kao kolekcije objekata s razliÄitim linearnim modelima pokreta.

Greedy pristupi segmentaciji:

[154] prvo uklanja dominantne evente (pozadinu), zatim fitira linearni model na ostatak (objekti).

[132] otkriva pokretne objekte detektiranjem odstupanja od dominantnog pokreta (background).

Iterativni pristupi:

[155] iterativno optimizira event-object assignments i motion parameters, daje bolje rezultate od greedy metoda.

OmoguÄ‡uje general parametric motion models za svaki objekt.

Learning-based pristupi:

[133] koristi ANN za procjenu depth, ego-motion, segmentation masks i 3D brzine objekata.

Dataset s pixel-wise motion maskama omoguÄ‡uje nadzirano uÄenje.

Prednosti event-based segmentacije:

Daje robusno praÄ‡enje Äak i u HDR i high-speed scenama gdje standardne kamere ne mogu.

ZakljuÄak:

Segmentacija je kljuÄna u frame-based vision, ali je joÅ¡ nedovoljno istraÅ¾ena u event-based vision.

Kako se razvijaju napredniji event-based algoritmi, oÄekuje se rast radova na ovom izazovnom problemu.



Recognition (4.8)


* **Algoritmi prepoznavanja** za event kamere postaju sve sloÅ¾eniji.
* Razvili su se od **jednostavnog template matchinga** (prepoznavanje osnovnih oblika) do **klasifikacije sloÅ¾enih uzoraka rubova**.
* U poÄetku su se koristili **klasiÄni ML pristupi** s ruÄno definiranim znaÄajkama (hand-crafted features).
* Danas se sve viÅ¡e koriste **deep learning metode** za automatsko uÄenje reprezentacija.
* Glavni cilj tog razvoja je **poveÄ‡ati izraÅ¾ajnost (expressibility)** sustava prepoznavanja i **otpornost na izobliÄenja podataka (robustness to distortions)**.

Rana istraÅ¾ivanja event based senzora -> praÄ‡enje moving objecta pomoÄ‡u statiÄnog senzora
PraÄ‡enje pozicije i oblika objekta (usporedba s poznatim jednostavnim oblicima...blob, circle, line)
Opcija je i matching s predefiniranim templateima (onda nam ne treba da znamo geometriju objekta, nego samo matching)
KoriÅ¡tenje konvolucija u ranim hardverima

Za kompleksnije objekte, templates se kroiste za povezivanje low-level featurea, a ne cijelih objekata
Nakon toga, klasifikator donosi odluke na temelju distribucije promatranih featurea
Koriste se nearest neighbor klasifikatori => udaljenosti u feature spaceu
Preciznost se moÅ¾e poveÄ‡ati s dodavanjem feature invariancea (hijerarhijski model gdje se kompleksnost featurea diÅ¾e u svakom layeru)
Uz dobre featurese, treba trenirati samo finalni klasifikator pri promjeni zadataka
Problem: koje featurese odabrati
U ranim radovima koriste se hand-crafted features, ali bolje je uÄiti featurese iz samih podataka
U najboljem sluÄaju, svaki template moÅ¾e nastati iz pojedinog samplea, ali takav pristup je osjetljiv na noise u podacima
MoguÄ‡e je uÄiti featurese pomoÄ‡u unsupervised uÄenja, clusteringa event podataka i koriÅ¡tenjem centra svakog clustera kao featurea
Svaki novi event povezuje se s najbliÅ¾im featureom
Koristi se back propagation 
Prednost: ne treba nam poseban klasifikator za output
Nedostatak: potrebno je jako puno labeliranih podataka za treniranje
Problem je i nedostatak spremnih labeliranih podataka za trening (veÄ‡inom treba raditi custom dataset)

Wormhole learning:
Problem: nedostatak kvalitetnih trening podataka u event domenu oteÅ¾ava uÄenje modela.

RjeÅ¡enje: koristi se wormhole learning, semi-supervised metoda koja povezuje RGB i event domenu.

Prvi korak: model treniran na RGB slikama (teacher) uÄi detektor za event podatke.

Drugi korak: event model postaje uÄitelj â€” dio robustnosti na promjene osvjetljenja (illumination invariance) prenosi se natrag na RGB model.

Na taj naÄin se iskoriÅ¡tava snaga oba senzora â€” bogatstvo podataka iz RGB i otpornost event kamere.

VeÄ‡inom se u learning-based pristupima eventi/spikeovi konvertiraju u dense vektore => mogu se koristiti u hijerarhijskim modelima (npr. ANN)

RazliÄiti naÄini evaluacije vektora (tensora)

Summary:

---

###  **1. Metode za pretvaranje event podataka**

* Najjednostavnije metode koriste **time surfaces** (karte vremena dogaÄ‘aja) ili **event histograme**.
* Naprednije varijante dodaju **eksponencijalni decay** [109] ili **prosjeÄne vremenske oznake** [113] za bolju robusnost.
* Alternativa: koristiti **rekonstrukciju slike** (Section 4.6) za dobivanje klasiÄne slike iz event streama.
* Neki pristupi **pretvaraju spikeove u frameove** tijekom inferencije [150], [235].
* Drugi konvertiraju **trenirani ANN** u **spiking neural network (SNN)** koji direktno radi s eventima [137].
* SliÄne ideje koriste se i za druge zadatke osim prepoznavanja [22], [108].

---

###  **2. Uloga neuromorfiÄkog hardvera**

* Razvijaju se **SNN-ovi** koji mogu **uÄiti izravno** iz event podataka [143].
* Neki eksperimenti Äak **treniraju modele direktno na neuromorfiÄkom Äipu** [144].
* Ovaj pristup otvara vrata **super brzim, energetski uÄinkovitim** sustavima prepoznavanja.

---

###  **3. Razvoj zadataka prepoznavanja**

* Prvi radovi: prepoznavanje **jednostavnih oblika** (krug, kvadrat) sa statiÄnom kamerom.
* Kasnije: **kompleksniji objekti** â€” znakovi na kartama (card pips), **slova**, **lica**, itd.
* **Najpopularniji test**: event-verzije **MNIST** dataset-a (rukom pisane znamenke).
* Moderni modeli postiÅ¾u **>98% toÄnosti**, ali to nije pravi pokazatelj snage event kamera â€” ti zadaci su prejednostavni.

---

###  **4. Napredniji i realniji zadaci**

* TeÅ¾i datasetovi: **Caltech-101**, **Caltech-256** (joÅ¡ uvijek â€œlaganiâ€ za CV, ali teÅ¾i za event kamere).
* **Recognition s pokretne kamere** (npr. na vozilu) â€” rijetko istraÅ¾eno podruÄje.
* VeÄ‡ina metoda ipak koristi **pretvaranje u frameove** i klasiÄne **deep learning modele**.

---

###  **5. KljuÄni izazovi**

* Event kamere **reagiraju samo na promjenu** â†’ trebaju **pokret** (objekta ili kamere).
* To znaÄi da **ne mogu uÄinkovito prepoznati statiÄne objekte**.
* Izgled event slike **ovisi o relativnom gibanju**, pa bi **kontrolirano gibanje kamere** moglo pomoÄ‡i u stabilnijem prepoznavanju [242].

---

###  **6. Pogodne aplikacije**

* Idealne za **prepoznavanje prema naÄinu gibanja** (gesture, action recognition).
* OdliÄne za **dinamiÄne scene** i **brze pokrete**, gdje klasiÄne kamere zamuÄ‡uju sliku.
* Posebno korisne na **mobilnim platformama** (npr. dronovi, roboti) gdje su uvjeti svjetla i brzine izazovni.

---

###  **7. OgraniÄenja trenutnog stanja**

* Iako event kamere imaju sjajne karakteristike, **joÅ¡ su daleko od konkurencije s frame-based metodama**.
* Moraju pronaÄ‡i **niÅ¡ne zadatke** koji **maksimalno koriste njihove prednosti** â€” a ne kopirati frame-based pristupe.

---

###  **8. Dataseti i anotacije**

* Kvaliteta event-based dataseta **se poboljÅ¡ava**, ali **anotacije su i dalje veliki problem**.
* Nema **standardnog alata ni formata** za oznaÄavanje event podataka.
* VeÄ‡ina postojeÄ‡ih dataseta dolazi iz **frame-based videa**, Å¡to **nije optimalno** jer ne iskoriÅ¡tava pravu prirodu event kamera.
* Velika prilika: napraviti **alat/pipeline za lako prikupljanje i oznaÄavanje event podataka**, Äak i od strane laika.

---
Neuromorphic control
- Kod Å¾ivih biÄ‡a, veÄ‡ina informacija se procesira pomoÄ‡u spike-based reprezentacije
Spikeovi enkodiraju senzorske (osjetilne) podatke
Spikeovi obavljaju izraÄune
Spikeovi odraÄ‘uju "aktuatorske naredbe"
Dakle, event-based paradigma primjenjiva je i na kontrolu, a ne samo percepciju i inference

Neurmorphic-vision-driven Control Architecture
- komponente: neuromorfni senzor, event-based estimator i tradicionalni kontroler

Estimator raÄuna "state", a kontroler raÄuna potrebnu kontrolu na temlju tog "statea"
Kontroler "nije svjestan" asinkronosti arhitekture

Prednosti: niska latencija i visoka efikasnost
Primjeri: spike-based konvolucijski target tracker, robotski "golman", robot koji balansira kemijsku
Latencija manja od 1ms + jednostavna ugradnja u embedded sustave (moÅ¾e raditi i na priliÄno ograniÄenim resursima)

Event based control theory
Control&decision => viÅ¡e informacija omoguÄ‡uje bolje odluke, ali ako su troÅ¡kovi vezani za dobivanje informacija preveliki, racionalnije je donijeti odluku na temelju parcijalne informacije
U event-based kontroli, signal se mijenja asinkrono 
Postoji viÅ¡e varijacija, ovisno o tome kako se generiraju control events

Najbitnije: event-triggered control i slef-triggered control

Osnovna ideja

Kod Å¾ivih biÄ‡a veÄ‡ina senzorne i motoriÄke obrade odvija se u spike-based formatu (tj. event-based).

Spikeovi enkodiraju senzorske podatke, raÄunaju stanja, i pokreÄ‡u akcije â€” percepcija, odluka i reakcija u jedinstvenom okviru.

Dakle, event-based paradigma nije samo za percepciju (vid, sluh...), nego i za kontrolu (pokret, akcije, regulaciju).

Neuromorphic Visionâ€“Driven Control Architecture
Komponente:

Neuromorfni senzor (event camera) â†’ proizvodi asinkrone dogaÄ‘aje.

Event-based estimator â†’ procjenjuje trenutno stanje sustava (â€œstateâ€).

KlasiÄni kontroler â†’ generira kontrolne naredbe na temelju tog stanja.

Kontroler nije svjestan asinkronosti â€” on samo prima aÅ¾uriranja kad ih ima.

Takva arhitektura kombinira bioloÅ¡ki realizam s inÅ¾enjerskom jednostavnoÅ¡Ä‡u.

Prednosti:

Ultra-niska latencija (ispod 1 ms).

Visoka energetska i raÄunska efikasnost.

MoÅ¾e raditi na embedded platformama i mikrokontrolerima s ograniÄenim resursima.

Pogodno za brze, reaktivne zadatke:

spike-based target tracking,

robotski â€œgolmanâ€,

balansiranje fizikalnih sustava (npr. kemijska epruveta).

Event-Based Control Theory
Konceptualna osnova:

Utemeljeno na control i decision teoriji.

Inspirirano ekonomskim principom â€œrational inattentionâ€ [247]:

ViÅ¡e informacija = bolje odluke,

ali ako je skupljanje ili obrada informacija skupa, racionalno je donositi odluke s parcijalnim znanjem.

Dakle, kontrolni signal se mijenja samo kad je to potrebno, a ne u fiksnim vremenskim koracima.

NaÄin rada:

Kontrolni signali se aÅ¾uriraju asinkrono â€” samo kad dogaÄ‘aji to opravdaju.

Postoje dvije glavne paradigme:

Event-triggered control â€“

dogaÄ‘aj pokreÄ‡e reakciju izvana (â€œexogenouslyâ€),

npr. ponovno izraÄunaj kontrolu kad pogreÅ¡ka u praÄ‡enju preÄ‘e prag.

Self-triggered control â€“

kontroler sam odluÄuje kada Ä‡e ponovno izraÄunati izlaz,

npr. â€œspavaâ€ duÅ¾e ako je stanje stabilno, reagira brÅ¾e ako se sustav mijenja.

Trade-off i motivacija:

Cilj: balansirati izmeÄ‘u performansi i raÄunalnog troÅ¡ka.

Idealno bi bilo stalno recomputati kontrolu (beskonaÄno Äesto) â†’ ali to je raÄunski neizvedivo.

Event-based pristup daje jednaku kontrolnu kvalitetu s puno manje raÄunanja, ili bolju kontrolu s istim brojem izraÄuna.

U nekim sluÄajevima (npr. linear Gaussian sistemi) taj se trade-off moÅ¾e izraÄunati analitiÄki.

OgraniÄenja i izazovi

KlasiÄna event-based control teorija bavi se malim, niskodimenzionalnim sistemima (npr. mreÅ¾na kontrola).

Neuromorphic control sustavi (npr. robotika, vozila) su visokodimenzionalni i nelinearni.

To oteÅ¾ava zatvorene (closed-form) matematiÄke rezultate â†’ potrebno je empirijsko i heuristiÄko modeliranje.

Otvoreni istraÅ¾ivaÄki problemi
1. Task-driven sensing

U prirodi, percepcija ima smisla samo ako vodi akciji.

Cilj: kontroler koji dinamiÄki modulira senzorski ulaz ovisno o zadatku i kontekstu.

Potencijal: integracija s region-of-interest (ROI) mehanizmima i promjenjivim bias postavkama kamere â†’ efikasniji sensing i kontrola.

2. Thinking Fast and Slow

Trenutni fokus: brza, niskolatencijska kontrola (â€œfast thinkingâ€).

Problem: kako to integrirati s viÅ¡erazinskom kognitivnom arhitekturom (npr. planiranjem, uÄenjem)?

BioloÅ¡ka analogija prema Kahnemanu [257]:

â€œSystem 1â€ â€“ brzo, instinktivno, refleksno (event-based).

â€œSystem 2â€ â€“ sporo, svjesno, deliberativno.

Cilj: spojiti oba sustava u jedinstvenu, adaptivnu kontrolnu arhitekturu.

Chapter 5. -> event based systems&applications
Neuromorphic computing

Neuromorfno inÅ¾enjerstvo pokuÅ¡ava koristiti kombinaciju raÄunalne snage i efikasnosti mozga kombinirajuÄ‡i njegovu strukturu i funkciju
Paralelni hardverski akceleratori za SNN-ove => definicija neuromorfnog procesora

Neuronski spikeovi unutar procesora su asinkroni i zato je neuromorfno procesiranje idealno za koristiti s event kamerama
Neuromorfni procesori reagiraju na evente koje Å¡alje event kamera, bez dodatne konverzije => jako dobro spatially i temporally lokalno procesiranje podataka
Low power consumption & low latency

Kriterij kategorizacije neuromorfnih procesora moÅ¾e biti naÄin implementacije modela neurona
Analogni neuroni, digitalni neuroni i software neuroni.
Neke arhitekture omoguÄ‡avaju i on-chip learning

Pri evaluaciji neuromorfnog procesora za ebv sustav, u obzir treba uzeti:
- funkcionalnost i performanse procesora
- ekosustav u kojem je software razvijen (minimum je: API za komponirati i trenirati network, kompajler za pripremu networka za hardver, runtime library za deployment networka na harddver
- event based vision sustavi tipiÄno zahtjevaju da je procesor dostupan kao zasebni sustav koji se moÅ¾e pokretati na edge devices, a da nije samo hostan na nekom remote serveru
- dostupnost neuromorphic procesora

Da bi se neuromorfni procesori Å¡ire koristili, nuÅ¾no je:
- razviti viÅ¡e user-friendly ekosustav (lakÅ¡i naÄin za isprogramirati ono Å¡to Å¾elimo deployat na hardver)
- omoguÄ‡iti veÄ‡e procesne moguÄ‡nosti na hardverskoj platformi
- poveÄ‡ati dostupnost ureÄ‘aja

Najbolji trenutni procesori:

---

###  **SpiNNaker (Spiking Neural Network Architecture)**

* Koristi **ARM jezgre** (general-purpose procesore).
* Ne koristi fiziÄke neurone, veÄ‡ ih **simulira softverski** â†’ **maksimalna fleksibilnost**, ali **manje ubrzanje**.
* Primjene s event kamerama:

  * **Stereo depth estimation**
  * **Optic flow**
  * **Object tracking i recognition**
* Fokus: **bioloÅ¡ki realistiÄne simulacije** mozga.

---

###  **TrueNorth (IBM)**

* Ima **digitalne neurone** â€” svaka Äip simulira:

  * **1 milijun neurona**
  * **256 milijuna sinapsi**
  * **4096 neurosinaptiÄkih jezgri**
* **Nema uÄenja na Äipu** â†’ mreÅ¾e se treniraju **offline (GPU)**.
* Primjene s event kamerama:

  * **Gesture recognition**
  * **Stereo rekonstrukcija**
  * **Optical flow**
* Fokus: **real-time inference**, **niska potroÅ¡nja**, **niska latencija**.

---

###  **Loihi (Intel)**

* Ima **digitalne neurone** s **real-time inference + online learning**.
* Jedan Äip:

  * **131 tisuÄ‡a neurona**
  * **130 milijuna sinapsi**
* Ima **learning engine** koji podrÅ¾ava:

  * **STDP** (Spike-Timing Dependent Plasticity)
  * **Reinforcement learning**
* MoÅ¾e trenirati obiÄne mreÅ¾e u **TensorFlowu**, pa ih konvertirati u spiking verziju pomoÄ‡u **Nengo DL toolkita**.
* Planiran sustav **Pohoiki Springs** s:

  * **768 Loihi Äipova**, ~**100 milijuna neurona**, **100 milijardi sinapsi**.
* Fokus: **online uÄenje i fleksibilnost**, ali joÅ¡ uvijek daleko od bioloÅ¡kog mozga (koji ima ~800 trilijuna sinapsi).

---

### ï¸ **DYNAP (Dynamic Neuromorphic Asynchronous Processor) â€“ aiCTX**

* Dvije varijante:

  * **Dynap-se** â†’ optimiziran za **inference (skalabilno izvoÄ‘enje)**
  * **Dynap-le** â†’ optimiziran za **online learning**
* Fokus: **asinkrono, energetski uÄinkovito procesiranje**.

---

###  **Braindrop**

* Prototip jedne jezgre sustava **Brainstorm** (planiran s 1M neurona).
* Programira se pomoÄ‡u **Nengo** i koristi **Neural Engineering Framework (NEF)**.
* Razvijen na **Stanfordu**, nasljednik je **Neurogrid** procesora.
* Fokus: **istraÅ¾ivanje modela neuronskih mreÅ¾a**, **jednostavna integracija u softver**.

---



---

| **Procesor**                | **Broj neurona (â‰ˆ)**                    | **Sinapse (â‰ˆ)**       | **UÄenje na Äipu**       | **Fokus / Namjena**                         | **Primjene s event kamerama**                   | **Posebne znaÄajke**                                                      |
| --------------------------- | --------------------------------------- | --------------------- | ------------------------ | ------------------------------------------- | ----------------------------------------------- | ------------------------------------------------------------------------- |
|  **SpiNNaker**            | Fleksibilno (ovisno o broju ARM jezgri) | Softverski definirano |  Da (softverski modeli) | BioloÅ¡ki realizam, simulacija mozga         | Stereo depth, optic flow, tracking, recognition | Neuronski modeli u softveru â†’ maksimalna fleksibilnost                    |
|  **TrueNorth (IBM)**      | 1 milijun                               | 256 milijuna          |  Ne                     | Real-time inference, niska potroÅ¡nja        | Gesture recognition, stereo, optical flow       | 4096 neurosinaptiÄkih jezgri, trenira se offline (GPU)                    |
|  **Loihi (Intel)**        | 131 tisuÄ‡a (po Äipu)                    | 130 milijuna          |  Da (STDP, RL)          | Online uÄenje, adaptivnost                  | Eksperimentalno za uÄenje u hodu                | TensorFlow + Nengo DL integracija, projekt Pohoiki Springs (100M neurona) |
| ï¸ **DYNAP (aiCTX)**        | TisuÄ‡e po Äipu (ovisno o verziji)       | Nepoznato             |  Da (u Dynap-le)        | Energetska uÄinkovitost, inference/learning | -                                               | Asinkron dizajn, dvije varijante: SE (inference), LE (learning)           |
|  **Braindrop (Stanford)** | 1 jezgra prototip (~1M planirano)       | -                     |  Da                     | IstraÅ¾ivanje neuronskih modela              | -                                               | Koristi Neural Engineering Framework (NEF), Nengo programiranje           |

---


---

### Real-time on-board robotika s event kamerama

**Glavna ideja:**
Event kamere generiraju znatno manje podataka po vremenskom intervalu nego klasiÄne frame-based kamere.
Zbog toga obrada moÅ¾e biti izvedena u stvarnom vremenu na samom ureÄ‘aju, bez potrebe za snaÅ¾nim raÄunalom ili USB prijenosom podataka.

---

### Konkretni primjeri:

1. **Wheeled robot (s ARM mikrokontrolerom)**

   * Dual-core ARM mikrokontroler na 200 MHz s 136 KB RAM-a obraduje evente u stvarnom vremenu.
   * Radi potpuno samostalno, bez vanjskog raÄunala.
   * Izvodi zadatke poput praÄ‡enja linije, aktivnog i pasivnog praÄ‡enja objekata, procjene udaljenosti i jednostavnog mapiranja prostora.
   * Ovaj primjer pokazuje da su event kamere iznimno uÄinkovite i prikladne za robote s vrlo niskom potroÅ¡njom energije.

2. **SpeckSoC11 (edge computing primjer)**

   * Sustav kombinira DVS (Dynamic Vision Sensor) i Dynap-se neuromorfni CNN procesor.
   * PotroÅ¡nja energije manja je od 1 mW, a latencija ispod 30 ms.
   * Primjene ukljuÄuju kontinuiranu detekciju objekata, sustave nadzora i automobilske aplikacije poput detekcije prepreka ili pjeÅ¡aka.

3. **Quadrotori (dronovi)**

   * Event kamere integrirane su u dronove s ograniÄenim raÄunalnim resursima.
   * Koriste se za autonomno slijetanje, navigaciju i let u zahtjevnim uvjetima, poput slabog osvjetljenja ili velikih brzina kretanja.
   * Glavna prednost je vrlo niska latencija i otpornost na zamuÄ‡enje slike pri brzom kretanju.

---

### ZakljuÄak:

- Event kamere omoguÄ‡uju obradu vizualnih informacija izravno na senzoru, u stvarnom vremenu i s minimalnom potroÅ¡njom energije.
- Zbog toga su idealne za primjenu u mobilnim i energetski ograniÄenim sustavima, poput autonomnih robota, dronova i IoT ureÄ‘aja.


DISCUSSION & CONCLUSION
- EBV = computer vision + robotika + neuromorphic engineering
- OmoguÄ‡ava low power consumption (always ON ureÄ‘aji)
- Korisno za embedded aplikacije na platformama s ograniÄenim resursima
- Niska latencija za visoku reaktivnost sustava
- Visoka dostupnost informacija za bolju percepciju okoline
- TroÅ¡i se malo raÄunalnih resursa

- Ne zna se joÅ¡ koji je najbolji naÄin za procesiranje i reprezentaciju evenata (jer ovisi o use case-u)
ViÅ¡e trade-off sluÄajeva:
- latency vs power consumption
- accuracy&sensitivity vs bandwith&processing capacity

npr. Smanjenje kontrast thresholda i/ili poveÄ‡anje rezolucije kreira viÅ¡e evenata (te evente procesira algoritam na platformi s ograniÄenim resursima)
Izazov:
- kvantifikacija opisanih tradeoffova i razvoj tehnika za dinamiÄku prilagodnu senzora i/ili algoritamskih parametara za optimalne performanse
- razvoj bio-inspired sustava koji su event based od poÄetka do kraja (od percepcije do kontrole i aktuacije (uporabe aktuatora))
- razliÄito u odnosu na mainstream deep learning metoda computer visiona (ideja: probati adaptirati postojeÄ‡e koncepte ili razviti sustave za odreÄ‘ene probleme od nule uz Äa bolje performanse)
- active vision -> percepcija + kontrola; posebno relevantno za event kamere jer eventi ovise o pokretima
- event kamera + hardver na istom senzorskom ureÄ‘aju (efikasno, near-sensor procesiranje, samo high level ne-redundantne informacije se Å¡alju; smanjenje bandwitha, latencije i potroÅ¡nje energije)

########################################################################################################################
Fast-Classifying, High-Accuracy Spiking Deep Networks Through Weight and Threshold Balancing

Duboke neuronske mreÅ¾e poput CNN-ova i DBN-ova su zlatna stvar za klasifikaciju u CV-u

CNNs
Main features:
- inspirirane ljudskim vidnim sustavom
- koriste konvolucijske slojeve (filters/kernel) koji klite preko slike i oktrivaju lokalne uzorke (rubovi, teksture etc.)
- imaju pooling slojeve za smanjenje dimenzionalnosti i fully connected slojeve na kraju za klasifikaciju
- dobre za: obradu slika, videa, object recognition, face detection etc.
- uÄe prostorne hijerarhije featurea (from simpler to more complex)

DBNs
Main features:
- sastoje se od viÅ¡e slojeva RBM-ova (Restricted Boltzmann Machines)
- unsupervised learning (prvo uÄe reprezentacije podataka (features), pa se kasnije mogu tunirati za klasifikaciju
- StohastiÄke neuronske jedinice (probabilistiÄki pristup)
- popularne PRIJE pojave CNN-ova (posebno za generative learning i dimensionality reduction)

Similarities:
- obadvoje su multi-layered deep neural networks
- uÄe data representations hijerarhijski
- mogu se koristiti za klasifikaciju, feature extraction i pattern recognition

| ZnaÄajka            | CNN                                     | DBN                                  |
| ------------------- | --------------------------------------- | ------------------------------------ |
| Tip uÄenja          | NajÄeÅ¡Ä‡e **supervizirano**              | **Nesupervizirano** (pre-trening)    |
| Struktura           | Konvolucijski slojevi + pooling + dense | Hijerarhija RBM-ova                  |
| PodruÄje primjene   | Obrada slika, videa                     | Generativni modeli, feature learning |
| NaÄin rada          | DeterministiÄki                         | ProbabilistiÄki                      |
| Brzina i efikasnost | BrÅ¾i, lakÅ¡e trenira                     | Sporiji, teÅ¾e trenira                |

- SNN-ovi omoguÄ‡avaju da nadiÄ‘emo velike computational troÅ¡kove kod obiÄnih CNN-ova

- Spiking deep networks su predloÅ¾eni kako bi se smanjio veliki raÄunski troÅ¡ak dubokih mreÅ¾a

- IskoriÅ¡tavaju specijalizirani hardver za spiking neural networks (SNNs)

- Konverzija iz analognih neuralnih mreÅ¾a (ANNs) u SNNs uzrokuje gubitke performansi

- Glavni razlog gubitaka je prelazak s kontinuiranih (bez pojma vremena) ANNs na rijetko aktivirane, event-driven SNNs

- Analizira se utjecaj konverzije ANNs u SNNs u odnosu na parametre spike neurona, poput frekvencije aktivacije (firing rate) i praga aktivacije (threshold)

- Postoji set optimizacijskih tehnika za minimizaciju gubitka performansi u procesu konverzije za CNN-ove i fully connected deep networks
- Takve mreÅ¾e nadmaÅ¡uju sve prethodne SNN-ove raÄ‘ene na MNISTU i jako dobro rade u vidu performansi

- Koristi se ReLU (rectified linear units) bez biasa za vrijeme treniranja, koristeÄ‡i novu weight normalizaciju za reguliranje fire-ratea

- Cilj: fast&efficient pattern recognition

- Duboke neuronske mreÅ¾e (konvolucijske) su fully connected feed forward neural networks
- Trenutno su jedna od najuspjeÅ¡nijih arhitektura za image classification

Record-breaking results za: handwriting recognition, scene labeling, CIFAR i ImageNet benchmarkse

Networks inspired by hierarchies of cortical visual information processing
UspjeÅ¡ne su, ali ima znaÄajan troÅ¡ak resursa pri treniranju i runnanju
Stoga, potreban je specijalizirani hardver + akcelaracija istog
Potreba za razvojem novih raÄunalnih paradigmi koji Ä‡e omoguÄ‡iti uporabu deep networka za real-time praktiÄne primjene

SNN-ovi su primarni kandidati za omoguÄ‡avanje takve akceleracije

Nova metoda optimizacija za Spiking deep arhitekture ( i za full connected feed forward networke i za conv. networks)
Niska latencija + manje potrebnih raÄunskih operacija u usporedbi s konvencionalnim computingom
Cilj: izgraditi biologically realistic neuarl networks

Neuromorphic plathorms => emuliranje brain-like spike-based raÄunanja na analognom ili digitalnom hardveru
Puno efikasnije od CPUova i GPUova (posebno za spiking networkse)
OmoguÄ‡avaju distribuirano, asinkrono event-based raÄunanje
Skalabilno i s minimalnom latencijom
Sustavi se fokusiraju na trenutno aktivne djelove networka i tako Å¡tede energiju na drugim djelovima networka
Koriste input neuromorfnih senzora (poput silicon retine)
Kreiraju se sparse, frame-free, precizno tempirani streamovi evenata s puno manje latencije u usporedbi s frame-based pristupima

Treniranje spiking deep networka tipiÄno ne koristi spike-based learning pravila, nego poÄinje s konvencionalnim ANN-ovima treniranima pomoÄ‡u backpropagacije
Zatim se taj rate-based model konvertira u model saÄinjen od jednostavnih spiking neurona

Malo je teÅ¡ko trenirati SNN-ove.
Teorija pokazuje da su SNN-ovi barem jednako raÄunski moÄ‡ni kao i njihovi analogni ekvivalenti (ANN-ovi), ali je u praksi teÅ¡ko postiÄ‡i ekvivalentne rezultate
Jedan pristup trenira spiking DBN-ove pomoÄ‡u Siegert aproksimacije srednje brzine aktivacije (mean-firing-rate) LIF neurona kako bi se aproksimirale vjerojatnosti tijekom treniranja
Drugi pristup zahtijeva podeÅ¡avanje parametara poput "leak" i "refractory period" u spiking mreÅ¾i
Oba pristupa pate od znaÄajnog gubitka toÄnosti klasifikacije u usporedbi s ne-spiking mreÅ¾ama sliÄne arhitekture
Nedavno je predloÅ¾ena metoda konverzije spiking ConvNet mreÅ¾a koja uzima u obzir razlike izmeÄ‘u spiking i ne-spiking mreÅ¾a, te postiÅ¾e bolje performanse od prijaÅ¡njih metoda
Glavni izazovi su reprezentacija negativnih vrijednosti i bias-a u spiking neuronima
Ti problemi se izbjegavaju koriÅ¡tenjem ReLU aktivacija i postavljanjem svih bias vrijednosti na nulu
Max-pooling se zamjenjuje prostornim linearnim subsamplingom
I dalje postoji manji gubitak performansi nakon konverzije
Autori analiziraju izvore tih gubitaka i predlaÅ¾u alate za optimizaciju
ZakljuÄuju da ako se SNN-ovi pokreÄ‡u u odgovarajuÄ‡em reÅ¾imu, mogu postiÄ‡i gotovo bezgubitnu konverziju i vrlo brzu klasifikaciju uz samo nekoliko izlaznih spikeova

* U potpuno povezanim feed-forward neuronskim mreÅ¾ama (FCNs), svaki neuron u jednom sloju povezan je sa svim neuronima u sljedeÄ‡em sloju, bez veza unutar istog sloja
* Nedavna istraÅ¾ivanja ponovno su pobudila interes za ovu arhitekturu zbog natjecateljskih rezultata
* KljuÄne toÄke uspjeÅ¡nog treniranja FCN-a su pravilna inicijalizacija teÅ¾ina kako bi se oÄuvao gradijent pogreÅ¡ke i regularizacija radi sprjeÄavanja overfittinga
* Kombinacija dropout tehnike i ReLU aktivacija dovela je do znaÄajnih poboljÅ¡anja performansi
* ReLU (Rectified Linear Unit) je nelinearna funkcija definirana kao xi = max(0, Î£(wij * xj))
* ReLU omoguÄ‡uje jednostavnu i uÄinkovitu propagaciju signala kroz mreÅ¾u
* Aktivacije se iterativno aÅ¾uriraju sloj po sloj kako bi se ulaz propagirao do izlaznih neurona koji oznaÄavaju predikciju klase

* Trening se nastavlja pomoÄ‡u standarne backpropagacije greÅ¡ke
* Gradijent funkcije greÅ¡ke se propagira unazad po layerima
* RaÄunaju se lokalne derivacije da bi se updateali lokalni weightovi i minimizirala greÅ¡ka
* Trening sluÅ¾i za prilagodbu nasumiÄno inicijalizirani matrice weightova koji opisuju veze izmeÄ‘u layera da bi se greÅ¡ka minimizirala koristeÄ‡i stohastiÄki gradijentni spust

* Konvolucijske neuronske mreÅ¾e (ConvNets ili CNNs) su viÅ¡eslojne feed-forward arhitekture koje koriste konvolucijske jezgre (kernels) kao detektore znaÄajki
* TipiÄno se sastoje od naizmjeniÄnih slojeva konvolucije i prostornog subsamplinga (poolinga), uz nelinearnu aktivaciju izmeÄ‘u njih
* Svaki konvolucijski sloj generira skup feature mapa konvoluiranjem prethodnih aktivacija s jezgrama Wk i dodavanjem bias termina bk
* Aktivacija svakog feature mapa definira se kao xk = f(Wk * xl + bk), gdje je f nelinearna funkcija (ovdje ReLU)
* Jezgre reagiraju samo na male lokalne dijelove ulazne slike i primjenjuju se pomicanjem preko cijelog ulaza (weight sharing)
* Nakon konvolucije slijedi pooling ili subsampling sloj koji kombinira odgovore viÅ¡e feature detektora u jednu vrijednost
* U ovom radu koriÅ¡ten je **average pooling** radi bolje prenosivosti ConvNeta u SNN
* ConvNet smanjuje dimenzionalnost podataka dok istovremeno generira apstraktnije znaÄajke
* Zbog manjeg broja teÅ¾ina u odnosu na potpuno povezane mreÅ¾e, manja je moguÄ‡nost overfittinga
* Izlaz CNN-a Äini spajanje svih feature mapa iz zadnjeg sloja, Å¡to se zatim koristi kao ulaz u jednostavnu potpuno povezanu mreÅ¾u za klasifikaciju
* Treniranje se vrÅ¡i stohastiÄkim gradijentnim spuÅ¡tanjem i backpropagacijom, uz dijeljenje teÅ¾ina u konvolucijskim slojevima

* Overfitting je Äest problem kod velikih i dubokih neuronskih mreÅ¾a
* Dropout tehnika djeluje kao regularizator koji sprjeÄava overfitting
* Dropout sluÄajno iskljuÄuje odreÄ‘ene neuronske jedinice (ulaze ili skrivene neurone) tijekom treniranja
* Na taj naÄin se izbjegava prevelika specijalizacija i meÄ‘usobna ovisnost skrivenih jedinica
* U ovom radu dropout se koristi u sklopu ReLU aktivacijske funkcije kao maska koja sluÄajno iskljuÄuje odreÄ‘ene ReLU aktivacije
* Formula za ReLU s dropoutom: xi = max(0, Î£(wij * xj)) s vjerojatnoÅ¡Ä‡u dr, ili 0 inaÄe
* Dropout stopa (dr) odreÄ‘uje udio jedinica koje se iskljuÄuju pri svakom trening koraku
* TipiÄna vrijednost dr je 0.5, Å¡to znaÄi da se nasumiÄno iskljuÄi polovica veza tijekom svake iteracije treninga
* Rezultat je poveÄ‡ana robusnost mreÅ¾e i bolja generalizacija na nove podatke

Arhitektura FCN (Fully Connected Feed-forward Neural Networks)
* Svaki neuron u jednom sloju povezan je sa svim neuronima u sljedeÄ‡em sloju.

* Nema poveznica unutar istog sloja (nema intra-layer konekcija).

* Takva mreÅ¾a se zove feed-forward jer se informacija kreÄ‡e samo u jednom smjeru â€“ od ulaza prema izlazu

Dobre performanse
KljuÄni faktori:
- dobra inicijalizacija weightove => stabilno Å¡irenje gradijenta (bez gubitka signala kroz layere)
- regularizacija => sprijeÄava overfittinga

Bitne tehniÄke komponente:

Dropout (regularizacijska tehnika)

NasumiÄno iskljuÄuje odreÄ‘ene neurone tijekom treniranja â†’ spreÄava njihovu meÄ‘usobnu ovisnost.

Time se model uÄi robustnije, smanjuje overfitting i poboljÅ¡ava generalizaciju.
---

## ğŸ”¹ **ReLU-temeljene feed-forward neuronske mreÅ¾e (FCN)**

### ğŸ§  Osnovna ideja

* **Feed-forward neuronska mreÅ¾a (FCN)** je tip mreÅ¾e u kojoj:

  * Svaki **neuron iz jednog sloja povezan je sa svim neuronima sljedeÄ‡eg sloja** (*fully connected*).
  * **Nema veza unutar istog sloja** (*no intra-layer connections*).
* Informacija teÄe **jednosmjerno â€” od ulaza prema izlazu**.

---

### âš™ï¸ **Razlozi ponovne popularnosti**

* Nedavni uspjesi u istraÅ¾ivanjima pokazali su da FCN-ovi mogu **postiÄ‡i vrlo konkurentne rezultate**.
* KljuÄni preduvjeti za visoke performanse:

  * **Dobra inicijalizacija teÅ¾ina** â†’ sprjeÄava problem nestajanja ili eksplozije gradijenata i osigurava stabilno uÄenje.
  * **Regularizacija** â†’ smanjuje rizik od **overfittinga** (prenauÄenosti).

---

### ğŸ”¸ **NajvaÅ¾nija poboljÅ¡anja**

1. **Dropout tehnika**

   * Tijekom treniranja **nasumiÄno "iskljuÄuje" neke neurone**, tako da mreÅ¾a ne postane previÅ¡e ovisna o odreÄ‘enim znaÄajkama.
   * Rezultat: **robustniji i generaliziraniji model**.

2. **ReLU (Rectified Linear Unit)**

   * Vrlo jednostavna, ali uÄinkovita **nelinearna aktivacijska funkcija**:
     [
     x_i = \max(0, \sum_j w_{ij}x_j)
     ]
   * ZnaÄenje:

     * ( x_i ): aktivacija neurona *i*
     * ( w_{ij} ): teÅ¾ina izmeÄ‘u neurona *j* i *i*
     * ( x_j ): izlaz neurona *j* iz prethodnog sloja
   * **Prednosti ReLU-a:**

     * Ubrzava uÄenje
     * SprjeÄava problem saturacije gradijenata
     * Daje **rijetke aktivacije** (mnogi neuroni imaju 0 â†’ uÄinkovitija mreÅ¾a)

---

### ğŸ”¹ **Kako se informacije Å¡ire**

* MreÅ¾a **sloj po sloj izraÄunava aktivacije** na temelju prethodnog sloja.
* Na kraju se **aktiviraju izlazni neuroni** koji predstavljaju rezultat modela (npr. klasnu oznaku).

---

### ğŸ”§ **Proces treniranja**

* Koristi se **standardni algoritam povratnog Å¡irenja pogreÅ¡ke (backpropagation)**:

  * PogreÅ¡ka na izlazu **propagira se unazad kroz mreÅ¾u**, sloj po sloj.
  * RaÄunaju se **lokalne derivacije** za svaki neuron.
  * **TeÅ¾ine se aÅ¾uriraju** u smjeru koji minimizira ukupnu pogreÅ¡ku.
* Optimizacija se izvodi pomoÄ‡u **stohastiÄkog gradijentnog spusta (SGD)**.
* TeÅ¾ine su u poÄetku **nasumiÄno inicijalizirane**, a zatim se uÄe kroz iteracije.

---

### âœ… **ZakljuÄak**

* Kombinacijom **ReLU aktivacija**, **dropout regularizacije**, i **dobro inicijaliziranih teÅ¾ina**,
  FCN-ovi mogu postiÄ‡i **vrlo visoke performanse** na standardnim skupovima podataka.
* Takva kombinacija je postala **temelj suvremenih dubokih neuronskih mreÅ¾a**.

---

## ğŸ”¹ **Konvolucijske neuronske mreÅ¾e (ConvNets / CNNs)**

### ğŸ§  **Osnovna ideja**

* **CNN** je **viÅ¡eslojna feed-forward arhitektura** (kao FCN), ali:

  * Umjesto punih veza, koristi **konvolucijske filtre (kernels)** kao detektore znaÄajki (feature detectors).
* Sastoji se od **izmjeniÄnih slojeva konvolucije i prostornog poduzorkovanja (subsampling/pooling)**, s **nelinearnom funkcijom aktivacije** izmeÄ‘u njih.

---

### âš™ï¸ **Konvolucijski sloj**

* Svaki konvolucijski sloj stvara **viÅ¡e â€œfeature mapaâ€**.

* Svaka mapa ( x_k ) dobiva se **konvolucijom** aktivacija prethodnog sloja s odgovarajuÄ‡im kernelom ( W_k ):
  [
  x_k = f(l * W_k + b_k)
  ]
  gdje je:

  * ( f ): aktivacijska funkcija (ovdje ReLU)
  * ( l ): aktivacija prethodnog sloja
  * ( * ): 2D konvolucijska operacija (valid-region)
  * ( b_k ): bias (pomak)

* Kernel (filter) **"klizi" po cijelom ulaznom prostoru** i reagira samo na **mala lokalna podruÄja** (lokalna receptivna polja).
  â†’ Time se mreÅ¾a fokusira na **lokalne uzorke** (rubove, teksture, oblike).

---

### ğŸ”¸ **Pooling (subsampling) sloj**

* Slijedi iza konvolucijskog sloja.
* **Smanjuje dimenzionalnost podataka** kombiniranjem odgovora viÅ¡e detektora znaÄajki u jedan izlaz.
* U ovom radu koriste se **average pooling slojevi** (prosjeÄni kernel) â€” umjesto max poolinga â€” kako bi se mreÅ¾a lakÅ¡e prenijela u **spiking neuronsku mreÅ¾u (SNN)**.
* Aktivacija pooling sloja je kao i u jednadÅ¾bi (2), ali s fiksnim teÅ¾inama:
  [
  W_{kij} = \frac{1}{\text{size}(W_k)}
  ]
  gdje je *size(Wk)* broj piksela u kernelu.

---

### ğŸ”¹ **KljuÄne prednosti CNN-ova**

1. **Smanjena dimenzionalnost podataka**

   * NaizmjeniÄni slojevi konvolucije i pooling-a **postupno reduciraju prostorne informacije**, dok poveÄ‡avaju **apstrakciju znaÄajki**.

2. **Manji broj teÅ¾ina**

   * Zbog **dijeljenja teÅ¾ina (weight sharing)** u konvolucijskim slojevima, CNN-ovi imaju **znatno manje parametara** od potpuno povezanih mreÅ¾a (FCN).
   * To **smanjuje overfitting** i ubrzava treniranje.

3. **UÄinkovito uÄenje reprezentacija**

   * Donji slojevi uÄe **jednostavne uzorke** (rubovi, boje, teksture).
   * ViÅ¡i slojevi kombiniraju te uzorke u **sloÅ¾enije znaÄajke** (oblici, dijelovi objekata, cijeli objekti).

---

### ğŸ”§ **Treniranje CNN-a**

* Izvodi se pomoÄ‡u **stohastiÄkog gradijentnog spusta (SGD)** i **backpropagationa** â€” isto kao kod FCN-a.
* **TeÅ¾ine konvolucijskih filtera (Wk)** i teÅ¾ine zavrÅ¡nog **klasifikacijskog sloja (FC sloj)** uÄe se zajedno.
* **Dijeljenje teÅ¾ina (weight sharing)** dodatno smanjuje broj parametara i stabilizira uÄenje.

---

### ğŸ§© **Izlaz mreÅ¾e**

* **Sve feature mape iz posljednjeg konvolucijskog sloja se spajaju (concatenate)**.
* Dobiveni vektor ulazi u **jednostavnu potpuno povezanu mreÅ¾u (FCN)** koja sluÅ¾i kao **klasifikator**.

---

### âœ… **ZakljuÄak**

* CNN-ovi kombiniraju **konvolucijske slojeve + pooling + ReLU + weight sharing**,
  Äime:

  * smanjuju broj parametara,
  * ublaÅ¾avaju overfitting,
  * i proizvode **sve apstraktnije znaÄajke**.
* Na kraju, FC sloj klasificira izlaz â†’ Äitav sustav se trenira putem **SGD + backpropagation**.

---


---

## ğŸ”¹ **Dropout tehnika**

### âš ï¸ **Problem: Overfitting**

* **Overfitting (prenauÄenost)** je Äest problem kod **velikih i dubokih neuronskih mreÅ¾a**.
* Dogodi se kad se mreÅ¾a **previÅ¡e prilagodi trening podacima**, pa loÅ¡e generalizira na nove (testne) podatke.

---

### ğŸ’¡ **RjeÅ¡enje: Regularizacija**

* Da bi se izbjegao overfitting, uvode se **regularizacijske metode**.
* Jedna od najuspjeÅ¡nijih i najpopularnijih je upravo **dropout tehnika**.

---

### ğŸ§  **Å to je dropout**

* Tijekom uÄenja, **nasumiÄno se â€œiskljuÄujuâ€ (onemoguÄ‡uju) odreÄ‘ene jedinice (neuroni)**.
* Time se sprjeÄava da se neuroni **meÄ‘usobno previÅ¡e â€œnaviknuâ€ jedni na druge** (tj. sprjeÄava **ko-adaptacija**).
* To tjera mreÅ¾u da nauÄi **robustnije znaÄajke**, koje bolje generaliziraju.

---

### ğŸ”§ **Kako se dropout primjenjuje**

* Dropout se u ovom radu koristi **unutar ReLU aktivacijske funkcije**, kao **maska** koja sluÄajno onemoguÄ‡uje dio ReLU aktivacija.
* Time se **poveÄ‡ava robusnost mreÅ¾e**.

---

### ğŸ”¹ **MatematiÄki prikaz (jednadÅ¾ba 3)**

[
x_i =
\begin{cases}
\max(0, \sum_j w_{ij}x_j), & \text{s vjerojatnoÅ¡Ä‡u } (1 - d_r) \
0, & \text{inaÄe}
\end{cases}
]
gdje je:

* ( x_i ) â†’ aktivacija neurona *i*
* ( w_{ij} ) â†’ teÅ¾ina izmeÄ‘u neurona *j* i *i*
* ( x_j ) â†’ aktivacija prethodnog neurona
* ( d_r ) â†’ **dropout stopa (dropout rate)**, tj. vjerojatnost da Ä‡e se neuron iskljuÄiti

---

### ğŸ” **Mehanizam uÄenja**

* Na **svakom trening koraku** (iteraciji), **donosi se nova nasumiÄna odluka za svaki neuron** â€” hoÄ‡e li biti aktivan ili ne.
* Tijekom inferencije (testiranja), dropout se **iskljuÄuje**, ali se izlazi **skaliraju** tako da reflektiraju prosjeÄan uÄinak tijekom treniranja.

---

### ğŸ”¢ **TipiÄne vrijednosti**

* U praksi se Äesto koristi **dropout rate ( d_r = 0.5 )**
  â†’ znaÄi da se **polovica veza nasumiÄno iskljuÄi** u svakom koraku treniranja.

---

### âœ… **KljuÄne prednosti**

* Smanjuje overfitting.
* PotiÄe mreÅ¾u da nauÄi **distribuirane i stabilnije reprezentacije**.
* PoboljÅ¡ava **generalizaciju i otpornost** na Å¡um u podacima.
* Jednostavan i vrlo uÄinkovit dodatak koji se moÅ¾e koristiti s bilo kojom aktivacijom (ali ReLU + dropout = zlatna kombinacija).

---

- U klasiÄnim ANN-ovima, cijeli input vector "unosi" se istovremeno, pa procesira layer po layer i stvara 1 output vrijednost
- U SNN-ovima, inputi su tipiÄno streamovi evenata i neuroni stvaraju spikeove na temelju tih evenata
- Spikeovi sluÅ¾e za komunikaciju sa svim layerima i na kraju dovode do "firea" kod output neurona
- Fire se sumira kroz vrijeme
- Input i output su pseudosimultani
- Time-varying inputi se mogu efikasno procesirati
- super za raÄuanje na specijaliziranim hardverima

---

## ğŸ”¹ **Spiking neuron model â€“ Integrate-and-Fire (IF)**

### ğŸ§  **Osnovna ideja**

* Koristi se **jednostavni Integrate-and-Fire (IF)** model neurona.
* To je **bioloÅ¡ki inspiriran model**, gdje neuron akumulira (integrira) ulazne impulse i ispaljuje *spike* kad dosegne odreÄ‘eni prag.

---

### âš™ï¸ **Evolucija membranskog napona**

* Membranski napon neurona oznaÄava se kao ( v_{mem}(t) ).
* Njegova promjena kroz vrijeme opisana je diferencijalnom jednadÅ¾bom:
  [
  \frac{dv_{mem}(t)}{dt} = \sum_i w_i \sum_s \delta(t - s_i)
  ]
  gdje je:

  * ( w_i ) â†’ teÅ¾ina *i*-tog dolaznog sinapsnog spoja
  * ( \delta(t - s_i) ) â†’ **Dirac delta funkcija** koja predstavlja dolazak spike-a u trenutku ( s_i )
  * ( S_i = {t^0_i, t^1_i, ...} ) â†’ skup vremena kada *i*-ti presinaptiÄki neuron puca (emitira spike)

---

### âš¡ **NaÄin rada neurona**

1. **Integracija:**

   * Neuron **zbraja dolazne impulse** (spikes) ponderirane teÅ¾inama ( w_i ).
   * Time se poveÄ‡ava njegov membranski potencijal ( v_{mem} ).

2. **Ispaljivanje spike-a (Fire):**

   * Kad ( v_{mem} ) **prijeÄ‘e prag pobude ( v_{thr} )** â†’ neuron **generira spike** (akcijski potencijal).

3. **Resetiranje:**

   * Nakon Å¡to neuron ispali spike, njegov membranski napon se **resetira na vrijednost ( v_{res} )**.
   * Zatim ciklus integracije poÄinje iznova.

---

### â±ï¸ **Diskretizacija u simulacijama**

* U simulacijama se ovaj **kontinuirani model** aproksimira **diskretnim vremenskim koracima od 1 ms**.
  â†’ To znaÄi da se napon i spike-ovi aÅ¾uriraju u **milisekundnim intervalima**.
  â†’ Takva aproksimacija olakÅ¡ava digitalnu implementaciju modela (npr. u PyTorch-u ili simulacijskim alatima).

---

### âœ… **KljuÄne znaÄajke IF modela**

* Jednostavan, ali uÄinkovit model neuronskog ponaÅ¡anja.
* Hvata osnovnu dinamiku bioloÅ¡kog neurona (integracija i ispaljivanje).
* Koristi se kao **temelj za izgradnju sloÅ¾enijih SNN arhitektura** (npr. LIF â€“ Leaky Integrate-and-Fire).
* Idealno za **simulacije s vremenskom diskretizacijom** i **neuralne Äipove (neuromorfne sustave)**.

---

- Spiking network conversion

- Konverzija deep ANN-ova u SNN-ove
- Redukcija gubitka perfomransi tijekom konverzije
- Normalizacija + analiza firing rateova i thresholda

---

## ğŸ”¹ **Veza izmeÄ‘u ReLU ANNs i SNN-ova**

1. **ReLU â‰ˆ firing rate IF neurona**

   * ReLU moÅ¾e se smatrati **aproksimacijom broja spike-ova IF neurona** u zadanom vremenskom prozoru.
   * Bez refraktornog perioda, izlaz ReLU-a je proporcionalan broju spike-ova.

2. **Prednosti ReLU-a za treniranje**

   * Njihova **piecewise linear derivacija** omoguÄ‡uje **jednostavne i stabilne update-e teÅ¾ina**.
   * Za klasifikacijske zadatke, vaÅ¾na je samo **maksimalna aktivacija izlaznog sloja**, pa se **sve stope moÅ¾e skalirati konstantom**.

3. **Skala teÅ¾ina je vaÅ¾na**

   * Ako je bias fiksiran na 0, jedino Å¡to utjeÄe su **omjeri teÅ¾ina meÄ‘u neuronima i njihov prag (threshold)**.

---

## ğŸ”¹ **Recept za konverziju ANN â†’ SNN**

1. Koristiti **ReLU aktivacije** za sve jedinice mreÅ¾e.
2. Fiksirati **bias na nulu** i trenirati mreÅ¾u normalnim **backpropagationom**.
3. **Izravno mapirati teÅ¾ine** iz ReLU mreÅ¾e u IF neuronsku mreÅ¾u.
4. Primijeniti **normalizaciju teÅ¾ina** (weight normalization) â†’ postiÅ¾e se **skoro bez gubitka toÄnosti i brÅ¾a konvergencija**.

> Ove metode rade za **FCN i ConvNet** arhitekture.

---

## ğŸ”¹ **Potencijalni gubici performansi nakon konverzije**

1. **Nedovoljno ulaza za spike**

   * Neuron ne prelazi prag â†’ njegova frekvencija spike-ova je manja od oÄekivane.

2. **PreviÅ¡e ulaza / over-aktivacija**

   * ReLU predviÄ‘a viÅ¡e od jednog spike-a po timestepu.
   * MoÅ¾e se dogoditi zbog:

     * PreviÅ¡e spike-ova u jednom timestepu.
     * TeÅ¾ine ulaza veÄ‡e od praga neurona.

3. **ProbabilistiÄka priroda spike-ova**

   * Spike-trains nisu uniformni â†’ moÅ¾e doÄ‡i do **prekomjerne ili nedovoljno jake aktivacije odreÄ‘enih znaÄajki**.

---

## ğŸ”¹ **Kako ublaÅ¾iti probleme**

* **Smanjiti timestep simulacije** â†’ smanjuje broj spike-ova po timestepu.
* **PoveÄ‡ati trajanje simulacije** â†’ sprjeÄava nedovoljnu aktivaciju.
* **PronaÄ‡i ravnoteÅ¾u izmeÄ‘u:**

  * Spiking threshold (prag za spike)
  * TeÅ¾ina ulaznih sinapsi
  * Firing rate ulaza

> Visok prag (ili niske ulazne teÅ¾ine) â†’ smanjuje over-aktivaciju, ali poveÄ‡ava under-aktivaciju.
> Nizak prag (ili visoke teÅ¾ine) â†’ smanjuje under-aktivaciju, ali poveÄ‡ava over-aktivaciju.

* **KljuÄ:** Samo **omjer praga i ulaznih teÅ¾ina** odreÄ‘uje integriranu vrijednost do spike-a, ne njihove apsolutne vrijednosti.

---

## ğŸ”¹ **RjeÅ¡enje za preciznu konverziju**

* Umjesto ruÄnog podeÅ¡avanja:

  * **IzraÄunati faktore reskaliranja teÅ¾ina** â†’ smanjuju greÅ¡ke iz **tri gore navedena uzroka** (under-aktivacija, over-aktivacija, neidealni spike-trains).

---

- Smanjenje timestampa u simulaciji moÅ¾e pomoÄ‡i za smanjenje broja input spikeova po timestepu i poveÄ‡anje trajanja simulacije pomaÅ¾e izbjeÄ‡i nedovoljne aktivacije

- Bitno je izbalansirati spiking thresholdse, input weights i input firing rates
- Visoki spiking threshold (ili niski input weights) smanjuju errore uzrokovane over-aktivacijom i ne-idealnim spikre trainovima, ali poveÄ‡ava greÅ¡ke zbog under-aktivacije i obratno

- samo omjer spiking thresholda i input weightova odreÄ‘uje akumuliranu koliÄinu inputa za spiking, ali ne i vrijednosti pojedinih impulsa

ğŸ”¹ Glavni doprinos rada

Uvedena je nova metoda normalizacije teÅ¾ina (weight normalization).

Cilj: dovesti mreÅ¾u u stabilan reÅ¾im rada, gdje se izbjegavaju problemi poput:

neuroni koji previÅ¡e spikaju (overactivation),

neuroni koji premalo spikaju (underactivation),

netoÄne procjene izlaza zbog previsokih ReLU aktivacija.

ğŸ”¹ Ideja normalizacije

Å½elimo ograniÄiti aktivacije tako da:

ReLU ne precjenjuje izlaz neurona.

Neuron ne moÅ¾e proizvesti viÅ¡e od jednog spike-a u istom trenutku.

ğŸ”¹ Model-based normalizacija (konzervativna metoda)

Za svaki sloj razmatraju se sve moguÄ‡e pozitivne aktivacije.

IzraÄuna se maksimalni moguÄ‡i pozitivni ulaz u sloj.

Sve teÅ¾ine u tom sloju se skaliraju tako da taj maksimalni ulaz proizvede najviÅ¡e jedan spike.

ğŸ”¹ Prednosti

MreÅ¾a postaje robustna na vrlo visoke ulazne stope (input rates).

Eliminiraju se gubici zbog previÅ¡e ulaznih spike-ova.

ğŸ”¹ Nedostatak

Potrebno viÅ¡e vremena da neuron akumulira dovoljno dokaza za spike.
â†’ dulje vrijeme simulacije, sporija reakcija.

ğŸ”¹ Kada koristiti

Ako je visoka toÄnost klasifikacije prioritet.

Ako su dulja vremena uzorkovanja prihvatljiva.

ğŸ”¹ Naziv metode

Zove se Model-Based Normalization jer koristi samo teÅ¾ine mreÅ¾e â€”
ne zahtijeva podatke iz stvarnih uzoraka (temelji se na modelu, ne na podacima).

SavrÅ¡eno! Evo ti **detaljne natuknice** iz tog dijela o **data-based normalizaciji teÅ¾ina** â€” jasno i saÅ¾eto:

---

## ğŸ”¹ **Data-Based Normalization (normalizacija temeljena na podacima)**

### ğŸ”¸ Osnovna ideja

* Umjesto najgoreg moguÄ‡eg sluÄaja (kao kod model-based metode),
  koristi se **stvarno ponaÅ¡anje mreÅ¾e na trening skupu** za procjenu tipiÄnih aktivacija.
* Time se dobiva **manje konzervativna** metoda koja Äuva toÄnost, ali ubrzava obradu.

---

### ğŸ”¸ Postupak

1. Nakon Å¡to se trenira ReLU mreÅ¾a,
   **propagira se cijeli trening skup** kroz mreÅ¾u.
2. Pohranjuju se **ReLU aktivacije** za sve neurone.
3. TeÅ¾ine se **normaliziraju** prema **maksimalnoj aktivaciji** koja se pojavila u trening skupu,
   tako da ta aktivacija proizvede **samo jedan spike**.
4. U obzir se uzima i **maksimalna pojedinaÄna ulazna teÅ¾ina** â€”
   da se sprijeÄi situacija gdje **jedan spike nosi previÅ¡e teÅ¾ine**,
   prisiljavajuÄ‡i neuron da spike-a viÅ¡e puta u istom timestepu.

---

### ğŸ”¸ Prednosti

* **Manje konzervativna** od model-based metode â†’ **brÅ¾a konvergencija**.
* **ZadrÅ¾ava gotovo svu toÄnost** (minimalan gubitak performansi).
* **Znatno kraÄ‡e vrijeme integracije dokaza** (kraÄ‡e trajanje simulacije).
* Idealna za **ravnoteÅ¾u izmeÄ‘u toÄnosti i brzine reakcije**.

---

### ğŸ”¸ OgraniÄenja

* **Nema jamstva** da Ä‡e performanse biti jednake na test skupu,
  ali ako je trening skup **reprezentativan**, rezultati su **vrlo pouzdani**.

---

### ğŸ”¸ Kada koristiti

* Kad Å¾eliÅ¡ **visoku toÄnost** + **kratke latencije** (brz rad).
* OdliÄna za **praktiÄne implementacije** gdje trebaÅ¡ balans performansi i brzine.

---

### ğŸ”¸ KljuÄna razlika od model-based metode

| ZnaÄajka          | Model-Based Normalization   | Data-Based Normalization                  |
| ----------------- | --------------------------- | ----------------------------------------- |
| Temelj            | Na teÅ¾inama modela          | Na stvarnim aktivacijama iz trening skupa |
| Konzervativnost   | Visoka (sigurna, ali spora) | Niska (brÅ¾a, ali s rizikom)               |
| Brzina simulacije | Spora                       | Brza                                      |
| ToÄnost           | Vrlo visoka                 | Gotovo jednaka, uz manju latenciju        |
| Naziv             | Model-based                 | Data-based                                |

---
OdliÄno! ğŸ‘
Ovo Å¡to si zalijepio su pseudokodovi za **model-based** i **data-based** normalizaciju teÅ¾ina â€” i toÄno tako se u radu i predstavljaju (Algorithm 1 i Algorithm 2).
Sad Ä‡u ti ih **prepisati i pojasniti korak po korak na hrvatskom**, da dobijeÅ¡ jasan intuitivan osjeÄ‡aj Å¡to svaka verzija radi i u Äemu se razlikuju.

---

## ğŸ”¹ **Algorithm 1 â€“ Model-Based Weight Normalization**

### ğŸ’¡ Ideja

Cilj: osigurati da **nijedan neuron ne moÅ¾e proizvesti viÅ¡e od jednog spike-a** za maksimalni moguÄ‡i ulaz.
â†’ MreÅ¾a postaje vrlo stabilna i robusna, ali zahtijeva dulju simulaciju.

### ğŸ§  Logika pseudokoda

```python
for layer in layers:
    max_pos_input = 0

    # 1ï¸âƒ£ NaÄ‘i maksimalni moguÄ‡i pozitivan ulaz u sloj
    for neuron in layer.neurons:
        input_sum = 0
        for input_wt in neuron.input_wts:
            input_sum += max(0, input_wt)
        max_pos_input = max(max_pos_input, input_sum)

    # 2ï¸âƒ£ Normaliziraj sve teÅ¾ine u sloju
    for neuron in layer.neurons:
        for input_wt in neuron.input_wts:
            input_wt = input_wt / max_pos_input
```

### ğŸ” ObjaÅ¡njenje

* Za svaki sloj se traÅ¾i **najveÄ‡a moguÄ‡a suma pozitivnih teÅ¾ina** (pretpostavlja se da svi ulazi mogu biti maksimalno aktivni).
* Sve teÅ¾ine se potom **skaliraju** tako da ta maksimalna kombinacija proizvodi **jedan spike**.
* Dakle: sigurnije, ali sporije â€” treba viÅ¡e vremena da neuron â€nabereâ€ dovoljno energije za spike.

---

## ğŸ”¹ **Algorithm 2 â€“ Data-Based Weight Normalization**

### ğŸ’¡ Ideja

Koristi **stvarne aktivacije iz trening skupa** umjesto najgoreg sluÄaja.
â†’ BrÅ¾a mreÅ¾a, zadrÅ¾ava toÄnost, ali malo manje konzervativna.

### ğŸ§  Logika pseudokoda

```python
previous_factor = 1

for layer in layers:
    max_wt = 0
    max_act = 0

    # 1ï¸âƒ£ PronaÄ‘i najveÄ‡u teÅ¾inu i najveÄ‡u ReLU aktivaciju u sloju
    for neuron in layer.neurons:
        for input_wt in neuron.input_wts:
            max_wt = max(max_wt, input_wt)
        max_act = max(max_act, neuron.output_act)

    # 2ï¸âƒ£ IzraÄunaj faktor skaliranja
    scale_factor = max(max_wt, max_act)
    applied_factor = scale_factor / previous_factor

    # 3ï¸âƒ£ Skaliraj teÅ¾ine u sloju
    for neuron in layer.neurons:
        for input_wt in neuron.input_wts:
            input_wt = input_wt / applied_factor

    # 4ï¸âƒ£ Spremi faktor za sljedeÄ‡i sloj
    previous_factor = scale_factor
```

### ğŸ” ObjaÅ¡njenje

* Nakon treniranja ReLU mreÅ¾e, kroz nju se propuÅ¡ta **trening skup** i biljeÅ¾e se stvarne **ReLU aktivacije**.
* RaÄuna se **maksimalna aktivacija** i **maksimalna teÅ¾ina** u sloju.
* Na temelju toga se odreÄ‘uje faktor skaliranja koji osigurava da ni najjaÄa aktivacija neÄ‡e proizvesti viÅ¡e od jednog spike-a.
* Svaki sloj koristi svoj **â€œapplied_factorâ€**, ali i **prenosi informaciju o prethodnom sloju** da oÄuva proporcionalnost.

---

## âš–ï¸ **SaÅ¾etak razlika**

| ZnaÄajka           | Model-Based                 | Data-Based                           |
| ------------------ | --------------------------- | ------------------------------------ |
| Na Äemu se temelji | Maksimalni moguÄ‡i ulaz      | Stvarne aktivacije s trening skupa   |
| Konzervativnost    | Visoka (sigurna, ali spora) | Niska (brÅ¾a, ali moÅ¾e malo varirati) |
| Vrijeme simulacije | Dulje                       | KraÄ‡e                                |
| ToÄnost            | Vrlo visoka                 | Gotovo identiÄna                     |
| Pogodno za         | Eksperimentalnu robusnost   | PraktiÄne implementacije             |

---


---

## ğŸ”¹ **Eksperimentalni setup â€” A. Dataset**

### ğŸ§  **KoriÅ¡teni skup podataka**

* Odabran je **MNIST dataset** â€” najpoznatiji i najÄeÅ¡Ä‡e koriÅ¡ten skup u *machine learningu*.
* Sastoji se od **ruÄno pisanih znamenki (0â€“9)**, svaka u formatu **28Ã—28 piksela**, **sivih tonova** (grayscale).

---

### ğŸ“Š **Struktura podataka**

* **Trening skup**:

  * 60.000 slika ruÄno pisanih znamenki.
  * Slike su prikupljene iz **poÅ¡tanskih kodova (postal codes)**.
  * Svaka slika ima pripadajuÄ‡u oznaku (label) od **0 do 9**.
* **Testni skup**:

  * 10.000 slika znamenki, koriÅ¡tene iskljuÄivo za evaluaciju modela.

---

### ğŸ† **Referentne toÄnosti (baseline rezultati)**

* **NajveÄ‡a toÄnost klasiÄne (nespiking) mreÅ¾e**:

  * **99.55%**, postignuto pomoÄ‡u **Maxout Networks** ([23]).
  * Ova vrijednost je â€œstate-of-the-artâ€ bez koriÅ¡tenja data augmentationa.

* **NajveÄ‡a toÄnost prethodne spiking implementacije**:

  * **98.30%**, postignuto pomoÄ‡u **spiking konvolucijskih mreÅ¾a (spiking ConvNets)** ([24]).

---

### ğŸ“ˆ **ZakljuÄak**

* MNIST je izabran jer je:

  * **standardiziran** â†’ omoguÄ‡uje lako usporeÄ‘ivanje s drugim modelima,
  * **dovoljno jednostavan** za brze eksperimente,
  * ali i **dovoljno izazovan** da pokaÅ¾e uÄinkovitost konverzije ANN â†’ SNN.

---


---

### ğŸ”¹ Eksperimentalne arhitekture

#### 1. **Fully-connected network (FCN)**

* Struktura: **784â€“1200â€“1200â€“10** (2 skrivena sloja po 1200 neurona).
* Svi neuroni su **povezani izmeÄ‘u slojeva**.
* **Trening setup:**

  * Learning rate: **1**
  * Momentum: **0.5**
  * Batch size: **100**
  * Epochs: **50**
  * Dropout: **50%**
  * Random inicijalizacija teÅ¾ina u rasponu **[-0.1, 0.1]**
* **Rezultati:**

  * Train accuracy: **99.87%**
  * Test accuracy: **98.68%**

---

#### 2. **Convolutional neural network (ConvNet)**

* Arhitektura: **28x28â€“12c5â€“2sâ€“64c5â€“2sâ€“10o**

  * 12 konvolucijskih jezgri 5x5
  * 2x2 prosjeÄno subsampliranje
  * 64 konvolucijske jezgre 5x5
  * 2x2 prosjeÄno subsampliranje
  * Potpuno povezani izlazni sloj od 10 neurona (za 10 klasa znamenki)
* **Trening setup:**

  * Learning rate: **1**
  * Batch size: **50**
  * Momentum: **0**
  * Dropout: **50% na kernelima**
  * Bias: **0**
  * Epochs: **50**
  * **Bez augmentacije** dataset-a
* **Rezultati:**

  * Train accuracy: **99.19%**
  * Test accuracy: **99.14%**

---

### ğŸ”¹ Pretvorba u Spiking IF mreÅ¾e

* Najbolji ReLU modeli iz obje arhitekture su **konvertirani** u **spiking IF (Integrate-and-Fire)** mreÅ¾e.
* **Grid search** je koriÅ¡ten za pronalazak optimalnih kombinacija:

  * **Input rate**: {25, 50, 100, 200, 400, 1000 Hz}
  * **Threshold (v_thr)**: {0.25, 0.5, 1, 2, 4, 10, 20}

---

### ğŸ”¹ Normalizacija teÅ¾ina

#### a) **Model-based normalization (algoritam 1)**

* Znatno smanjuje teÅ¾ine svakog sloja.
* FCN teÅ¾ine smanjene za:

  * Faktor 0.08 (prvi sloj)
  * Faktor 0.045 (drugi sloj)
* **Nije primijenjena na izlazni sloj**.
* ConvNet teÅ¾ine:

  * Conv1: 0.1657
  * Conv2: 0.1238

#### b) **Data-based normalization (algoritam 2)**

* Lagano prilagoÄ‘ava teÅ¾ine, Äini mreÅ¾u otpornijom na visoke input rateove.
* FCN faktori:

  * 0.37, 1.25, 0.8
* ConvNet faktori:

  * Conv1: 0.1657
  * Conv2: 1.0021
  * Output: 1.19
* PoveÄ‡anje teÅ¾ina u izlaznom sloju zbog **premale aktivacije** tijekom treninga.

---

Spiking input
Vrijednosti intenziteta na MNIST slikama su bile normalizirane u vrijednostima izmeÄ‘u 0 i 1.
Na temelju tih vrijednosti, koriÅ¡tenjem Poissonove distribucije, spike trains su bili generirani za svaki piksel u slici, s firing rateom proporcionalnim s intenzitetom piksela

Å to znaÄi â€spiking inputâ€œ za MNIST slike (detalnije)

Normalizacija piksela

Intenzitet piksela 
ğ¼
ğ‘–
ğ‘—
I
ij
	â€‹

 je skaliran u raspon 
[
0
,
1
]
[0,1].

0 = potpuno crno (nema svjetla), 1 = maksimalna svjetlina.

Pretvaranje intenziteta u firing rate

Za svaki piksel definiramo firing rate (stopu pucanja) 
ğ‘Ÿ
ğ‘–
ğ‘—
r
ij
	â€‹

 proporcionalnu intenzitetu:

ğ‘Ÿ
ğ‘–
ğ‘—
=
ğ¼
ğ‘–
ğ‘—
Ã—
ğ‘Ÿ
max
r
ij
	â€‹

=I
ij
	â€‹

Ã—r
max
	â€‹


ğ‘Ÿ
max
r
max
	â€‹

 je maksimalna stopa (npr. 100 Hz, 400 Hz, 1000 Hz â€” ovisno o eksperimentu).

Dakle, bijeli piksel intenziteta 1 generira spike-ove sa stopom 
ğ‘Ÿ
max
r
max
	â€‹

, tamni piksel intenziteta 0 ne generira spikes.

Poissonov proces za spike-train

Spike-ovi se modeliraju kao Poissonov proces s intenzitetom 
ğ‘Ÿ
ğ‘–
ğ‘—
r
ij
	â€‹

.

U kontinuiranom vremenu: broj spike-ova u intervalu 
[
0
,
ğ‘‡
]
[0,T] slijedi Poissonovu distribuciju s parametrom 
ğ‘Ÿ
ğ‘–
ğ‘—
ğ‘‡
r
ij
	â€‹

T.

Diskretna aproksimacija (korisna za simulacije): s vremenskim korakom 
ğ‘‘
ğ‘¡
dt (npr. 
ğ‘‘
ğ‘¡
=
1
Â ms
=
0.001
Â s
dt=1Â ms=0.001Â s), u svakom koraku generiraÅ¡ Bernoullijevu odluku s vjerojatnoÅ¡Ä‡u:

ğ‘
=
ğ‘Ÿ
ğ‘–
ğ‘—
â‹…
ğ‘‘
ğ‘¡
p=r
ij
	â€‹

â‹…dt

tj. u svakom timestepu piksel puca s vjerojatnoÅ¡Ä‡u 
ğ‘
p. Ovo je standardna i vrlo dobra aproksimacija Poisson procesa.

ZaÅ¡to Poisson?

Poisson spike-trains imaju nezavisne inter-spike intervale i stohastiÄnost nalik biologiji.

Daje varijaciju u ulazu (ne deterministiÄke spike-ove) Å¡to testira robusnost SNN-a

Evo kako to moÅ¾emo izvuÄ‡i i objasniti na hrvatskom, korak po korak:

---

### **Evaluacija rezultata konverzije ReLU â†’ SNN**

1. **Cilj**

   * Provjeriti koliko dobro spiking IF mreÅ¾e mogu replicirati performanse originalnih ReLU mreÅ¾a.

2. **Postupak evaluacije**

   * Originalna ReLU mreÅ¾a je trenirana i postavlja ciljnu toÄnost (`target performance`) za spiking mreÅ¾u.
   * Spike-based mreÅ¾e se simuliraju za **0.5 s po slici**.
   * Parametri spike mreÅ¾e (input rate i threshold) su podeÅ¡avani **grid searchom** za najbolje performanse.

3. **Vrste spiking mreÅ¾a koje se evaluiraju**

   1. **Najbolja spiking IF mreÅ¾a** â€“ dobivena grid searchom parametara.
   2. **Data-normalized mreÅ¾a** â€“ teÅ¾ine su prilagoÄ‘ene prema stvarnim aktivacijama trening seta, bez podeÅ¡avanja hyperparametara.
   3. **Model-normalized mreÅ¾a** â€“ teÅ¾ine su skalirane prema maksimalnim moguÄ‡im aktivacijama (konzervativnija metoda).

4. **ZakljuÄci iz rezultata**

   * **Data-normalized mreÅ¾a** gotovo replicira toÄnost originalne ReLU mreÅ¾e **bez potrebe za grid searchom**.
   * U praksi, **dovoljno je simulirati samo nekoliko desetaka milisekundi** po slici da se postigne performansa usporediva s originalnom mreÅ¾om.
   * Model-normalized mreÅ¾a je konzervativnija, Äesto zahtijeva duÅ¾e simulacije zbog smanjenih teÅ¾ina, ali eliminira probleme s previÅ¡e spike-ova u jednom timestepu.

5. **PraktiÄna implikacija**

   * Data-based normalizacija omoguÄ‡uje **brzu i preciznu konverziju ReLU mreÅ¾a u SNN**.
   * Spike simulacije mogu biti vrlo kratke (`tens of milliseconds`) i i dalje postiÅ¾u visoku toÄnost.
   * Pokazuje da SNN-ovi mogu biti gotovo jednako uÄinkoviti kao i standardne ANN-ovi, ali koriste **temporalnu kodiranu informaciju** i stohastiÄke spikeove.

---


Brainchip.com
---

## ğŸ§  BrainChip Akida â€“ Neuromorfni AI procesor

### ğŸ” Å to je Akida?

* **Neuromorfni Äip** inspiriran ljudskim mozgom.
* **Event-based arhitektura**: obraÄ‘uje samo znaÄajne podatke, Äime se postiÅ¾e visoka energetska uÄinkovitost i niska latencija.
* OmoguÄ‡uje **uÄenje u stvarnom vremenu** na ureÄ‘aju, bez potrebe za stalnom vezom s oblakom ([BrainChip][1]).

### âš™ï¸ KljuÄne znaÄajke

* **Sparsity princip**: obraÄ‘uje samo podatke koji donose vrijednost, ignorirajuÄ‡i nule i neaktivne informacije ([BrainChip][2]).
* **Spiking Neural Networks (SNNs)**: neuronske jedinice aktiviraju se samo kada je to potrebno, sliÄno ljudskom mozgu ([eejournal.com][3]).
* **On-chip uÄenje**: omoguÄ‡uje treniranje modela direktno na ureÄ‘aju, smanjujuÄ‡i potrebu za obradom u oblaku ([BrainChip][1]).

### ğŸ§© Arhitektura

* **Modularna struktura**: do 256 Ävorova povezano u mreÅ¾u, svaki s Äetiri Neural Processing Unit-a (NPU).
* **Fleksibilnost**: NPUs mogu biti konfigurirani kao konvolucijski ili potpuno povezani slojevi.
* **Skalabilnost i kompaktnost**: omoguÄ‡uje primjenu u razliÄitim ureÄ‘ajima, od IoT senzora do autonomnih sustava ([BrainChip][4]).

### ğŸŒ Primjene

* **Edge AI**: obrada podataka na ureÄ‘aju u stvarnom vremenu.
* **Industrijska automatizacija**: nadzor proizvodnih linija i prediktivno odrÅ¾avanje.
* **Pametni gradovi i IoT**: analiza podataka s senzora za optimizaciju resursa.
* **Zdravstvo**: detekcija anomalija u medicinskim ureÄ‘ajima i nosivim tehnologijama.

---

BrainChip nudi vlastiti razvojni alat pod nazivom **Akida Development Environment (ADE)**, koji je sada besplatan i dostupan za preuzimanje. ğŸ‰

---

## ğŸ§° Akida Development Environment (ADE)

### ğŸ”§ Å to je ADE?

* **MetaTF** je glavni okvir unutar ADE-a, temeljen na Pythonu i inspiriran Keras API-jem. OmoguÄ‡uje razvoj, treniranje i testiranje neuronskih mreÅ¾a na Akida neuromorfnoj platformi.
* UkljuÄuje:

  * **Akida Simulator**: softverska implementacija Akida NSoC-a za simulaciju modela.
  * **CNN2SNN**: alat za konverziju konvolucijskih modela u spiking neuronske mreÅ¾e.
  * **QuantizeML**: alat za kvantizaciju modela s niskobitnim teÅ¾inama i aktivacijama.
  * **Akida Model Zoo**: zbirka unaprijed obuÄenih modela za jednostavan poÄetak rada. ([doc.brainchipinc.com][1])

### ğŸ§  Radni tok u ADE-u

1. **Izgradnja modela**: Koristi Keras ili model iz BrainChip Model Zoo.
2. **Kvantizacija**: Primijeni QuantizeML za smanjenje preciznosti modela.
3. **Konverzija**: Upotrijebi CNN2SNN za prilagodbu modela Akida platformi.
4. **Simulacija i testiranje**: Pokreni model u Akida Simulatoru ili na stvarnom AKD1000 hardveru. ([doc.brainchipinc.com][2])

### â˜ï¸ Akida Cloud

Za brÅ¾i poÄetak, BrainChip nudi **Akida Cloud** â€“ platformu koja omoguÄ‡uje razvoj i testiranje modela bez potrebe za lokalnim hardverom. Idealno za prototipiranje i eksperimentiranje. ([BrainChip][3])

---

- Uklanjaju se podaci, weightovi i aktivacije koje ne donose znaÄajne informacije

- Sparse princip => sparse data, sparse weights, sparse activations
- Sparse = rijedak / razrijeÄ‘en

- U neuronskim mreÅ¾ama, â€œsparseâ€ znaÄi da veÄ‡ina neurona ili konekcija ne Å¡alje signal u svakom trenutku.

- Samo oni neuroni koji su stvarno â€œaktivniâ€ zbog znaÄajnog inputa zapravo Å¡alju spike (impuls).

- Prednost sparse pristupa

- Manja potroÅ¡nja energije â€“ Äip ne troÅ¡i resurse na nepotrebne izraÄune.

- BrÅ¾a obrada â€“ jer se procesira samo mali dio podataka.

- Efikasno u stvarnom vremenu â€“ idealno za edge AI i senzore koji stalno prikupljaju podatke.

- Kako to izgleda u praksi

- Recimo da kamerom snimaÅ¡ scenu: ako se veÄ‡ina scene ne mijenja, neuroni koji â€œprateâ€ neaktivne dijelove ne Å¡alju spike.

- Samo neuroni koji detektiraju pokret ili promjenu podataka Å¡alju signal i aktiviraju daljnju obradu.

- Veza sa Spiking Neural Networks (SNN)

- Sparse priroda Akida Äipova se savrÅ¡eno uklapa u SNN: spikeovi se dogaÄ‘aju samo kad je potrebno, sliÄno ljudskom mozgu.

- Za razliku od klasiÄnih CNN ili DNN gdje se cijela matrica propagira kroz mreÅ¾u, ovdje veÄ‡ina neurona miruje dok ne doÄ‘e do bitnog dogaÄ‘aja.

- Sparse data => streaming inputi konvertiraju se u eventa na hardverskoj razini, smanjuje se obujam podataka za Äak 10 puta prije nego procesiranje poÄne. Tradicionalni CNN-ovi procesiraju svaki ulazni datapoint, neovisno o promjeni. Brainchip filtrira input na hardverskoj razini i reagira samo na nove relevantne podatke
- Sparse weights => nepotrebni weightovi se uklanjaju i komprimiraju, smanjuje se veliÄina modela i raÄunalna sloÅ¾enost za Äak 10x
- Sparse activations => Samo kljuÄne aktivacijske funkcije Å¡alju podatke u sljedeÄ‡e slojeve, smanjujuÄ‡i raÄunanje u narednim slojevima do 10 puta.

- BITNI PRINCIPI:
- event-driven
- process only when needed (computation se obavlja samo kad se event treba obraditi; smanjuje se potroÅ¡nja energije i workload)
- communicate essentials (nodevi u neuralnoj mreÅ¾i dijelie podatke samo kad je potrebno; izbjegava se komunikacijski overhead koji bezveze troÅ¡i energiju)
- keep data close to compute (memorije je distribuirana i nalazi se blizu raÄunalnih nodeva da se smanji latencija i potroÅ¡nja struje)
- focus on development, not owerhead (intelligent runtime + simple API...navodno lako za koristit...vidit Ä‡emo :D )
- learn and adapt on device (on-chip learning...ureÄ‘aji se mogu personalizirati i adaptirati bez clouda)
- reduce CPU load (smanjenje ili uklanjanje potrebe za uporabom CPU-a)
- fully digital and proven in silicon (u potpunosti digitalan dizajn; skalabilan, portabilan i spreman za produkciju)
- built-in privacy (podaci su privatni jer se svi raÄuni obavljaju lokalno i samo weights se spremaju za uÄenje)
- podrÅ¾ava rad s CNN-ovima, DNN-ovima, RNN-ovima i sl. OmoguÄ‡ava pretvorbu istih u SCNN-ove
- more se pokrenut na FPGA, AKIDA hardveru ili u simulatorima

- PodrÅ¾avaju razne arhitekture:
---

### ğŸ–¼ï¸ CNNs and Spatio-Temporal CNNs

* Optimizirane za **prostorne (spatial) i vremenski ovisne (time-aware) zadatke**.
* Idealne za: **prepoznavanje slika**, **detekciju gesta**, **analizu vibracija**.
* Rade s podacima koji imaju i **prostorne i vremenske dimenzije**.

---

### â±ï¸ State Space Models (SSMs)

* Nova klasa neuronskih mreÅ¾a koja **kombinira temporalnu svijest i efikasnost u treniranju**.
* **Bolje performanse od tradicionalnih RNNs** (LSTM, GRU) u skalabilnosti i brzini treniranja.
* Pogodne za **zadace gdje treba pratiti stanje kroz vrijeme**.

---

### ğŸ¯ Temporal Event-Based Neural Networks (TENNsâ„¢)

* Idealne za **sve Å¡to ukljuÄuje kretanje** â€“ prate streaming podatke kroz vrijeme.
* PoboljÅ¡avaju SSMs dodavanjem **event-based awareness**.
* Pojednostavljuju: **motion tracking**, **object detection**, **audio processing**.
* Koriste **manje memorije i raÄunanja** od transformera.

---

ZaÅ¡to su opisani SCNN-ovi bolji nego tradicionalni?
- Parallel training => izrazito brÅ¾i od konkurencije s arhitekturama dizajniranima za paralelni rad
- Efficiency => manji modeli s manje parametara i manje memorijskog overheada
- Stable and reliable => konzistentan trening i lakÅ¡i deployment na edge devices

################################################## BRAINCHIPS ##########################################################
Dmitry Ivanov&co - Neuromorphic AI systems
- Moderni AI sustavi bazirani na von Neumann arhitekturei i klasiÄnim neural mreÅ¾ama imaju mnoge nedostatke u usporedbi s mozgom
- Pregled dostupnih neuromorfnih Äipova => TrueNorth, Loihi, Tianjic, SpiNNaker, BrainScaleS, NeuronFlow, DYNAP, Akida
- Klasifikacija neuromorfnih sustava na temelju brain featuresa koji koriste
- Neuronske mreÅ¾e, paralelizam i asinkronost, prijenos informacija pomoÄ‡u impulsa, lokalno uÄenje, sparsity, analogni in-memory computing

- Bitno je brzo obavljanje brojnih repetitivnih paralelnih operacija
- Bilo bi idealno kreirati AI algoritme spojene s hardverom na kojem rade (zato jer zapravo hardver odreÄ‘uje dostupnost i efektivnost AI algoritama

- Glavni problem Von Neumann Arhitekture => odvajanje memorije i operacija
- Operacije se izvrÅ¡avaju u obliku programa (sekvence strojnih uputa)
- Procesor obavlja instrukcije => viÅ¡e argumenata koje prima od procesnih registara (male, ali brze memorijske Ä‡elije locirane na procesoru)
- Instrukcije i veÄ‡ina podataka se pohranjuju u memoriju koja je odvojena od procesora
- Procesor i memorija spojeni su data busem preko kojeg procesor prima instrukcije i podatke iz memorije

- Prvi bottleneck: ograniÄena propusnost podataka izmeÄ‘u memorije i procesora
- Data bus veÄ‡inom Å¡alje privremene izraÄuna prema RAM-u/iz RAM-a tijekom rada programa
- Throughtput data busa je puno manji od brzine kojom procesor moÅ¾e procesirati podatke (u prijevodu: brÅ¾a obrada ne pomore, kad svakako bus ne more brzo slat podatke)
- RAM i procesni registri nisu jednako brzi => uzrokuje se latencija i processor downtime => procesor ne dela niÅ¡ dok Äeka podatke iz memorije => VON NEUMANN BOTTLENECK
- TroÅ¡i se jako puno energije => Äak i viÅ¡e energije za sam prijenos podataka nego za obradu istih => Äisti overhead
- npr. u operaciji zbrajanja 2 broja viÅ¡e energije se troÅ¡i za dovlaÄenje i Äitanje brojeve iz memorije nego za samo zbrajanje

- Neuralne mreÅ¾e temeljene na Von Neumann arhitekturi

- namijenjene za rijeÅ¡avanje kognitivnih problema na raÄunalu
- utemeljene na perceptronu i metodi backpropagacije
- Perceptron => pojednostavljeni matematiÄki model neronske mreÅ¾e u kojem neuroni raÄunaju weighted zbroj input signala i generiraju output signal koristeÄ‡i aktivacijsku funkciju
- Proces treniranja svodi se na prilagdobe weightova s ciljem smanjenja errora

- PoÅ¡to veÄina modernih neuronskih mreÅ¾a ima layered arhitekturu, najviÅ¡e raÄunalno zahrjevana operacija je svakako mnoÅ¾enje matrica vektorima (y = Wx)
- Da bi se taj proces odradio, potrebno je najprije dohvatiti podatke iz memorije (m*n weightova za W i n vrijednsoti vektora x) => vrijednosti m*n weigthova koriste se jednom po mnoÅ¾enju, dok se vrijendosti vektora x koriste ponovno

- Da bi raÄunao, procesor treba primiti weightove i input podatke iz memorije
- Propusnost (throughtput) data busa i latencija u primanju podataka ograniÄavaju brzinu dobivanja weightova
- broj weightova raste u O(n^2) di je n veliÄina inputa
- Throughtput se izrazito jako troÅ¡i za mnoÅ¾enje matrica vektorom

- Kako ublaÅ¾iti navedena ograniÄenja?

- CPU => koriÅ¡tenje kompleksnog multi-level cache sistema
- U modernim procesorima, cache zna Äiniti i do 40% povrÅ¡ine Äipa
- deseci megabajta ultra-brze memorije
- Äesto, neuronske mreÅ¾e ne dozvoljavaju pohranu svih weightova u cache
- Ne trebaju nam neka super kompleksna rjeÅ¡enja jer u mnoÅ¾enju matrica unaprijed znamo redoslijed operacija
- CPU je u ANN-ovima zadovoljavajuÄ‡ samo za male neuronske mreÅ¾e, ali ne i za moderne velike arhitekture od viÅ¡e stotina MB

- GPU => viÅ¡e strategija za rijeÅ¡avanje memorijske latencije
- svakom streaming multiprocesoru daje se veliki file registar koji sprema execution context za puno threadova i omoguÄ‡ava brzi switch izmeÄ‘u njih (za svaki thread se zna Äa toÄno dela)
- koristi se computation scheduler koji upotrebljava upravo taj feature s viÅ¡e threadova
Visoka latencija instrukcija

Neke instrukcije, poput pristupa podacima iz glavne memorije, imaju znaÄajno vrijeme Äekanja (latenciju).

Tijekom tog Äekanja, procesor ne moÅ¾e odmah nastaviti s izvrÅ¡avanjem te instrukcije.

Prebacivanje izmeÄ‘u threadova (warp switching)

Kada GPU detektira da trenutni thread (npr. SIMD thread 1) Äeka na podatke, scheduler automatski prebacuje izvrÅ¡avanje na drugi thread (SIMD thread 2).

Ako i taj thread naiÄ‘e na latenciju, GPU moÅ¾e nastaviti s treÄ‡im threadom (SIMD thread 3), i tako redom.

Ovo prebacivanje je vrlo brzo i odvija se bez znaÄajnog overheada.

Sakrivanje latencije (latency hiding)

Dok jedan thread Äeka podatke iz memorije, drugi threadovi koriste raÄunalne resurse (ALU, FPU itd.).

Na taj naÄin, ukupna iskoristivost GPU-a ostaje visoka, iako su pojedini threadovi privremeno blokirani.

Velik broj paralelnih threadova

GPU arhitektura podrÅ¾ava istovremeno izvoÄ‘enje velikog broja threadova (Äesto tisuÄ‡e).

Ti threadovi su grupirani u streaming multiprocesore (SM) â€“ svaka jedinica SM sadrÅ¾i vlastiti scheduler i skup jezgra.

Brojni SM-ovi zajedno omoguÄ‡uju kontinuirano izvoÄ‘enje i ravnomjernu raspodjelu optereÄ‡enja.

Efekt

ZahvaljujuÄ‡i ovom mehanizmu, latencija memorije se "skriva" jer se u meÄ‘uvremenu obavlja koristan rad na drugim threadovima.

Time GPU postiÅ¾e visoku propusnost i efikasnost u paralelnom procesiranju podataka.

Uz samu latenciju, kljuÄan je i memory throughtput => makismalna koliÄina podataka koja se moÅ¾e primiti iz memorije u odreÄ‘enoj vremenskoj jedinici 

TPU => smanjuje efekte latencije i low memory throughtputa koristeÄ‡i systoliÄke matrice i software controlled memoriju umjesto cache-a.

Ideja systolic raÄunanja je kreiranje velike matrice (256x256 za TPUv1) raÄunalnih jedinica

Svaka jedinica pohranjuje weightove i odraÄ‘uje 2 operacije. PRvo mnoÅ¾i broj x koji je doÅ¡ao iz jedinice lijevo. Zatim Å¡alje broj x primljen od jedinice gore, jedinici dole i prosljeÄ‘uje primljenu sumu na desno
Weigthovi su pohranjeni u raÄunalnim jedinicama, a ne u memoriji => EFIKASNO :D

TPU Å¡tedi energiju jer ima mnogo ALU jedinica koje mogu ponovno koristiti ulazne vrijednosti bez stalnog pristupa registrima, za razliku od CPU-a i GPU-a koji to stalno rade.

Neuromorphic approach

CPU, GPU i TPU su supercool, ali ni blizu legit bioloÅ¡kim conterpartovima.
Posebno u: potroÅ¡nji energije, fleksibilnosti (moguÄ‡nost da rijeÅ¡avaju razliÄite zadatke), adaptibilnosti i skalabilnosti
Implementacija kljuÄnih funkcionalnosti i principa mozga mogle bi rijeÅ¡iti taj gap

Mozak je tehniÄki gledano, veliki fundamentalno drukÄiji, non von Neumann kompjuter
- Za razliku od everyday kompova, u mozgu:
- neuroni Å¡alju informacije koristeÄ‡i diskretne impulse (spikeove)
- svi eventi se dogaÄ‘aju asinkrono (nema 1 centralnog procesa koji eksplicitno orkestrira rad svih neurona)
- Learning procesi su lokalni
- Network topologije su neslojevite
- Nema zajedniÄke memorije s kojom bi univerzalni procesori radili
- Umjesto toga, postoji ogroman broj jednostavnih agenata koji funkcioniraju samoorganizacijski

Neuromorfni pristupi u raÄunalnim sustavima
- Danas se mnogi akceleratori neuronskih mreÅ¾a nazivaju **neuromorfnim AI sustavima** kako bi privukli paÅ¾nju.
- Kako bi se **smanjila nejasnoÄ‡a u klasifikaciji** AI sustava kao neuromorfnih, autori predlaÅ¾u **popis svojstava** koja su korisna pri izradi raÄunalnih sustava.
- Ta svojstva su se **pokazala uÄinkovitima u stvarnim projektima**.

- Neural network-based approach: sposobnost uÄenja (ne treba postavljati parametre eksplicitno) => povezivanje velikog broje relativno jednostavnih elemenata u network => zajedniÄki obavljaju sloÅ¾ene zadatke
- Paralelizam: paralelni rad neurona i simultana provedba viÅ¡e zadataka
- Asinkronost: nema posebnog procesa koji sinkronizira ostale
- Impulsna priroda transmisije informacija: minimalni overhead za transimisiju i procesiranje signala na primateljskom neuronu => resistance to noise
- Local learning: manji overhead za transfer podataka tijekom uÄenja; moguÄ‡nost kreiranja neograniÄeno velikih sustava; kontinuirano inkrementalno uÄenje
- Sparse data streamovi=> podaci stiÅ¾u rijetko, ali smisleno
- GPT SAID:
ZnaÄi da se podaci generiraju samo kada se dogodi neki dogaÄ‘aj (event), umjesto kontinuiranog slanja ogromne koliÄine informacija (kao u klasiÄnim kamerama ili senzorima).

Takav event-driven signal processing omoguÄ‡uje da se obrada i prijenos podataka odvijaju samo kad je to potrebno, Äime se:

smanjuje overhead (optereÄ‡enje) kod prijenosa i obrade,

Å¡tedi energija,

i poveÄ‡ava uÄinkovitost cijelog sustava.
- Analog computing: efikasna implementacija hardvera
- in-memory computing: nema overheada za transfer privremenih meÄ‘upodataka; nema kompetitivnog pristupa memoriji

- PARALELIZAM:
- svaki bioloÅ¡ki neuron je neovisno raÄunalo, ali puno sporiji nego silicijski procesori
- U mozgu ima i viÅ¡e od 87 milijardi neurona
- Potrebno je puno paralelnog rada da bi svi oni mogli raditi

- ASINRKONOST:
- paralelizam sam po sebi ne daje uvjek dovoljan efekt jer je ipak potrebna sinkronizacija izmeÄ‘u nodeva
- Po Amdahlovom zakonu, sinkronizacijski owerhead raste nelinearno kako se poveÄ‡ava broj kompjutera i tako limitira dobrobiti paralelizma
- ÄŒini se da mozak nema mehanizam koji eksplicitno sinkronizira rad svih neurona
- bioloÅ¡ki neuroni rade asinkrono i omoguÄ‡avaju da se nadiÄ‘u ograniÄenja Amadhlovog zakona

- IMPULSNA PRIRODA TRANSMISIJE INFORMACIJA
---

### **KljuÄne ideje o Spiking Neural Networks (SNN):**

* **NaÄin prijenosa informacija:**

  * U mozgu se informacije prenose u obliku impulsa (spikeova) â€” kratkih, naglih promjena potencijala.
  * SNN modelira upravo tu prirodu â€” neuroni meÄ‘usobno razmjenjuju *spikeove* koji sadrÅ¾e **samo informaciju o vremenu nastanka**.

* **Vremenska komponenta:**

  * Prijenos spikea nije trenutan â€” svaka sinapsa ima **teÅ¾inu (w)** i **vremensko kaÅ¡njenje (d)**.
  * **Vrijeme spikea i kaÅ¡njenje** sluÅ¾e za **eksplicitno uvoÄ‘enje vremena** u model obrade informacija.

---

### **Prednosti SNN-a nad klasiÄnim neuronskim mreÅ¾ama:**

* **Asinkroni prijenos podataka:**
  OmoguÄ‡uju prijenos informacija izmeÄ‘u neurona *bez potrebe za globalnim sinkronizacijama*.

* **Rad s dinamiÄkim podacima:**
  ZahvaljujuÄ‡i vremenskoj komponenti, SNN moÅ¾e obraÄ‘ivati **signale koji se mijenjaju u vremenu**, jer informacija ovisi o **vremenu generiranja spikea** i **kaÅ¡njenju propagacije**.

* **Nelinearna dinamika:**
  SNN su **kompleksni nelinearni dinamiÄki sustavi**, Å¡to omoguÄ‡uje bogatiju i realistiÄniju obradu informacija.

* **Energetska uÄinkovitost:**
  Neuroni troÅ¡e energiju samo kada reagiraju na dolazni spike, a zatim prelaze u **neaktivno stanje**.
  U svakom trenutku samo **mali broj neurona radi**, Å¡to dramatiÄno **smanjuje potroÅ¡nju energije**.

---

### **OgraniÄenja danas:**

* Malo praktiÄnih primjena zbog **ograniÄenja hardvera** i **teÅ¾ine treniranja**.
* KlasiÄne mreÅ¾e joÅ¡ uvijek **postiÅ¾u bolje rezultate** u veÄ‡ini zadataka.
* Trening algoritmi i topologije SNN-a su joÅ¡ uvijek **otvoreni istraÅ¾ivaÄki problemi**.

---

