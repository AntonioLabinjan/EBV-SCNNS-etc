#### Ovaj file Ä‡u koristit za pisanje biljeÅ¡ki i zapaÅ¾anja kad krenen detaljnije istraÅ¾ivat materiju i Äitat resources koje iman

Neuromorphic Electronic Systems, Carver Mead, 1990
- https://hasler.ece.gatech.edu/Published_papers/Technology_overview/MeadNeuro1990.pdf

- PotroÅ¡nja energije je velik problem kod raÄunala
- ObiÄna raÄunala ne mogu imitirati mozak, pa ni njegove najjednostavnije procese
- Mozak je i 10 milijuna puta efikasniji nego raÄunala iz 90-ih
- Funkcije u mozgu se mogu djeliti na: jednostavne elementarne funkcije, reprezentacije informacija i najkompleksnije organizacijske principe 
- Ideja je pokuÅ¡ati reverse-engineerati mozak
- Kompleksno je rastavljati fizikalne principe u bitove i onda ih rekreirati s AND i OR gatesima
- Mozak se moÅ¾e gledati kao distribuirani sustav s viÅ¡e nodesa koji primaju elektriÄne impulse
- Sigurno se radi o nelinearnim funkcijama
- Napon u sinapsama neurona za osnovne funkcije raste eskponencijalno s naponom
- Mozak ima i sustave za dugotrajno uÄenje i memoriju
- Dobro izgraÄ‘en sustav moÅ¾e simulirati uÄenje i pamÄ‡enje (silicon chips)
- Neuromorphic sustavi su sustavi koji implementiraju iste operacija poput Å¾ivÄanog sustava
- Zero-cost addition using Kirchhoff's Law

Kirchhoffov zakon (struja): u jednom Ävoru zbroj svih struja koje ulaze = zbroj svih struja koje izlaze.

Ako viÅ¡e izvora struje spojiÅ¡ na isti Ävor â†’ automatski se saberu (nema dodatnih komponenti).

Zero-cost addition = zbrajanje bez dodatnog sklopa â†’ priroda elektronike sama radi raÄunanje.

Kapacitet Ävora (parazitski ili namjerni kondenzator) integrira ukupnu struju tijekom vremena â†’ dobijeÅ¡ napon koji predstavlja zbroj.

U digitalnim sklopovima bi ti za zbrajanje trebao adder (logika, tranzistori, energija).

U neuromorfnim sklopovima: samo spojiÅ¡ sinaptiÄke struje na Ävor i dobijeÅ¡ sabiranje â€œbesplatnoâ€.

To je ultra-bitno jer neuron = integrator sinaptiÄkih ulaza â†’ Kirchhoff + kapacitet daju ti toÄno tu funkcionalnost prirodno.

Mead je rekao: iskoristi fiziku (Kirchhoffov zakon) umjesto da je â€œnadograÄ‘ujeÅ¡â€ kompleksnim digitalnim adderima.

ğŸ‘‰ Ukratko: viÅ¡e sinapsi Å¡alje spikeove kao struje â†’ struje se automatski zbroje na membrani neurona â†’ kondenzator integrira â†’ izlaz = ponaÅ¡anje bioloÅ¡kog neurona, i to praktiÄki bez troÅ¡ka.

Evo kako ide â€œstoryâ€ u neuromorfnom hardveru i u mozgu:

ViÅ¡e sinapsi Å¡alje svoje â€œsignaleâ€ (u elektronici kao struje, u mozgu kao ionski tokovi).

Te sve struje ulaze u jedan Ävor (membrana neurona).

Po Kirchhoffovom zakonu â†’ struje se automatski zbroje (niÅ¡ta ne moraÅ¡ posebno raÄunati).

Kondenzator membrane integrira taj ukupni signal kroz vrijeme â†’ to daje membranski potencijal.

Ako potencijal preÄ‘e odreÄ‘eni threshold â†’ neuron ispali spike (akcijski potencijal).

ğŸ‘‰ Ukratko: Neuron radi kao prirodni zbrajaÄ + integrator.

Sabira ulaze (Kirchhoff).

Pamti ih kroz vrijeme (kapacitor = integracija).

Triggera izlaz kad sve skupa dosegne kritiÄnu vrijednost (threshold).

- Zjenica oka se, pri direktom osvjetljenju Äini svjetlijom/tamnijom u odnosu na okolinu, ovisno o okolini
- Zjenica stvara napon po primitku inputa (svjetlosti)
- RaÄuna se prosjek prostorno weighted inputa (ne vrijedi svaki input jednako, ovisno o poziciji)
- Cilj je napraviti senzor sliÄan oku koji moÅ¾e reagirati na sve inpute, neovisno od kud dolaze i koji im je intenzitet (zato se koriste weightovi)
- Koriste se amplifieri kako bi se bolje simulirao pravi potencijal Å¾ivÄanog sustava
- Laplacian filter => edge detction filter

Ajmeee, top Å¡to pitaÅ¡ za Laplacian filter! ğŸ”¥ To ti je jedan od najpoznatijih **edge detection filtera** u raÄunalnom vidu i obradi slika.

Evo ti jasno u natuknicama:

---

### ğŸ”¹ Å to je Laplacian filter?

* **MatematiÄki temelj:** koristi **Laplacian operator** (druga derivacija funkcije).
* **Poanta:** pronalazi mjesta gdje se intenzitet slike brzo mijenja â†’ tj. rubove (*edges*).
* Za razliku od Sobel/Prewitt (koji koriste prvu derivaciju i detektiraju smjer ruba), Laplacian gleda **drugu derivaciju** â†’ pa je osjetljiv na *naglu promjenu nagiba*.

---

### ğŸ”¹ Kako radi na slici?

* Sliku gleda kao **matricu piksela**.
* Na svaki piksel primjenjuje kernel (konvolucijsku masku) koji aproksimira Laplacian operator.
* TipiÄni kernel izgleda npr. ovako:
Laplacian filter kerneli:
```
0  -1   0
-1  4  -1
0  -1   0
```

i "jaÄa" verzija:
```
-1  -1  -1
-1   8  -1
-1  -1  -1
```

* Kad se primijeni, filter daje visoke vrijednosti na mjestima gdje postoji jaka promjena intenziteta â†’ tj. rub.

---

### ğŸ”¹ ZaÅ¡to je koristan?

* Detektira rubove **neovisno o smjeru** (Sobel detektira horizontalne/vertikalne, Laplacian je â€œisotropicâ€).
* Jako dobar za **naglaÅ¡avanje struktura** i **detekciju kontura**.
* ÄŒesto se koristi nakon blura (npr. Gaussian blur + Laplacian = *Laplacian of Gaussian*, LoG) â†’ to pomaÅ¾e da se smanji Å¡um.

---

### ğŸ”¹ Intuicija

* Ako piksel izgleda â€œsliÄanâ€ susjedima â†’ rezultat â‰ˆ 0.
* Ako je piksel jako razliÄit od susjeda â†’ rezultat velik (pozitivan ili negativan) â†’ to je rub.

---

ğŸ‘‰ Ukratko: **Laplacian filter je edge detector baziran na drugoj derivaciji, hvata rubove u svim smjerovima i jako se koristi u raÄunalnom vidu.**


PRIMJER PRIMJENE by ChatGPT:

Ajmo brutalno jednostavno da odmah sjedne ğŸ”¥

---

### ğŸ“Œ Primjer matrice (mala â€œslikaâ€ 5Ã—5 piksela)

Zamisli da imaÅ¡ grayscale sliku, gdje su vrijednosti piksela:

```text
10  10  10  10  10
10  10 100  10  10
10  10 100  10  10
10  10 100  10  10
10  10  10  10  10
```

ğŸ‘‰ To ti je slika gdje imaÅ¡ **vertikalnu bijelu crtu** (100) na sredini crne pozadine (10).

---

### ğŸ“Œ Laplacian kernel (klasiÄni)

```text
0  -1   0
-1  4  -1
0  -1   0
```

---

### ğŸ“Œ Primjena filtera (konvolucija)

1. Uzimamo kernel 3Ã—3 i stavljamo ga iznad piksela u centru (recimo sredina je `100`).
2. PomnoÅ¾imo element po element i zbrojimo:

```
Kernel:          Dio slike:       Rezultat = sum(kernel * dio_slike)

 0  -1   0       10  100  10
-1   4  -1   *   10  100  10   =   (0*10) + (-1*100) + (0*10) +
 0  -1   0       10  100  10       (-1*10) + (4*100) + (-1*10) +
                                    (0*10) + (-1*100) + (0*10)

= -100 -10 +400 -10 -100
= 180
```

ğŸ‘‰ Dakle u centru bijele crte izlazni piksel je **jako velik (180)** â†’ filter ga oznaÄi kao rub.

3. Ako isti kernel stavimo na dio pozadine (gdje su sve vrijednosti 10):

```
 0  -1   0       10  10  10
-1   4  -1   *   10  10  10   = (0*10) + (-1*10) + (0*10) +
 0  -1   0       10  10  10      (-1*10) + (4*10) + (-1*10) +
                                  (0*10) + (-1*10) + (0*10)

= -10 -10 +40 -10 -10
= 0
```

ğŸ‘‰ Rezultat = **0** â†’ pozadina nema rub, pa filter niÅ¡ta ne detektira.

---

### ğŸ“Œ ZakljuÄak

* Na rubu (gdje se vrijednost naglo mijenja) dobijeÅ¡ **visok rezultat**.
* Na ravnom dijelu slike â†’ rezultat â‰ˆ **0**.

---

Primjenjuje se na cijelu sliku, dio po dio
Evo kako to ide u praksi:

ImaÅ¡ cijelu sliku (npr. 512Ã—512 piksela).

Uzmemo kernel (mala matrica, npr. 3Ã—3 ili 5Ã—5).

Kernel â€œkliziâ€ po slici â€“ piksel po piksel, red po red (to se zove konvolucija).

Za svaki poloÅ¾aj:

UzmeÅ¡ â€œkomadiÄ‡â€ slike iste veliÄine kao kernel.

PomnoÅ¾iÅ¡ element po element (kernel Ã— slika).

ZbrojiÅ¡ sve rezultate â†’ to je novi izlazni piksel u filtriranoj slici.

Rezultat cijelog procesa = nova slika gdje su naglaÅ¡eni rubovi (ili Å¡to god kernel radi).

ğŸ‘‰ Dakle, da, filter se primjenjuje na cijelu sliku, dio po dio, i rezultat je feature map (slika s naglaÅ¡enim znaÄajkama).

- PomaÅ¾e u lokalizaciji objekata (odredimo di su u prostoru pomoÄ‡u edge detectiona)
- Bitno je napravit da se broj kalkulacija u oku/mozgu prilagodi broju vanjskih evenata (MOZAK NE PROCESIRA ISTU KOLIÄŒINU PODATAKA AKO GLEDA U BIJELI ZID I AKO -GLEDA U NEÅ TO POKRETNO I DINAMIÄŒNO) => dali je to maybe event-based princip??
- Cilj: viÅ¡e kalkulacija za viÅ¡e evenata; manje kalkulacija za manje evenata
- VaÅ¾nost napona pojedinog eventa slabi s protokom vremena i dolaskom novih evenata
- Ni jedan senzor u oku i mozgu nije 100% isti kao neki drugi i zato koriste adaptivne mehanizme da kompenziraju manjak preciznosti
- U mraku zjenica ne mora niÅ¡ procesirat jer ne vidi niÅ¡
- Uzima se input. Radi se predikcija inputa (Äa mozak misli da vidi). Ako je ok, ne dela nikakav dodatan tuning. Ako pogrijeÅ¡i, mora opet kalkulirat i malo prilagodit parametre (primjer: zjenice se Å¡ire u tami da bolje vidimo)
- Isti princip je i za situaciju: neÅ¡to gledamo i delamo predikciju Äa Ä‡e se desit. Ako pogrijeÅ¡imo, radi se tuning, ako pogodimo, sve je ok
- Adaptation feedback
- Mozak raÄuna average od svih viÄ‘enih piksela da se bolje adaptira i da vidi bitno, a izbacuje nebitno
- Problem simuliranog mozga pomoÄ‡u Äipova: ako 1 Äip crkne, sve zgori. Stvara se jako puno topline i troÅ¡i se puno energije
- NaÅ¡ mozak nije u potpunosti spojen (x nodeova spojeno sa x nodeova, nego su spojeni lokalno i onda se to nadoveÅ¾e, ali ne svaki sa svakin, jer bi to zauzimalo previÅ¡e mista)
- Lokalno spajanje je kljuÄno za efikasnost
- Ako imamo nepravilne inpute, treba nam neuromorphic computing 
- I do 10x efikasnije u performansama + 10000 x manje power consumptiona


 A 128x128 120 db 15 Âµs Latency Asynchronous Temporal Contrast Vision Sensor, Patrick Lichsteiner, Cristopher Posch, Tobi Debruck
- https://www.ifi.uzh.ch/dam/jcr:18928364-d16b-4403-9217-2098aaad72bd/lichtsteiner_dvs_jssc08.pdf
- 128x128 pikselni CMOS vision senzor
- Svaki piksel zasebno i kontinuirano generira spike evente na temelju lokalnih promjena intenziteta
- brÅ¾i od milisekunde
- "mreÅ¾nica od silcija"

- PROS and CONS FRAME BASED VISIONA
- PROS: mali i jednostavni pikseli -> visoka rezolucija
                                   -> viskok fill factor i nizak imager cost
---

### ğŸ¯ **Fill Factor**

**Definicija:**
Fill factor = **udio povrÅ¡ine piksela koji stvarno prima svjetlo** u odnosu na **ukupnu povrÅ¡inu piksela**.

Zamisli da svaki piksel ima odreÄ‘enu povrÅ¡inu (npr. 10Ã—10 Âµm). Dio te povrÅ¡ine zauzimaju fotodetektor i elektroniÄki sklopovi (tranzistori, kondenzatori, Å¾ice...).
Samo **fotodetektor** (photo diode) zapravo skuplja svjetlo â€” i to je efektivna "korisna povrÅ¡ina".

ğŸ‘‰ Formula:
[
\text{Fill Factor} = \frac{\text{PovrÅ¡ina osjetljiva na svjetlo}}{\text{Ukupna povrÅ¡ina piksela}} \times 100%
]

---

**Primjer:**

* Ako je piksel 10Ã—10 Âµm, ali samo 5Ã—5 Âµm hvata svjetlo â†’ fill factor = 25%.
* Ako se koristi **mikro-leÄ‡e** koje fokusiraju svjetlo na aktivni dio â†’ fill factor raste.

---

**ZaÅ¡to je bitan:**

* **VeÄ‡i fill factor = bolja osjetljivost na svjetlo (viÅ¡i SNR)**
* **Manji fill factor = viÅ¡e Å¡uma, loÅ¡iji kontrast u slabom svjetlu**

---

**U kontekstu frame-based senzora:**
Frame-based senzori imaju **jednostavnije piksele**, pa mogu imati **veÄ‡i fill factor** i time hvataju viÅ¡e svjetla â€” to je njihov *PRO*.

**Kod DVS-a (event-based):**
Pikseli imaju viÅ¡e elektronike (detekcija promjene intenziteta, threshold komparator itd.) â€” pa Äesto **fill factor pada**.
Zato se Äesto dodaju **mikroleÄ‡e** i posebni layouti da se fill factor poboljÅ¡a.

---

### âš¡ **Imager Noise (Å¡um senzora)**

**Definicija:**
To je **neÅ¾eljena varijacija** u elektriÄnom signalu piksela koja **nije rezultat stvarne promjene svjetla**.

---

**Glavne vrste Å¡uma u imagerima:**

1. **Photon shot noise** â€“ dolazi od same prirode svjetlosti (nasumiÄan broj fotona).
2. **Thermal noise (Johnson noise)** â€“ termiÄke fluktuacije u elektronici.
3. **Read noise** â€“ Å¡um koji nastaje pri Äitanju signala s piksela (ADC, bufferi...).
4. **Fixed pattern noise (FPN)** â€“ razlike izmeÄ‘u piksela zbog proizvodnog procesa.

---

**ZaÅ¡to je bitan:**

* Visok Å¡um â†’ senzor ne moÅ¾e toÄno detektirati male promjene svjetla.
* Kod **DVS-a**, Å¡um direktno utjeÄe na toÄnost generiranja eventa â€”
  ako je noise previsok, senzor moÅ¾e â€œlaÅ¾noâ€ detektirati promjenu i emitirati spike event iako svjetlo nije stvarno promijenjeno.

---

**Balans kod DVS-a:**

* Ako se threshold za promjenu intenziteta postavi **prenisko**, Å¡um Ä‡e stvarati laÅ¾ne evente.
* Ako se postavi **previsoko**, senzor Ä‡e ignorirati male, ali bitne promjene u sceni.

---

### ğŸ” Ukratko:

| Pojam            | ObjaÅ¡njenje                                                               | Posljedica                              |
| ---------------- | ------------------------------------------------------------------------- | --------------------------------------- |
| **Fill Factor**  | Postotak povrÅ¡ine piksela koji hvata svjetlo                              | ViÅ¡i = bolja osjetljivost               |
| **Imager Noise** | NasumiÄne elektroniÄke varijacije koje uzrokuju greÅ¡ke u mjerenju svjetla | ViÅ¡i = viÅ¡e laÅ¾nih eventa, niÅ¾a toÄnost |

---

- CONS: - baziran na serijama snapshota -> pikseli se ponovno obraÄ‘uju Äak i ako su nepromijenjeni iz framea u frame -> JAKO BITNO
        - limitirani bandwith (FRAME RATE/2)
        - limitirani dynamic range (ograniÄen broj piksela po frameu)

IDEJA: senzor koji prati promjene inteziteta u okolini i pretvara ih u asinkrone promjene piksela
output: asinkroni stream pixel address evenata (AEs) => smanjuje se redundantnost (ignoriramo nepromijenjene piksele)
imitiranje bioloÅ¡kog vida i odbacivanje frame-based principa

KONCEPT ADDRESS-EVENT: svaki piksel dobije svoju koordinatnu adresu (lokalni array)
                       kontinuirano; sliÄno kao moÅ¾dani impulsi
                       jako high speed

PROBLEM S PROTOTIPOVIMA: uopÄ‡e ne smanjuju redundantnost podataka, nego samo prostornu redundantnost
- puno noisea
- spori response
- limitirani dynamic range
- mala osjetljivost na kontrast

POLJE JE BILO NERAZVIJENO ZBOG NEZNANJA O ASINKRONOSTI I ZBOG BEZNAÄŒAJNE UNIFORMNOSTI RESPONZIVNIH KARAKTERISTIKA PIKSELA

1) AER senzor -> MAHOWALD I MEAD
   - silikonska mreÅ¾nica s adaptivnim fotoreceptorima, spatial smoothing mreÅ¾om i self-timed komunikacijom
   DEMO UREÄAJ BEZ IKAKVE REAL-WORLD PRIMJENE

2) Spatial+temporal filtering -> ZAGHOUL I BOAHEN
   - puno malih tranzistora i el. krugova usko spojenih diffusor networksima
   - veliki mismatch -> GOTOVO 50% PIKSELA NE OSTVARUJE SPIKE

3) CSEM NEUCHATEL -> ostvaren spatial kontekst -> transisija evenata high-low
  - moguÄ‡e zaustaviti ranije
  - ne smanjuje redundantnost, ograniÄena rezolucija zbog frame ratea

4) CULURCIELLO-ANDREON -> inter-event interval / mean frequency
   (+) - mala koliÄina piksela
   (-) - bandwith ovisi o osvjetljenju
   nema reset mehanizma (puno tamnih piskela)

5) ETIENNE-CUMMING
   - temporal change detection imager
   - moÅ¾e detektirati apsolutnu promjenu osvjetljenja
   - sinkrono -> FIFO pristup
  
VISION SENSOR DESIGN
a) PIXEL DESIGN
 - cilj je: minimizacija mismatcheva
 - Å¡iroki dynamic range
 - low latency
BRZI LOGARITAMSKI PHOTORECEPTOR CIRCUIT -> pojaÄava promjene
- kontrolira pojedine piksele + brzo odgovara/reagira na promjene osvjetljenja
- mana: tranzistori uzrokuju mismatch meÄ‘u pikselima zbog varijacija u thresholdu
- potrebna je dodatna kalibracija
KALIBRACIJA : balansiranje outputa na reset level nakon generiranja eventa (nekon Äa se zabiljeÅ¾i event, senzor se resetira => fadeout u onima mojima testnima kodovima...)
!differencing circuit! -> pikseli su osjetljivi na temporal contrast -> ima formula u paperu; bitno

RECEPTOR CIRCUIT SADRÅ½I: fotodiodu, tranzistor, amplifier -> "TRANSIMPEDANCE CONFIGURATION" -> logaritamska pretvorba photocurrenta u NAPON

- PoveÄ‡an bandwith -> veÄ‡a brzina
- adaptive biasing -> znatno manja potroÅ¡nja energije
- reset switch -> OKIDA input i output zajedno i tako resetira napon

OVO OPISUJE ONAJ PROCES KADA SE EVENT POJAVI NA KAMERI I ONDA SAMO IZBLJEDI I RESETIRA SE

ON i OFF eventi -> circuit ih emitira u periferiju
- Pixel more emitat ili ON ili OFF event (NIKAD OBA ISTOVREMENO) prema periferiji
- Proces "komunikacije" kreÄ‡e kad event trigerira piksel, a zavrÅ¡ava kada se piksel resetira na 0 (vrati u poÄetno stanje)
- Prijevod na glupo: ON event -> neÅ¡to se miÄe i pikseli reagiraju; OFF event -> niÅ¡ se viÅ¡e ne miÄe, pikseli miruju
- Bitna napomena: ON event oznaÄava da je piksel posvjetlio, OFF event da je potamnio

- ograniÄava se "fire-rate" za piksele kako pojedini pikseli ne bi zauzeli sve resurse za obradu
- omoguÄ‡ava da se viÅ¡e resursa posveti aktivnijim podruÄjima (procesiraÅ¡ ono di se neÅ¡to deÅ¡ava; di ima evenata)
- Cilj je da se circuit ne pregrijava pretjerano, da ne troÅ¡i resurse nepotrebno, da radi samo kad se neÅ¡to dogaÄ‘a

KARAKTERISTIKE NAJVAÅ½NIJIH ASPEKATA:

- Uniformity of response - vraÄ‡a razliku u osvjetljenju piksela -> bitno je uniformno i standardizirano evaluirati promjene
- Dynamic range - razlika imzeÄ‘u maksimalnog i minimalnog osvjetljenja u "sceni" kroz piksele; reliable and reproducible events
- Pixel bandwith - iznos raspona jaÄine najjaÄeg i najslabijeg intenziteta koji 1 piksel "prepozna"/"odradi". Stariji i noviji eventi se razlikuju u intenzitetu; intenzitet opada protokom vremena (fade-out)
- Latency&Latency jitter - ideja: Äa je osvjetljenje manje, latencija je veÄ‡a => proporcionalna reciproÄnom osvjetljenju (Äa je Å¡kurije, teÅ¾e se skuÅ¾e eventi i promjene u svjetlosti kod piksela)
- UtvrÄ‘eno je kako je latencija ipak jako mala u svim uvjetima (SUPER ZA REAL-TIME PROCESSING)


### Synaptic modifications in cultured hippocampal neurons:
### Dependence on spike timing, synaptic strength and postsynaptic cell type
### Guo-qiang Bi&Mu-ming Poo

Eksperimenti raÄ‘eni na hipokampusnim neuronima Å¡takora
PostsinaptiÄki i presinaptiÄki neuroni

PresinaptiÄki neuron = onaj koji Å¡alje signal.

Njegov akson zavrÅ¡ava na sinapsi i otpuÅ¡ta neurotransmitere (npr. glutamat).

To je â€œpoÅ¡iljatelj porukeâ€.

PostsinaptiÄki neuron = onaj koji prima signal.

Na svojim dendritima ima receptore koji hvataju neurotransmitere i reagira (moÅ¾e spajkati ako se dovoljno pobudi). => procesira neÅ¡to samo ako dobije dovoljno inputa i skuÅ¾i da se neÅ¡to desilo

To je â€œprimatelj porukeâ€.

Spike neurona => registrira dovoljno ulaznih signala i preÄ‘e threshold aktivacije => ako je input dovoljno "jak", aktivira se spike
Okine strujni elektriÄni impuls (par milisekundi) i otpuÅ¡ta neurotransmitere

U kontekstu event based visiona => spike je event
Nema stalnih signala kao kod obiÄnih CNN-ova nego samo triger kad se dogodi dovoljno jaka promjena
TroÅ¡i se energija samo kada se neÅ¡to stvarno dogaÄ‘a
Spike => kratki elektriÄni event kojim neuron javlja da je aktivan
Npr. Ako se detektira dovoljno pokreta, onda se input procesira, a ako ima malo/niÅ¡ pokreta, ne procesiramo niÅ¡

LTP i LTD = dugotrajno jaÄanje ili slabljenje sinapsi, inducirano ponavljanom elektriÄnom aktivnoÅ¡Ä‡u.

KlasiÄni protokoli: obiÄno ukljuÄuju repetitivnu presinaptiÄku stimulaciju (razne frekvencije) + Äesto dodatnu depolarizaciju postsinaptiÄkog neurona.

U nekim eksperimentima trebalo je blokirati spontane spikeove (npr. tetrodotoksin) ili smanjiti MgÂ²âº da bi LTP uspio.

Novija istraÅ¾ivanja (in vitro slices) pokazala su da precizno tempirani back-propagating action potentials (postsynaptic spike koji se vraÄ‡a kroz dendrite) mogu inducirati LTP ili LTD.

KljuÄna nova ideja: nije samo vaÅ¾na frekvencija stimulacije â†’ relativno vrijeme izmeÄ‘u presinaptiÄkog i postsinaptiÄkog spikea odluÄuje smjer plastiÄnosti.
Ni bitno koliko je 1 event jak, nego je za spike bitno da se deÅ¡ava viÅ¡e evenata u kratkom vremenu

Rezultati ove studije:

PostsinaptiÄki spike <20 ms nakon presinaptiÄkog â†’ LTP.

PostsinaptiÄki spike <20 ms prije presinaptiÄkog â†’ LTD.

Postoji uska prijelazna zona od samo ~5 ms izmeÄ‘u LTP i LTD.

Ovisnost o poÄetnoj snazi sinapse:

Slabe sinapse = visoka Å¡ansa za LTP.

Jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.

SpecifiÄnost ciljne stanice:

GlutamatergiÄke sinapse na GABA neurone ne pokazuju ovu vrstu plastiÄnosti.

Implicira target cellâ€“specific mehanizme.


---

* **LTP i LTD** = dugotrajno jaÄanje ili slabljenje sinapsi, inducirano ponavljanom elektriÄnom aktivnoÅ¡Ä‡u.
* **KlasiÄni protokoli**: obiÄno ukljuÄuju **repetitivnu presinaptiÄku stimulaciju** (razne frekvencije) + Äesto dodatnu depolarizaciju postsinaptiÄkog neurona.

  * U nekim eksperimentima trebalo je blokirati spontane spikeove (npr. tetrodotoksin) ili smanjiti MgÂ²âº da bi LTP uspio.
* **Novija istraÅ¾ivanja (in vitro slices)** pokazala su da **precizno tempirani back-propagating action potentials** (postsynaptic spike koji se vraÄ‡a kroz dendrite) mogu inducirati LTP ili LTD.
* **KljuÄna nova ideja**: nije samo vaÅ¾na frekvencija stimulacije â†’ **relativno vrijeme izmeÄ‘u presinaptiÄkog i postsinaptiÄkog spikea odluÄuje smjer plastiÄnosti**.
* **Rezultati ove studije**:

  * PostsinaptiÄki spike **<20 ms nakon** presinaptiÄkog â†’ **LTP**.
  * PostsinaptiÄki spike **<20 ms prije** presinaptiÄkog â†’ **LTD**.
  * Postoji uska prijelazna zona od samo **~5 ms** izmeÄ‘u LTP i LTD.
* **Ovisnost o poÄetnoj snazi sinapse**:

  * **Slabe sinapse** = visoka Å¡ansa za LTP.
  * Jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.
* **SpecifiÄnost ciljne stanice**:

  * GlutamatergiÄke sinapse na **GABA neurone** ne pokazuju ovu vrstu plastiÄnosti.
  * Implicira **target cellâ€“specific mehanizme**.

STDP je bioloÅ¡ki mehanizam uÄenja kojim se jaÄina veze (sinaptiÄka teÅ¾ina) izmeÄ‘u dva neurona mijenja ovisno o vremenskom razmaku izmeÄ‘u njihovih spikeova (akcijskih potencijala).

Drugim rijeÄima:
Nije samo vaÅ¾no da neuroni spajkaju zajedno, nego toÄno kada to rade.

Pravilo (u osnovnoj formi):

PresinaptiÄki neuron spajka PRVI â†’ PostsinaptiÄki ubrzo nakon (do ~20 ms)

LTP (Long-Term Potentiation): sinapsa se ojaÄa.

ZnaÄenje: presinaptiÄki neuron je vjerojatno pridonio aktivaciji postsinaptiÄkog â€“ mozak to â€œnagradiâ€ jaÄanjem veze.

PostsinaptiÄki neuron spajka PRVI â†’ PresinaptiÄki tek kasnije (do ~20 ms)

LTD (Long-Term Depression): sinapsa se oslabi.

ZnaÄenje: presinaptiÄki neuron nije uzrokovao aktivaciju postsinaptiÄkog, pa mozak smatra da je ta veza nebitna.

Ako su spikeovi previÅ¡e udaljeni u vremenu (> ~20 ms)

 Nema promjene â€“ mozak zakljuÄuje da nema uzroÄno-posljediÄne veze.
 
 U mozgu (STDP):

Ako presinaptiÄki spike doÄ‘e, i postsinaptiÄki spike se dogodi ubrzo nakon â†’ mozak zakljuÄi da ovaj input uzrokuje ovaj output.

Rezultat = ojaÄaj tu sinapsu (nauÄi asocijaciju).

Ako je obrnuto (postsinaptiÄki prije presinaptiÄkog) â†’ veza se smatra nebitnom â†’ oslabi sinapsu.

Analogija s event-based kamerom:

Ako se u kratkom vremenu i prostoru javi viÅ¡e evenata â†’ sustav zakljuÄuje da pripadaju istoj stvari (npr. kretanje osobe).

Ako eventi dolaze previÅ¡e razdvojeni u vremenu/prostoru â†’ nisu povezani, ignoriraÅ¡ ih.

1. â€œPostsinaptiÄki spike slijedi EPSP unutar ~15 ms â†’ LTPâ€

EPSP (Excitatory Post-Synaptic Potential) = mali elektriÄni signal u postsinaptiÄkom neuronu, nastao kad presinaptiÄki neuron otpusti glutamat.

Ako taj EPSP uspije â€œpoguratiâ€ postsinaptiÄki neuron do praga i on okine spike vrlo brzo nakon toga (~15 ms) â†’ mozak zakljuÄi:

â€œOvaj presinaptiÄki input je doprinos postsinaptiÄkoj aktivaciji.â€

Rezultat: ojaÄaj tu sinapsu (LTP).

To je zapravo bioloÅ¡ki dokaz Hebbove ideje: neuroni koji spajkaju zajedno, povezuju se zajedno, ali uz precizan timing.

2. â€œI slabe i jake sinapse mogu se ojaÄati ako je spike timing pozitivno koreliranâ€

â€œSlaba sinapsaâ€ = EPSP sam po sebi nije dovoljan da izazove spike u postsinaptiÄkom neuronu.

â€œJaka sinapsaâ€ = EPSP dovoljno velik da sam digne neuron do spikea.

Pokus pokazao: i slabe i jake veze se mogu ojaÄati, ako se pobrineÅ¡ da postsinaptiÄki spike padne unutar tog prozora (npr. kod slabih sinapsi su ruÄno injektirali malu struju da potaknu spike nakon EPSP).

ZakljuÄak: bitan je timing, a ne samo jaÄina veze.

â€œNMDA receptori su kljuÄniâ€

NMDA receptor = poseban tip glutamatnog receptora koji je osjetljiv na napon i omoguÄ‡uje ulazak CaÂ²âº iona u neuron.

Taj CaÂ²âº signal je â€œmolekularni prekidaÄâ€ koji pokreÄ‡e plastiÄnost (LTP/LTD).

Kad su ih blokirali s lijekom D-AP5 â†’ nije bilo LTP-a â†’ dakle, bez NMDA nema uÄenja.

LTP (long-term potentiation) = trajno jaÄanje sinapse (poveÄ‡ava se vjerojatnost da Ä‡e signal proÄ‡i).

EPSP (excitatory postsynaptic potential) = mali "plusiÄ‡" napona na postsinaptiÄkom neuronu, kao mini podraÅ¾aj.

Evo paralela s event-based kamerom 

---

### U mozgu (neuroni):

* **PresinaptiÄki spike** = dolazni signal â†’ EPSP.
* **PostsinaptiÄki spike** = izlaz neurona.
* **STDP / LTP** = ako ulazni event stigne malo prije nego neuron ispali, veza se jaÄa.
* **NMDA receptor** = â€œgatekeeperâ€ koji kaÅ¾e: *event se raÄuna samo ako su se ulaz i izlaz poklopili u vremenu*.

---

### U event-based kameri:

* **Pixel event** = presinaptiÄki spike (svaki event je mala promjena â†’ mini EPSP).
* **Kamera/algoritam detektira pokret** = postsinaptiÄki spike (output).
* **STDP logika**:

  * Ako viÅ¡e pixela (ulaznih evenata) **u kratkom vremenu i prostoru** â€œokineâ€ i to dovede do registriranog pokreta (output), sustav zakljuÄi: *ti eventi su povezani, pojaÄaj im znaÄaj*.
* **NMDA paralela** = kao filter koji ne puÅ¡ta â€œrandom Å¡umâ€, nego traÅ¾i da se viÅ¡e evenata poklopi u pravom trenutku â†’ tek onda priznaje da je stvarno detekcija.

---

 Ukratko:
U mozgu â€“ sinapsa se jaÄa ako ulaz brzo dovede do izlaza.
U kameri â€“ grupa evenata se tretira kao znaÄajan pokret samo ako se prostorno-vremenski poklope i generiraju detekciju.

---

Pozitivno korelirani spikeovi (pre â†’ post, unutar ~20 ms)
â†’ rezultira LTP (ojaÄavanje sinapse).

Negativno korelirani spikeovi (post â†’ pre, unutar ~20 ms)
â†’ rezultira LTD (slabljenje sinapse).

Prozor djelovanja (temporal window):

Potencijacija = post-sinaptiÄki spike unutar +20 ms nakon EPSP.

Depresija = post-sinaptiÄki spike unutar âˆ’20 ms prije EPSP.

Izvan Â±40 ms = nema znaÄajne promjene.

NMDA receptori su obavezni i za LTP i za LTD (bez njih nema sinaptiÄke plastiÄnosti).

JaÄina poÄetne sinapse utjeÄe na plastiÄnost:

Slabe sinapse = lakÅ¡e jaÄaju (LTP).

Jako jake sinapse = manje podloÅ¾ne daljnjem jaÄanju.

Tip postsinaptiÄkog neurona:

GlutamatergiÄki = pokazuju STDP (LTP/LTD).

GABA neuroni = nema STDP efekta.

Uloga CaÂ²âº kanala:

L-type CaÂ²âº kanali pomaÅ¾u kod LTP, ali nisu nuÅ¾ni.

Za LTD (depresiju) jesu nuÅ¾ni.

STDP je asimetriÄan:

Ako ulaz doÄ‘e prije izlaza â†’ uÄenje = â€œovo je korisnoâ€ (LTP).

Ako izlaz doÄ‘e prije ulaza â†’ uÄenje = â€œovo nije korisnoâ€ (LTD).
Sve to ovisi o NMDA receptorima, vremenskom prozoru (~Â±20 ms) i jaÄini same sinapse.

Ako se viÅ¡e evenata dogodi vrlo brzo jedan nakon drugog (unutar â€œSTDP prozoraâ€ od ~20 ms), sustav ih tretira kao povezane.

Kao posljedica, postsynaptiÄki spike je jaÄi nego kada bi ti eventi doÅ¡li pojedinaÄno i razdvojeni u vremenu.

BioloÅ¡ki mozak â†’ pojaÄava sinapsu (LTP).

Event-based sustav â†’ grupira dogaÄ‘aje i â€œpojaÄava signalâ€, Å¡to olakÅ¡ava detekciju stvarnih objekata/pokreta.

Ok, ovo je sad super saÅ¾eto i profesionalno â€“ ovo su **kljuÄni zakljuÄci cijelog rada**, izvuÄeni za tvoj event-based vision kontekst:

---

### KljuÄne toÄke / natuknice:

1. **STDP vremensko pravilo je vrlo precizno i usko**:

   * Potencijacija (LTP) se dogaÄ‘a kada **postsynaptiÄki spike slijedi EPSP unutar +20 ms**.
   * Depresija (LTD) se dogaÄ‘a kada **postsynaptiÄki spike prethodi EPSP unutar âˆ’20 ms**.
   * Izvan Â±40 ms â†’ nema znaÄajne sinaptiÄke promjene.
   * Prelaz izmeÄ‘u LTP i LTD je **oÅ¡tra, samo ~5 ms**.

2. **JaÄina sinapse utjeÄe na plastiÄnost**:

   * Slabe sinapse = lako potenciraju (LTP).
   * Jako jake sinapse = mogu biti â€œsaturiraneâ€ i ne reagiraju viÅ¡e na pozitivno korelirane spikeove.

3. **Tip postsinaptiÄkog neurona je kljuÄan**:

   * GlutamatergiÄki neuroni â†’ pokazuju LTP i LTD.
   * GABAergiÄki neuroni â†’ nema sinaptiÄke modifikacije (nije osjetljivo).

4. **NMDA receptori i CaÂ²âº su kritiÄni**:

   * NMDA receptori â†’ obavezni i za LTP i za LTD.
   * L-type CaÂ²âº kanali â†’ potrebni za LTD, pomaÅ¾u za LTP.
   * Lokalni CaÂ²âº spikeovi unutar dendrita omoguÄ‡uju preciznu temporalnu detekciju.

5. **Temporalni slijed spikeova implementira Hebbovu logiku**:

   * Ako **ulaz (presynaptiÄki spike) uzrokuje izlaz (postsynaptiÄki spike)** â†’ veza se jaÄa (LTP).
   * Ako je redoslijed obrnut â†’ veza se slabije aktivira (LTD).
   * Ovo je prirodni â€œcausality detectorâ€ â†’ neuronska mreÅ¾a moÅ¾e uÄiti sekvence i predviÄ‘ati dogaÄ‘aje.

6. **Spontana aktivnost moÅ¾e â€œsaturiratiâ€ sinapse** â†’ starije sinapse u kulturi moÅ¾da ne mogu dodatno potencirati.

7. **Implications for event-based systems:**

   * **Brzo slijedeÄ‡i eventi â†’ tretiraju se kao povezani â†’ jaÄi output**.
   * Sustavi poput spiking CNN-a mogu koristiti STDP logiku da detektiraju obrasce u vremenskim eventima i odluÄe Å¡to je relevantno.
   * Temporalna asimetrija omoguÄ‡uje â€œprediktivno kodiranjeâ€ â†’ sliÄno onome Å¡to mozak radi kod navigacije i sekvencijalnog uÄenja.



A million spiking-neuron integrated circuit with a scalable communication network and interface
Paul A.Merolla&co.

- inspirirano strukturom mozga
- efikasna, skalabilna, fleksibilna, non-von Neumannova arhitektura
- suvremena silikonska tehnologija
- Äip od 5.4 milijardi tranzistora s 4096 neurosinaptiÄkih jezgri meÄ‘usobno povezanih preko intrachip networka
- network se sastoji od milijun programabilnih spiking neurona i 256 milijuna konigurabilnih sinapsi (sinapse su veze meÄ‘u neuronima; zato ima viÅ¡e sinapsi nego neurona jer veze nisu 1:1)
- Äipovi se mogu povezati u 2 dimenzije pomoÄ‡u interchip komunikacijskog interfacea -> skaliranje na razinu cortexlike sheeta proizvoljne veliÄine (cortex => vanjski dio mozga..."kora")
- omoguÄ‡ava koriÅ¡tenje kompleksnih neuronskih mreÅ¾a u realnom vremenu (npr. multiobject detekcija i klasifikacija)
- 400 px x 240px video input brzine 30 fps-a na Äipu troÅ¡i 63 miliwatta
Chatgpt:
Da, ako to stavimo u perspektivu, ovo je **priliÄno efikasno**, pogotovo za embedded ili edge AI Äipove. Hajde da to raÅ¡Älanimo:

* Video ulaz: **400 Ã— 240 px** â†’ 96.000 piksela po okviru.
* Brzina: **30 fps** â†’ 2.880.000 piksela obraÄ‘eno u sekundi.
* PotroÅ¡nja: **63 mW** â†’ 0,063 J po sekundi.

Ako raÄunamo **energiju po pikselu**:

E_per_pixel = 0.063 / (400 * 240 * 30) = 21.875e-9 J = 21.875 nJ/pixel

Za usporedbu, moderni edge AI Äipovi (npr. za male kamere ili IoT senzore) Äesto ciljaju **10â€“100 nJ/piksel** za video obrade pri visokoj efikasnosti.

ZakljuÄak: **63 mW za 400Ã—240 @ 30 fps je vrlo dobar rezultat**. Ovo je tipiÄno u rangu ultra-low-power AI kamera Äipova.

Cilj je stvoriti viÅ¡enamjenski kompjuter efikasan u vidu prostora i potroÅ¡nje resursa, skalabilan za velike neuronske mreÅ¾e i sinapse, dovoljno fleksibilan da odraÄ‘uje bihevioralne modele cortexa mozga

Takva raÄunala 2014. nisu postojalaa

Von Neumannova arhitektura je neefikasna i neskalabilna te ne moÅ¾e kvalitetno reprezentirati masivne, meÄ‘usobno povezane neuronske mreÅ¾e
Koristi se miks analognih i digitalnih neuromorfnih signala => imitacija neurobioloÅ¡kih procesa koriÅ¡tenjem:
- silicijskih neurona
- winner-take-all strujnih krugova 
- senzorskih strujnih krugova


Winner-take-all circuits by Gepetto

Apsolutno brate ğŸ’ªğŸ”¥ â€” ajmo to sad sloÅ¾it **jasno, saÅ¾eto i profesionalno**, ali da ti sjedne odmah u glavu kad ÄitaÅ¡.
Evo ti **natuknice o Winner-Take-All (WTA)** koje moÅ¾eÅ¡ doslovno ubacit i u rad ako Å¾eliÅ¡:

---

## ğŸ§  Winner-Take-All (WTA) circuits â€” natuknice

### ğŸ”¹ Osnovna ideja

* WTA (Winner-Take-All) krugovi su **neuromorfni elektroniÄki sustavi** koji oponaÅ¡aju **konkurenciju meÄ‘u neuronima** u mozgu.
* Cilj im je da **odaberu samo najaktivniji (najjaÄi) signal** meÄ‘u viÅ¡e ulaznih neurona ili kanala.
* Samo â€œpobjedniÄkiâ€ neuron ostaje aktivan â†’ ostali se **inhibiraju** (iskljuÄe).

---

### ğŸ”¹ BioloÅ¡ka inspiracija

* Temeljeni su na principu **lateralne inhibicije** u bioloÅ¡kim neuronskim mreÅ¾ama.
* U mozgu aktivni neuron **koÄi (inhibira)** susjedne neurone â†’ rezultat je **pojaÄan kontrast i selektivnost percepcije**.
* Ovaj mehanizam omoguÄ‡uje **fokus paÅ¾nje** i efikasnu obradu informacija (npr. u ljudskoj mreÅ¾nici).

---

### ğŸ”¹ Kako WTA krug radi

1. **Ulaz:** viÅ¡e analognih signala (npr. struja ili napon iz razliÄitih neurona/piksela).
2. **Natjecanje:** svi ulazi se natjeÄu u istom krugu.
3. **Inhibicija:** slabiji ulazi se potiskuju putem inhibicijskog feedbacka.
4. **Izlaz:** samo najjaÄi signal ostaje aktivan â†’ â€œwinner takes allâ€.

---

### ğŸ”¹ Implementacija u hardveru

* Realizira se koriÅ¡tenjem **MOS tranzistora** i **strujnih zrcala** (current mirrors).
* Krug se ponaÅ¡a poput â€œstrujnog trÅ¾iÅ¡taâ€ â€” ulaz s najveÄ‡om strujom **privuÄe sve resurse** i â€œpobijediâ€.
* TipiÄno se koristi u **neuromorfnim procesorima** (npr. Intel Loihi, IBM TrueNorth, DYNAP-SE).

---

### ğŸ”¹ Prednosti

* **Smanjuje redundanciju** â€” aktivan je samo najvaÅ¾niji neuron.
* **PoveÄ‡ava kontrast** i selektivnost u prepoznavanju uzoraka.
* **Å tedi energiju** jer se ne obraÄ‘uju svi ulazi.
* OmoguÄ‡uje **sparse coding** â€” mali broj neurona aktivan u danom trenutku.

---

### ğŸ”¹ Primjene

* **RaÄunalni vid (event-based senzori):** bira piksele s najveÄ‡om promjenom kontrasta.
* **Prepoznavanje uzoraka:** odabir najrelevantnijeg neurona u skupu.
* **Klasifikacija i clustering:** odreÄ‘uje koji neuron najbolje â€œpredstavljaâ€ ulazni uzorak.
* **Roboti i edge sustavi:** koristi se za brze odluke uz minimalnu potroÅ¡nju energije.

---

### ğŸ”¹ Ukratko

| Pojam                     | ObjaÅ¡njenje                                                         |
| ------------------------- | ------------------------------------------------------------------- |
| **Winner-Take-All (WTA)** | Sustav koji aktivira samo najjaÄi ulaz, ostale potiskuje            |
| **BioloÅ¡ki ekvivalent**   | Lateralna inhibicija meÄ‘u neuronima                                 |
| **KljuÄna funkcija**      | Odabir dominantnog signala i smanjenje redundancije                 |
| **Prednosti**             | UÄinkovitost, energetska Å¡tednja, bolja selektivnost                |
| **Upotreba**              | Neuromorfni Äipovi, senzori vida, robotski sustavi, AI akceleratori |

---



- Digitalno implementirani spiking neuroni su efikasniji od svih dosadaÅ¡njih dizajna
- omoguÄ‡avaju one-to-one correspondence izmeÄ‘u softvera i hardvera => ÄŒa znaÄi one-to-one?
Svaka funkcija softvera (npr. odreÄ‘eni algoritam, neuronski sloj, procesiranje piksela) ima direktno odgovarajuÄ‡i hardverski resurs koji ju izvrÅ¡ava.
Nema posrednog sloja ili generiÄkog procesora koji simulira funkciju â€” hardware je dizajniran toÄno za tu operaciju.

- stvoreni su event driven komunikacijski frameworkovi => komunikacija se deÅ¡ava samo kad se dogodi event
- na taj naÄin se emulira unutarnja povezanost unutar mozga

Colocated memory and computation + event driven communication nadilazi von Neumann bottleneck

Colocated memory and computation + event driven communication nadilazi von Neumann bottleneck

Von Neumann bottleneck

* KlasiÄna arhitektura raÄunala (CPU + RAM) ima **odvojen procesor i memoriju**.
* Podaci i instrukcije se stalno Å¡alju izmeÄ‘u memorije i CPU-a preko **jedne sabirnice**.
* **Problem:** sabirnica je usko grlo â†’ CPU Äesto Äeka podatke iz memorije â†’ sporije i manje energetski efikasno.
* To je tzv. **von Neumann bottleneck**.

Colocated memory and computation

* â€œColocatedâ€ znaÄi da **memorija i procesiranje stoje zajedno**, na istom Äipu ili blizu.
* Prednost: podatke **ne treba stalno pomjerati preko sabirnice** â†’ manje Äekanja, manja potroÅ¡nja energije.
* Primjer: **neuromorfni Äipovi**, gdje svaki â€œneuronski elementâ€ ima svoje â€œlocal memoryâ€ i logiku za izraÄun.


Event-driven communication

* Sustav **reagira samo kad se dogodi event** (npr. piksel se promijeni).
* Za razliku od stalnog pollanja, **samo se Å¡alju podaci koji su relevantni**.
* Prednost: joÅ¡ manja potroÅ¡nja i brÅ¾i prijenos informacija.


ZakljuÄak

* Kombinacija **lokalne memorije + event-driven komunikacije** znaÄi:

  * Nema stalnog Äekanja na podatke izmeÄ‘u procesora i memorije.
  * Podaci se Å¡alju **samo kad je potrebno**.
* Dakle, sustav **nadilazi von Neumann bottleneck** â†’ brÅ¾e, efikasnije, manje energije troÅ¡i, posebno kod neuromorfnih i edge AI sustava.

KljuÄna arhitektura => mreÅ¾a neurosinaptiÄkih jezgri koja moÅ¾e izgraditi velike spiking neural networke koji su efikasni, skalabilni i fleksibilni

Osnovna graÄ‘evna jedinica je "core" -> samostojeÄ‡a neuronska mreÅ¾a s 256 inputa (aksona) i 256 outputa (neurona) povezanih preko 256x256 usmjerenih, programabilnih sinaptiÄkih veza
Od viÅ¡e coreva mogu se graditi sloÅ¾enije mreÅ¾e pomoÄ‡u globalne, distribuirane on- and off-chip povezivosti
Svaki neuron na svakom coreu moÅ¾e se povezati s bilo koji aksonom na bilo kojem drugom coreu (jako dobra povezanost viÅ¡e neuronskih mreÅ¾a)

Aksionski branching je implementiran hijerarhijski u 2 stadija:

Najprije 1 konekcija putuje od starta (prvog corea) skoro do cilja (drugog corea), ali se po dolasku do aksona razdvaja u puno manjih konekcija koje prolaze joÅ¡ kratku udaljenost unutar samog corea

Neuroni se kreÄ‡u u stepsima od 1ms (orkestrirano pomoÄ‡u globalnog 1-kHz clocka)

Uz opisani globalni sinkronizacijski clock (koji osigurava 1-1 konekciju softvera i hardvera), coresi koriste i paralelni  i event driven naÄin rada
Osnovni napon upravlja potpuno asiknronom intercore komunikacijom i event-driven intracore komunikacijom. Taj napon radi po principu all-or-nothing spike evenata koji predstavljaju aktivaciju pojednih neurona

Efikasno zato jer se neuroni klasteriraju u klastere koji izvlaÄe svoje inpute iz sliÄnih poolova aksona (neuroni se grupiraju prema aksonima)
Samo spike eventi se Å¡alju komunikacijom izmeÄ‘u jezgri . Å to su eventi jaÄi, to se ÄeÅ¡Ä‡e Å¡alju

Ta je arhitektura skalabilna jer jezgre na Äipu, kao i sami Äipovi imaju moguÄ‡nsot slaganja u 2 dimenzije (sliÄno kao cortex sisavaca)
Svaki spike event  cilja toÄno odreÄ‘eni "pool" neuorna na ciljanoj jezgri i tako smanjuje broj long-range spike evenata koji predstavljaju kljuÄni bottleneck (event se ne Å¡alje svuda nego toÄno odreÄ‘enim neuronima koji ga trebaju primiti)
Fault tolerance -> povremene greÅ¡ke u core-u i na Äipovima ne oslabljuju rad cijelog sustava

Arhitektura je fleksibilna jer je svaki neuron individualno konfigurabilan i imitira prave neurone podrÅ¾avajuÄ‡i razne funkcije i bioloÅ¡ki relevantne spiking mehanike
Svaka sinapsa se moÅ¾e individualno "paliti i gasiti" i moÅ¾e joj se dodjeliti relativna snaga (sliÄno kao weighted metrike)
Svaka neuron-axon veza je programabilna s ukljuÄenim axonal delayom
Neuroni i sinapse mogu prikazivati programirano stohastiÄko (nasumiÄno, ali s predvidivim obrascem) ponaÅ¡anje korsteÄ‡i pseudo-random number generator (1 po jezgri)
Arhitektura podrÅ¾ava imitaciju psiholoÅ¡ke dinaimke i anatomske povezanosti.
Ima: feed-forward, reccurent i lateral veze

---

### **1ï¸. Feed-forward veze**

* Informacija ide **jednosmjerno od ulaza prema izlazu**.
* Nema povratnih veza â†’ signal ne vraÄ‡a se unatrag.
* TipiÄno u **klasiÄnim perceptronima i CNN-ovima**.
* Prednost: jednostavno, stabilno, brzo raÄunanje.
* Mana: ne moÅ¾e modelirati vremenske sekvence ili stanje memorije.

---

### **2ï¸. Recurrent veze**

* Informacija se **vraÄ‡a unatrag unutar mreÅ¾e** â†’ stvaraju **petlje**.
* OmoguÄ‡uju mreÅ¾i da **pamti prethodne ulaze** â†’ modeliranje sekvenci, npr. tekst, govor, vremenske serije.
* Primjeri: RNN, LSTM, GRU.
* Mana: teÅ¾e trenirati (problem â€œexploding/vanishing gradientsâ€).

---

### **3ï¸. Lateral veze**

* Veze **izmeÄ‘u neurona unutar istog sloja**.
* OmoguÄ‡uju **modulaciju aktivnosti susjednih neurona**, konkurenciju ili potporu.
* TipiÄno u **bioloÅ¡kim mreÅ¾ama** â†’ lateralna inhibicija pomaÅ¾e kod detekcije rubova, kontrasta, itd.
* U umjetnim mreÅ¾ama rjeÄ‘e, ali se koristi za **attention, normalizaciju ili interneuron modulaciju**.

---

Core ima individualno adressable aksone, konfigurabilni synaptic crossbar array i programabilne neurone

Core (u neuromorfnom Äipu)

Individualno addressable aksone

Svaki aksone (put kojim ide signal od neurona) moÅ¾e se posebno adresirati i kontrolirati.

ZnaÄi moÅ¾eÅ¡ poslati signal toÄno odreÄ‘enom neuronu ili grupi neurona, bez da utjeÄeÅ¡ na ostatak mreÅ¾e.

Konfigurabilni synaptic crossbar array

MreÅ¾a sinapsi (kao matrica) gdje moÅ¾eÅ¡ konfigurirati teÅ¾ine veze izmeÄ‘u neurona.

OmoguÄ‡uje da jedan neuron Å¡alje signal viÅ¡e neurona s razliÄitim jaÄinama â†’ kljuÄno za uÄenje i prilagodbu.

Programabilni neuroni

Neuroni Äipa se mogu programirati: npr. prag aktivacije, dinamiku spike-a, reakciju na inpute.

To omoguÄ‡uje simulaciju razliÄitih tipova bioloÅ¡kih neurona i razliÄitih algoritama unutar istog hardwarea.

Ukratko:

Aksone = kontrola kamo signal ide

Crossbar = kontrola koliko je signal jak izmeÄ‘u neurona

Programabilni neuroni = kontrola kako neuron reagira na signal

Unutar corea informacija teÄe od presinaptiÄkih aksona kroz aktivne sinapse u crossbaru kako bi stvarala inpute za sve povezane postsynaptic neurone

Aksioni se aktiviraju pomoÄ‡u input spike evenata koje generiraju neuroni bilo gdje u sustavu i Å¡alju se dalje nakon definiranog axonal delaya (od 1 do 15 vremenskih jedinica)
Mozak ima dedicated "Å¾icu" za svaku konekciju; Äip ima time-multiplexed Å¾ice koje povezuju 2-d mesh network rutera
Svaki ruter ima 5 portova (sjeverni, juÅ¾ni, istoÄni, zapadni i lokalni)
Ruteri su osnova 2-d mesh networka koji povezuje 64x64 array coresa

Kada neuron u coreu spike-a, u lokalnoj memoriji traÅ¾i axonal delay (4 bita) i adresu destinacije (8 bitova apsolutne adrese za target aksone i dvije 9-bitne relativne adrese koje predstavlaju core "skokove" u svakoj dimenziji ciljanog corea)
Te se informacije enkodiraju u paket koji se Å¡alje pomoÄ‡u mesha od corea do corea (prvo po x-u, pa po y-u) => takva je komunikacije deadlock free
Za implementaciju feedback veza u coreu, gdje se neuron spaja na akson isto corea, paket se dostavlja koristeÄ‡i lokalne kanale rutera (efikasno jer se ne napuÅ¡ta core)
Za skaliranje opisanog sustava (2-d mesh) u kojem je broj interchip konekcija ograniÄen, koristi se merge-split struktura na 4 ruba mesha da bi se postojeÄ‡i spikeovi serijalizirali, a izlazeÄ‡i deserijalizirali. Svakom spikeu se da labela njegovog reda (ako putuje istok-zapad) ili stupca (ako putuje sjever-jug) prije nego se spoje u shared link koji postoji na Äipu
TakoÄ‘er, spikeovi koji ulaze na Äip iz shared linka, razdvajaju se u odgovarajuÄ‡i redak ili stupac koristeÄ‡i info sa tagova

ObjaÅ¡njenje:

---

### 1ï¸.Osnovni tok informacija unutar corea

* **PresinaptiÄki aksone** Å¡alju spike dogaÄ‘aje kroz **aktivne sinapse u crossbar**.
* Crossbar distribuira signal prema **postsynaptiÄkim neuronima** unutar corea.
* **Input spike event** = signal od nekog neurona bilo gdje u sustavu.
* **Axonal delay** = vremensko kaÅ¡njenje prije nego spike stigne do target neurona (1â€“15 jedinica).

**Ukratko:** neuron spike-a â†’ signal ide kroz aksone i sinapse â†’ dolazi do drugih neurona, uz kaÅ¡njenje.

---

### 2ï¸.Razlika izmeÄ‘u mozga i Äipa

* **Mozak:** svaka veza ima svoju â€œÅ¾icuâ€ â†’ fiziÄki dedicated.
* **ÄŒip:** koristi **time-multiplexed Å¾ice** â†’ jedna fiziÄka veza prenosi spikeove od viÅ¡e neurona koristeÄ‡i redoslijed i vrijeme.
* Spikeovi putuju kroz **2-d mesh network**: mreÅ¾a rutera koji povezuju coreove u x i y dimenziji.

---

### 3ï¸.Ruter i 2-d mesh network

* Svaki ruter ima **5 portova**: sjever, jug, istok, zapad, lokalni (core unutar kojeg se nalazi).
* Spike ide kroz mesh tako da prvo ide **po x osi, pa po y osi** â†’ deadlock-free (nema zastoja u mreÅ¾i).
* MreÅ¾a povezuje **64Ã—64 corea**.

---

### 4ï¸.Paket spike-a

* Kada neuron spike-a:

  * TraÅ¾i se **axonal delay** (4 bita).
  * TraÅ¾i se **adresa destinacije** (8-bit apsolutna + 2Ã—9-bit relativne za target core).
  * Ove informacije se enkodiraju u **paket** i Å¡alju kroz mesh.

* **Feedback veze unutar corea** â†’ spike ostaje unutar corea, koristi lokalni kanal rutera â†’ efikasno.

---

### 5ï¸.Skaliranje i interchip komunikacija

* Problem: broj veza izmeÄ‘u Äipova je ograniÄen.

* RjeÅ¡enje: **merge-split struktura**:

  * Spikeovi se **serijaliziraju** prije slanja kroz shared link.
  * Na odrediÅ¡tu se **deserijaliziraju**.
  * Svakom spikeu se dodaje **labela reda (x)** ili **stupca (y)** â†’ omoguÄ‡uje pravilan routing.

* Spikeovi koji dolaze iz shared linka se **razdvajaju u odgovarajuÄ‡i redak/stupac** prema tagu.

---

###  Ukratko, Å¡to se dogaÄ‘a

1. Neuron spike-a â†’ lokalno traÅ¾i delay i adresu.
2. Spike se enkodira u paket â†’ ide kroz 2D mesh network rutera.
3. Ako je intra-core feedback â†’ koristi lokalni kanal, nema routing po meshu.
4. Ako ide na drugi Äip â†’ spikeovi se serijaliziraju, Å¡alju shared linkom, zatim deserializiraju i rasporede po target coreu.

**Cilj:**

* Efikasna, skalabilna, deadlock-free komunikacija izmeÄ‘u 64Ã—64 coreova + interchip povezanost.
* OmoguÄ‡uje **tisuÄ‡e paralelnih spike dogaÄ‘aja** da se prenesu brzo i precizno.

---

Implementacija: milijun spiking neurona i 256 milijuna sinapsi i 5.4 milijarde tranzistora na prostoru od 4.3 cm2
Ima 428 milijuna bitova on-chip memorije
Svaki core ima 104,448 bitova lokalne memorije za pohranu stanja sinapsi (65,536), stanja neurona i parametre (31,232), adrese destinacija (6656) i axonal delays (1024)
Energija: 20 mW po cm2, dok CPU troÅ¡i 50-100 W po cm2
Active power density je nizak zbog arhitekture
Passive power density je nizak zbog tranzistora s malim leakegom

4096 puta viÅ¡e coreva na 15 puta manje povrÅ¡ine, sa 100 puta manje potroÅ¡nje energije u odnosu na prethodna rjeÅ¡enja

OmoguÄ‡ava event driven asinkrono-sinkroni pristup => implementirano koristeÄ‡i: offline learning (CNN, liquid state machines, restricted Boltzman machines, hidden Markov models, support vector machines, optical flow i multimodal classification)
Offline learning metode

CNN (Convolutional Neural Network)

Ekstrahira prostorne znaÄajke iz slika/video koristeÄ‡i konvolucijske filtere.

Liquid State Machines (LSM)

Vrsta recurrent spiking neural network; pamti kratkoroÄne temporalne obrasce â†’ dobro za vremenske serije i neuromorfne spike podatke.

Restricted Boltzmann Machines (RBM)

ProbabilistiÄki model za uÄenje distribucija i reprezentacija podataka; Äesto se koristi za feature extraction i pretreniravanje dubljih mreÅ¾a.

Hidden Markov Models (HMM)

Model sekvencijalnih podataka gdje stanja nisu direktno vidljiva, ali generiraju opaÅ¾ene dogaÄ‘aje â†’ koristi se za govor, signale i vremenske serije.

Support Vector Machines (SVM)

Supervised learning metoda koja pronalazi optimalnu granicu izmeÄ‘u klasa u feature prostoru.

Optical Flow

Tehnika za praÄ‡enje kretanja objekata u video sekvencama prema promjeni intenziteta piksela kroz vrijeme.

Multimodal Classification

Kombinacija viÅ¡e tipova podataka (npr. video + audio + senzori) za preciznu klasifikaciju.
ÄŒip vrti te iste algoritme bez da ih treba modificirati

Za dodatno testiranje, razvijena je i dodatna multiobject detekcija i klasifikacija s fiksnom kamerom
Zadaci: detekcija ljudi, auti, i ostalih vozila na slikama gdje se pojavljuju rijetko s ciljem minimizacije false detekcija (sustav spikea samo kad se neÅ¡to stvarno pojavi; ne troÅ¡i eneriju bezveze)
Radi na 400x240 piksela. ÄŒip je troÅ¡io 63 mW na 30-fps videu u 3 boje koji je zatim bio skaliran na 1920x1080. Bilo je potrebno konvertirati piksele u spike evente jer je video bio snimljen standarndom kamerom
dobre performanse

MoguÄ‡e koristiti i spike-based retinal cameru
Implementirana je vizualna "mapa" orijentacijsko selektivnih filtera inspiriranih ranim procesiranjem u coretexu sisavaca koji se Äesto koristi u CV za feature extraction

Svih milijun neurona dobilo je feedforward inpute s orientation biasima iz vizualnog prostora skupa s rekurzivnim konekcijama meÄ‘u bliskim featuresima

Standardni benchmark u arhitekturi raÄunala je: energy per operation
U domeni konfigurabilnih neuralnih arhitektura, osnovna operacija je "sinaptiÄki event" koji predstavlja source neuron koji Å¡alje spike event target neuronu putem posebne (non-zero) sinapse
SinaptiÄki eventi su atomiÄne jedinice mjerenja jer se koliÄina raÄunanja, memorija, komunikacija, snaga, povrÅ¡ina i brzina proporcionalno poveÄ‡avaju s brojem sinapsi

KoristeÄ‡i rekurzivno poveane mreÅ¾e, izmjeren je total power i energy per synaptic event
Power consumption  je funkcija spike rate-a, prosjeÄne udaljenosti koju spikeovi prolaze i prosjeÄnog broja aktivnih sinapsi po neuronu (synaptic density)

Ako je "fire" u prosjeku 20 hz uz 128 aktivnih sinapsi, ukupna izmjerena snaga iznosila je 72mW (na naponu od 0.775 V), Å¡to odgovara 26pj po sinaptiÄkom eventu

U usporedbi s standarnim raÄunalom, troÅ¡i se 176000 x manje energije po eventu
OmoguÄ‡ava se individualno programiranje neurona i njihovih konekcijama
SPOS -> sinaptiÄke operacije po sekundi u ovom sustavu
Standardna superraÄunala -> FLOPS (floating point operations per second)

Slaganjem viÅ¡e TrueNorth brainchipova, mogu nastati superraÄunala sa stotinama tisuÄ‡a jezgri, stotinama milijuna neurona i stotinama milijardi sinapsi

Arhitektura -> slika -> svaki node je spojen sa svakim (node = core, edge = neural connection)

#####################################################################################################
- NaÅ¡a san video SNN in 5 minutes...pa zaÅ¡ ne hitit oko
- Mozak jako efikasno procesira informacije
- SNNovi su novi tip AI inspiriran komunikacijom mozga
- ObiÄne neuronske mreÅ¾e baziraju se na kontinuiranim signalima, SNNovi koriste spikeove kao mozak
- Spikes => diskretni eventi koji se javljaju kroz vrijeme
- RealitiÄniji i efikasniji za obradu temporalnih informacija (informacije koji nisu statiÄne, nego imaju vremensku "dimenziju"...videa, signali, Å¾ivÄani signali, eventi za event kamere i sl.)
- Real time procesiranje, event based vision, robotika, autonomna vozila

Komponente SNN-ova:
- meÄ‘usobno povezani neuroni
- svaki neuron prima input od drugih
- inputi su elektriÄni impulsi koje zovemo "spikes"

- Kad neuron primi dovoljno spikeova u kratkom periodu, "fire-a" svoj spike
- Tako neuroni komuniciraju
- Timing spikeova je kljuÄan => enkodira informacije o inputu
- ÄŒa je jaÄi input, jaÄi je i spike
- Sinapse - veze izmeÄ‘u neurona
- Synaptic plasticity - sposobnost da sinapsa jaÄa ili slabi kroz vrijeme => tako se SNN-ovi adaptiraju i uÄe kroz vrijeme
- Primjer: speÄemo se na peÄ‡, pain receptori poÅ¡alju spikeove mozgu, to pojaÄava vezu meÄ‘u neuronima zaduÅ¾enim za toÄno taj proces (osjet boli zbog vruÄ‡e peÄ‡i), iduÄ‡i put kad smo blizu vruÄ‡eg objekta, mozak Ä‡e brÅ¾e prepoznati opasnost i brÅ¾e Ä‡emo reagirati => synaptic plasticity IRL - "neurons that fire together, wire together"

Encoding information => kako pretvorit real-world data u spike patterne?
- Pretvorba naÅ¡eg jezika u jezik neurona



- Rate coding -> frequency spikeova predstavlja intenzitet inputa => Äa je input jaÄi, to ima viÅ¡e spikeova...tipa...video koji prikazuje high-speed let drona stvara viÅ¡e spikeova nego video bijelega zida na kojemu se niÅ¡ ne deÅ¡ava

- NajklasiÄniji i najÄeÅ¡Ä‡e koriÅ¡ten model.

- Frekvencija spikeova = intenzitet podraÅ¾aja.

- Tvoj primjer s dronom je savrÅ¡en â€” ako kamera â€œvidiâ€ puno promjena â†’ neuroni Ä‡e ispucavati puno spikeova. Ako je scena statiÄna (bijeli zid), spikeova gotovo da nema.
ğŸ‘‰ OgraniÄenje: sporije reagira jer se Äeka da se skupi odreÄ‘eni broj spikeova da bi se dobila jasna slika intenziteta.

- Temporal coding -> koristi se precizni timing spikeova za prijenos informacija. ToÄno vrijeme kad se spike dogodi moÅ¾e biti kljuÄno; posebno za taskove gdje je bitno vrijeme i praÄ‡enje sekvenci

- Tu je vaÅ¾an toÄan trenutak kad spike doÄ‘e.

- ÄŒak i ako je broj spikeova isti, razliÄit raspored u vremenu moÅ¾e nositi razliÄite informacije.

- Super za event-based senzore i zadatke gdje redoslijed i precizno vrijeme imaju smisla (npr. prepoznavanje govora, ritma, ili toÄno kada je objekt uÅ¡ao u vidno polje).
ğŸ‘‰ Prednost: moÅ¾e biti ekstremno energetski efikasno, jer mali broj spikeova moÅ¾e nositi puno info.

- Population coding -> koristi se grupa neurona da predstavlja 1 input. Svaki neuron u populaciji predstavlja specifiÄni feature inputa. Potpuni pattern aktivnosti kroz populaciju predstavlja potpunu informaciju; npr. razliÄiti neuroni mogu "fire-ati" za razliÄite boje unutar slike

- Radi se o skupinama neurona â€” svaki neuron se â€œpaliâ€ za odreÄ‘eni feature (npr. specifiÄnu boju, kut linije, smjer kretanja).

- Informacija se dobiva iz kolektivnog uzorka aktivnosti svih neurona.

- Primjer: u vidnom korteksu mozga razliÄiti neuroni su specijalizirani za razliÄite orijentacije linija â†’ cijela populacija ti daje kompletnu reprezentaciju slike.
ğŸ‘‰ Ovo je â€œrobustnijeâ€ jer se informacija ne oslanja na jedan neuron nego na distribuciju aktivnosti kroz cijelu populaciju.

- Neuron model
- LIFT model => matematiÄki model toga kako neuroni procesiraju spikeove
- Kanta s vodom => neuron
- Kapljice vode => nadolazeÄ‡i spikeovi
- Svaki spike dodaje malo vode u kantu/napona u neuron

- Kanta ima malu Å¡kulju koja uzorkuje da sporo gubi vodu kroz vrijeme => to predstavlja slabljenje napona u neuronu s prolaskom vremena (ono kad na kameri event izblijedi)
- Ako se kanta napuni i prelije, to je ekvivalentno temu kad neuron dobije dovoljno napona da postigne spike i resetira se  da bi mogao obraÄ‘ivati novu rundu inputa => neuron fireing

- Moremo prilagoÄ‘avat koliko se voda gubi i potrebnu koliÄinu vode da se kanta napuni (dakle; tunable parametri su threshold za spike i vrijeme slabljenja eventa)

- Za slaganje SNN-ova => neuroni + sinapse + definiranje kako sinapse uÄe + layeri neurona + broj neurona u layeru

RATE VS TEMPORAL: 
https://github.com/AntonioLabinjan/Simulation-of-rate-and-temporal-coding/tree/master




Opportunities for neuromorphic computing algorithms and applications

Catherine D. Schuman & co.

Tehnologije neuromorfnog computinga bit Ä‡e vaÅ¾ne u buduÄ‡nosti. Puno rada posveÄ‡eno je hardverskom djelu
Pregled nedavnih neuromorfnih algoritama i njihovih primjena

BliÅ¾i se kraj Moorovog zakona i Dennardovog scalinga. TraÅ¾e se nove tehnologije za nastavak napredovanja performansi.

Chatgpt explained:
---

### ğŸ’¡ **Moorov zakon (Mooreâ€™s Law)**

**Definicija:**
Gordon Moore (suosnivaÄ Intela) 1965. je primijetio da se **broj tranzistora na integriranom krugu otprilike udvostruÄuje svake dvije godine**, dok se **cijena po tranzistoru smanjuje**.

**Å to to znaÄi:**

* ViÅ¡e tranzistora = **veÄ‡a raÄunalna snaga**
* Manji tranzistori = **manja potroÅ¡nja energije i niÅ¾i troÅ¡kovi**
* Dakle, raÄunala postaju **brÅ¾a, manja i jeftinija** svake 1â€“2 godine

**Primjer:**
Procesor iz 2000. imao je moÅ¾da 30 milijuna tranzistora.
Danas ih high-end Äip ima **preko 100 milijardi!**

**Aliâ€¦**
Danas smo doÅ¡li do **fiziÄkih granica minijaturizacije** â€” tranzistori su veÄ‡ veliÄine par **nanometara** (manji od virusa!), pa se dalje teÅ¡ko ide klasiÄnim litografskim metodama.

---

### âš™ï¸ **Dennardov scaling (Dennard scaling)**

**Definicija:**
Robert Dennard (IBM) 1974. rekao je da kad se tranzistori smanjuju,
**napon i struja se proporcionalno smanjuju**, tako da **snaga po povrÅ¡ini ostaje konstantna**.

**Drugim rijeÄima:**
Ako smanjiÅ¡ tranzistor 2x u svemu â€” visinu, Å¡irinu, napon â€”
on troÅ¡i **isto energije po kvadratnom milimetru**, ali ima **dvostruko viÅ¡e tranzistora** â†’ performanse rastu bez poveÄ‡anja potroÅ¡nje energije ili topline.

**To je omoguÄ‡ilo:**
ğŸ‘‰ ViÅ¡e tranzistora + veÄ‡a brzina + ista potroÅ¡nja = eksplozija performansi od 80-ih do ranih 2000-ih.

**Aliâ€¦**
Oko **2005. scaling se raspao.**

* Naponi viÅ¡e ne mogu padati proporcionalno (fiziÄke granice â€” â€œleakage currentâ€, tuneliranje elektrona kroz tanke gate-oxide slojeve).
* Snaga i temperatura su poÄele **drastiÄno rasti**.
  â¡ï¸ Zbog toga su frekvencije CPU-a stale oko 3â€“4 GHz i pojavila se era **viÅ¡ejezgrenih procesora** i **energetske optimizacije**.

---

### ğŸ§  Ukratko:

| Zakon                 | Ideja                                                 | Å to je omoguÄ‡io                  | ZaÅ¡to viÅ¡e ne vrijedi                      |
| --------------------- | ----------------------------------------------------- | -------------------------------- | ------------------------------------------ |
| **Moorov zakon**      | Broj tranzistora se udvostruÄuje svake 2 god.         | Eksponencijalni rast performansi | FiziÄke granice minijaturizacije           |
| **Dennardov scaling** | Manji tranzistori troÅ¡e proporcionalno manje energije | ViÅ¡e brzine bez viÅ¡e topline     | Gubitak proporcionalnosti, previÅ¡e topline |

---

ğŸ’¥ **Å to sad?**
Kako se pribliÅ¾avamo kraju oba zakona, istraÅ¾uju se nove paradigme:

* **3D Äipovi** (vertikalno slaganje tranzistora)
* **Neuromorfni Äipovi** (poput IBM TrueNorth, Intel Loihi)
* **Kvantno raÄunarstvo**
* **OptiÄki procesori**
* **Spintronika i memristori**

---

Neuromorfna raÄunala su jedna od tih novih tehnologija
Pojam "neuromorphic" je osmislio Carver Mead kasnih '80-ih
Odnosio se na: miks analogno-digitalnih implementacija raÄunarstva inspiriranog mozgom
Sada ipak obuhvaÄ‡a veÄ‡i raspon raznovrsnih hardverskih implementacija

Neuromorfna raÄunala - non-von Neumann raÄunala Äija struktura i funkcionalnosti su inspirirane mozgom i sastoje se od neurona i sinapsi
Von Neumann raÄunala sastoje se od odvojenih jedinica za CPU i memoriju gdje se posebno pohranjuju podaci i instrukcije
U neuromorphic raÄunalima i procesiranjem i memorijom upravljaju neuroni i sinapse
Programi u neuromorphic raÄunalima definirani su strukturom neural networka i njihovih parametara, a ne eksplicitnim instrukcijama kao Å¡to je sluÄaj kod von Neumann raÄunala
Von Neumann raÄunala enkodiraju informacije kao numeriÄke vrijednosti u binarnom sustavu, a neuromorphic raÄunala primaju spikeove kao input
Koristi se vrijeme pojave spikea, intenzitet i oblik za enkodiranje numeriÄkih informacija
Binarne vrijednosti mogu se pretvoriti u spikeove i obratno

Neuromorfna raÄunala se u velikoj mjeri koriste paralelizmom gdje se izraÄuni obavljaju koriÅ¡tenjem viÅ¡e neurona i sinapsi istovremeno
No, izraÄuni koje neuroni i sinapse rade su relativno jednostavni u usporedbi s von Neumann sistemima
Collocated processing and memory (procesi i memorija su na istom mjestu). Iako se nekad neuroni smatraju processing unitima, a sinapse memorijom, u veÄ‡ini implementacija i neuroni i sinapse predstavljaju i memoriju i procese
PomaÅ¾e izbjeÄ‡i von Neumann bottleneck (odvojenost procesora i memorije uzrokuje usporavanje u maksimalnom moguÄ‡em throughputu)
PomaÅ¾e izbjeÄ‡i pristup podacima iz glavne memorije Å¡to inaÄe troÅ¡i puno energije

KljuÄne znaÄajke neuromorfnih raÄunala:

1. Inherentna skalabilnost

Neuromorfna raÄunala su prirodno skalabilna â€“ dodavanjem novih Äipova poveÄ‡ava se broj neurona i sinapsi koje sustav moÅ¾e realizirati.

ViÅ¡e fiziÄkih neuromorfnih Äipova moÅ¾e se povezati u jedan veliki sustav za izvoÄ‘enje veÄ‡ih mreÅ¾a.

To je veÄ‡ uspjeÅ¡no ostvareno kod sustava kao Å¡to su SpiNNaker i Intel Loihi.

2. RaÄunanje temeljeno na dogaÄ‘ajima (event-driven computation)

Sustav obraÄ‘uje samo kada postoje podaci â†’ ogromna energetska uÄinkovitost.

Neuroni i sinapse rade samo kada ima spikeova (impulsa) za obraditi.

Aktivnost mreÅ¾e je vremenski rijetka (temporalno rijetka), Å¡to dodatno Å¡tedi resurse.

3. StohastiÄnost (sluÄajnost)

Neuromorfni sustavi mogu ukljuÄivati elemente nasumiÄnosti u ponaÅ¡anju neurona (npr. u njihovom okidanju).

Ova â€œÅ¡umovitostâ€ (noise) moÅ¾e biti korisna â€“ omoguÄ‡uje robustnije i prirodnije ponaÅ¡anje sustava, sliÄno bioloÅ¡kom mozgu.

Neuromorfna raÄunala troÅ¡e ektremno malo energije => event driven & parallel => u bilo kojoj vremenskoj toÄki, samo mali dio sustava je aktivan, a ostatak je "idle"
Implementiraju "neural-network style" raÄunanja => prirodna platforma za rad s brojnim primjenama machine learninga i AI
Trenutno se iz mozga najviÅ¡e koriste neuroni i sinapse, ali joÅ¡ se istraÅ¾uje mogu li se joÅ¡ neki koncepti mozga koristiti
Tehnologije su silicon-based, ali istraÅ¾uju se novi materijali popur phase-change, ferroelectric, non-filamentary topological insulatora ili chanell-doped biomembrana
Razni neuromorfni ureÄ‘aji imaju razne ciljeve i pristupe koriÅ¡tenja tehnologije


---

### ğŸ§  **SaÅ¾etak â€“ Trenutno stanje i smjer razvoja neuromorfnih raÄunala**

**1. Neuromorfni hardver veÄ‡ postoji i razvija se brzo**

* Za razliku od nekih drugih buduÄ‡ih tehnologija, **neuromorfni Äipovi veÄ‡ postoje** i **dostupni su istraÅ¾ivaÄima**.
* ViÅ¡e **velikih sustava** razvijeno je s razliÄitim pristupima i ciljevima.

---

**2. Glavni postojeÄ‡i sustavi i projekti**

* **EU Human Brain Project** â†’ razvio **SpiNNaker** i **BrainScaleS** za velike neuronske simulacije.
* **ODIN** â€“ digitalni spiking neuromorfni procesor s podrÅ¡kom za sloÅ¾enije neuronske modele.
* **Tianjic chip** â€“ kombinira **neuromorfne SNN-ove** i **klasiÄne umjetne neuronske mreÅ¾e (ANN)** â†’ omoguÄ‡uje Å¡iru primjenu.
* Industrijski primjeri: **IBM TrueNorth**, **Intel Loihi**
* Akademski projekti: **DYNAPs**, **Neurogrid**, **IFAT**, **BrainScaleS-2**
* **BrainScaleS-2** dokazano ubrzava â€œlearning-to-learnâ€ procese â€” **uÄi mnogo brÅ¾e od bioloÅ¡kih mreÅ¾a**.

---

**3. Tehnologije i materijali za implementaciju**

* Svi ovi sustavi su trenutno **temeljeni na siliciju** (klasiÄna CMOS tehnologija).
* IstraÅ¾uju se **nove vrste materijala**, poput:

  * **Phase-change**, **feroelektriÄni** materijali
  * **TopoloÅ¡ki izolatori**
  * **Biomembrane s dopiranim kanalima**
* **Memristori** su posebno popularni â€“ omoguÄ‡uju **spajanje memorije i obrade** (â€œcollocated processing and memoryâ€), Äime se **smanjuje kaÅ¡njenje i potroÅ¡nja energije**.
* Koriste se i **optoelektroniÄki ureÄ‘aji** za joÅ¡ brÅ¾u i energetski efikasniju obradu.

---

**4. Raznolikost ureÄ‘aja = prilagodljivost**

* Svaki materijal i ureÄ‘aj ima **vlastite karakteristike** (brzina, potroÅ¡nja energije, bioloÅ¡ka sliÄnost).
* Ta raznolikost omoguÄ‡uje da se **neuromorfni hardver prilagodi specifiÄnim aplikacijama**.

---

**5. Povezanost s algoritmima i aplikacijama**

* Trenutno se veÄ‡ina istraÅ¾ivanja fokusira na **hardver**, ali pravi napredak zahtijeva **spajanje s algoritmima i primjenama**.
* Da bi se iskoristile sve prednosti neuromorfnog raÄunanja, potrebno je razviti **neuromorfne algoritme** koji u potpunosti koriste potencijal te arhitekture.

---

**6. Definicija koriÅ¡tena u radu**

* Ovaj rad pod pojmom **â€œneuromorfno raÄunanjeâ€** obuhvaÄ‡a sve vrste implementacija:

  * **digitalne**,
  * **mjeÅ¡ovite analogno-digitalne**,
  * **analogne** sustave,
    ali se **posebno fokusira na one koji koriste spikeove** â€” tj. **spiking neuromorphic computers (SNN)**.

---

Programiranje neuromorfnih raÄunala Äesto ukljuÄuje kreiranje spiking neural networka koji se mogu deployati na neuromorfno raÄunalo

---

### âš¡ **KljuÄne znaÄajke Spiking Neural Networks (SNN-ova):**

**1. BioloÅ¡ka inspiracija s dodatnom dimenzijom vremena**

* SNN-ovi su **najbioloÅ¡kiji oblik umjetnih neuronskih mreÅ¾a**.
* Za razliku od klasiÄnih ANN-ova, **ukljuÄuju pojam vremena** u izraÄune.
* Neuroni i sinapse imaju **vremenske konstante i kaÅ¡njenja (delaye)**.

  * Npr. neuron **â€œcuriâ€ (leak)** naboj kroz vrijeme dok ne dosegne prag i ispali â€œspikeâ€.

---

**2. Modeli neurona u SNN-ovima**

* Mogu biti **jednostavni** (npr. *Integrate-and-Fire*) â€“ akumuliraju naboj do praga.
* Ili **sloÅ¾eni i bioloÅ¡ki vjerniji**, poput *Hodgkinâ€“Huxley modela* koji modelira ionske kanale u stvarnim neuronima.
* Dakle, razina bioloÅ¡ke toÄnosti ovisi o potrebama i sloÅ¾enosti sustava.

---

**3. Dvije glavne skupine algoritama u neuromorfnom raÄunanju:**
1ï¸âƒ£ **Algoritmi za uÄenje/trening SNN-a** â€“ optimiziraju mreÅ¾u da bi se koristila na neuromorfnom Äipu (uÄeni pristup).
2ï¸âƒ£ **RuÄno konstruirani SNN-ovi** â€“ dizajnirani bez strojnog uÄenja, veÄ‡ **ruÄno prilagoÄ‘eni za odreÄ‘eni zadatak** (heuristiÄki pristup).

---

**4. SuÅ¡tinska razlika od tradicionalnih ANN-ova:**

* ANN-ovi â†’ rade s **kontinuiranim vrijednostima** i *bez pojma vremena*.
* SNN-ovi â†’ **obraÄ‘uju impulse (spikeove)** koji se dogaÄ‘aju u **vremenu**.
  â¡ï¸ Time bolje **imitiraju naÄin na koji mozak obraÄ‘uje informacije**.

---


---

## âš¡ **Detaljan saÅ¾etak: Funkcioniranje Spiking Neural Networks (SNN)**

---

### ğŸ§© **1. Neuroni u SNN-u**

* **Akumulacija naboja:**

  * Neuroni **skupljaju elektriÄni naboj** tijekom vremena.
  * Naboj dolazi iz:

    * **okoline** â†’ vanjski ulazni podaci, senzori itd.
    * **unutarnjih komunikacija** â†’ spikeovi iz drugih neurona.

* **Prag (threshold):**

  * Svaki neuron ima **definiranu prag-vrijednost**.
  * Kad se akumulirani naboj **dosegne ili premaÅ¡i prag**, neuron **ispali spike** (signal).
  * Spike se Å¡alje **svim izlaznim sinapsama** tog neurona.

* **Leak (curenje naboja):**

  * Ako neuron ne dosegne prag, dio naboja **postupno nestaje kroz vrijeme**.
  * Ova **vremenska degradacija naboja** modelira ponaÅ¡anje stvarnih bioloÅ¡kih neurona.

* **Axonal delay (aksonska odgoda):**

  * Kad neuron ispali spike, signal moÅ¾e biti **odgoÄ‘en** prije nego Å¡to stigne do sinapsi.
  * Ova odgoda simulira **vremensko kaÅ¡njenje u prijenosu impulsa** kroz akson.

---

### ğŸ”— **2. Sinapse u SNN-u**

* **Povezuju neurone:**

  * Svaka sinapsa ima **pre-sinaptiÄki** (izvorni) i **post-sinaptiÄki** (ciljni) neuron.

* **TeÅ¾ina (weight):**

  * Sinapse imaju **numeriÄku teÅ¾inu** koja odreÄ‘uje snagu veze.
  * TeÅ¾ine mogu biti:

    * **pozitivne** â†’ *poticajne (excitatory)*, pojaÄavaju aktivnost
    * **negativne** â†’ *inhibitorne*, smanjuju aktivnost

* **SinaptiÄka odgoda (delay):**

  * Signal iz pre-sinaptiÄkog neurona moÅ¾e imati **kaÅ¡njenje prije nego stigne do post-sinaptiÄkog**.
  * To doprinosi **asinkronom vremenskom ponaÅ¡anju** mreÅ¾e.

* **UÄenje kroz promjenu teÅ¾ina:**

  * Sinapse **mijenjaju svoje teÅ¾ine** ovisno o aktivnosti mreÅ¾e.
  * To omoguÄ‡uje **uÄenje tijekom vremena** (npr. kroz mehanizme poput STDP â€“ Spike-Timing Dependent Plasticity).

* **Rekonfigurabilnost:**

  * Neuromorfni Äipovi omoguÄ‡uju **paljenje/gaÅ¡enje sinapsi** unutar fiziÄke mreÅ¾e, Äime se dinamiÄki definira struktura mreÅ¾e.

* **Programabilni parametri:**

  * U modernim neuromorfnim arhitekturama moguÄ‡e je podeÅ¡avati:

    * **threshold neurona**
    * **teÅ¾ine sinapsi**
    * **aksonske i sinaptiÄke odgode**
  * Time se omoguÄ‡uje **potpuna fleksibilnost** mreÅ¾nih parametara.

---

### ğŸ§  **3. Asinkroni prijenos informacija**

* **Razlika u odnosu na klasiÄne ANN-ove:**

  * U klasiÄnim ANN-ovima â†’ informacije se **sinkrono prenose sloj po sloj**.
  * U SNN-ovima â†’ zbog vremenskih odgoda i razlika u kaÅ¡njenju, **informacije se Å¡ire asinkrono** â€“ svaki spike moÅ¾e stiÄ‡i u drugo vrijeme.

* **Posljedica:**

  * Svaki neuron moÅ¾e reagirati **u razliÄitim trenucima**, ovisno o tome **kad mu spikeovi stignu**.
  * MreÅ¾a tako radi u **realnom vremenu** i ima **vremensku dinamiku** sliÄnu mozgu.

* **Prednost za neuromorfni hardver:**

  * Ova asinkronost **savrÅ¡eno odgovara** neuromorfnim Äipovima koji rade u **event-driven reÅ¾imu** â€“ obraÄ‘uju samo kada spike stigne.
  * Time se **Å¡tedi energija** i omoguÄ‡uje **visoka paralelizacija**.

---

### â±ï¸ **4. Vremenska domena rada mreÅ¾e**

* Aktivnost mreÅ¾e se moÅ¾e promatrati **po vremenskim koracima (t, t+1, t+2, â€¦)**.
* U svakom vremenskom trenutku mijenja se:

  * koji neuroni su â€œispaliliâ€ spike,
  * koliko naboja su drugi neuroni akumulirali,
  * koje sinapse su aktivne i kada njihovi signali dolaze.
* Dakle, mreÅ¾a ima **dinamiÄno stanje koje se evolucijski mijenja kroz vrijeme**.

---

### ğŸ“Š **5. Ukratko â€“ kljuÄni koncepti**

| Element            | Funkcija                     | KljuÄne karakteristike                                  |
| ------------------ | ---------------------------- | ------------------------------------------------------- |
| **Neuron**         | Akumulira i ispuÅ¡ta naboj    | Prag, curenje, aksonska odgoda                          |
| **Sinapsa**        | Povezuje neurone             | TeÅ¾ina (pozitivna/negativna), sinaptiÄka odgoda, uÄenje |
| **Signal (spike)** | Diskretni impuls             | Prenosi informaciju u vremenu                           |
| **Obrada**         | Asinkrona, dogaÄ‘ajima voÄ‘ena | Energetski uÄinkovita, vremenski osjetljiva             |

---
DNN = umjetna neuronska mreÅ¾a s viÅ¡e slojeva koja uÄi iz velike koliÄine podataka pomoÄ‡u backpropagationa i gradijentnog spuÅ¡tanja.
---

## ğŸ”¹ 1. Problem s klasiÄnim treniranjem SNN-ova

* **Backpropagation i SGD (stochastic gradient descent)** su jako uspjeÅ¡ni u deep learningu,
  ali **ne mogu se direktno primijeniti na SNN-ove** jer:

  * Spiking neuroni imaju **nediferencijabilne aktivacijske funkcije** (threshold funkcije).
  * SNN-ovi obraÄ‘uju **vremenske informacije**, Å¡to dodatno komplicira uÄenje.
* Potrebne su **prilagodbe** (npr. surrogate gradients, smoothed activation functions),
  ali to Äesto **smanjuje toÄnost** u odnosu na klasiÄne ANN-ove.

---

## ğŸ”¹ 2. Mapiranje klasiÄnih DNN-ova na SNN-ove

* Umjesto treniranja SNN-a od nule, Äesto se:

  1. **Trenira DNN**,
  2. **Zatim se mapira (pretvori)** u SNN za **inference**.
* Ove metode daju:

  * Blizu **state-of-the-art toÄnost**
  * Uz **veliko smanjenje potroÅ¡nje energije** (jer SNN obraÄ‘uje samo spikeove).
* Dataseti koriÅ¡teni: **MNIST, CIFAR-10, ImageNet**.
* KljuÄne tehnike:

  * Normalizacija teÅ¾ina i aktivacija
  * Zamjena max-poolinga s average poolingom
  * "Few Spikes" neuron model (FS-neuron) â€” sloÅ¾ene aktivacije predstavljene s 1â€“2 spikea.
* Primjene: **keyword spotting, medicinska analiza, detekcija objekata** (na Loihi, TrueNorth).
* Problem: **mapiranje moÅ¾e smanjiti toÄnost** zbog:

  * razlike DNN â†” SNN
  * hardverskih ograniÄenja (npr. **memristori** imaju niÅ¾u preciznost teÅ¾ina i varijacije po ciklusu).

---

## ğŸ”¹ 3. Reservoir computing (Liquid State Machines)

* Ne zahtijeva klasiÄno treniranje SNN-a.
* Sastoji se od:

  * **"tekuÄ‡eg" (liquid) dijela** â€“ nasumiÄna mreÅ¾a spike neurona (recurrent, sparse)
  * **readout sloja** â€“ trenira se (npr. linearnom regresijom)
* Dvije kljuÄne osobine:

  * **Input separability** â€“ razliÄiti ulazi daju razliÄite izlaze
  * **Fading memory** â€“ stari signali nestaju s vremenom
* Prednosti:

  * Nema treniranja samog SNN-a
  * Dobro radi s vremenskim podacima
* Primjene:

  * obrada **bio-signala**, **prosthetic control**, **audio/video analiza**
  * koristi **hijerarhijske slojeve** tekuÄ‡ih mreÅ¾a

---

## ğŸ”¹ 4. Evolucijski pristupi

* Koriste **evolucijske algoritme** (mutacija, selekcija, reprodukcija) za:

  * Optimizaciju **parametara** (thresholds, delays)
  * Dizajn **strukture mreÅ¾e** (koliko neurona, kako su povezani)
* Prednosti:

  * Ne zahtijevaju diferencijabilnost
  * Mogu raditi s bilo kojom topologijom mreÅ¾e
* Nedostatak:

  * **Sporo konvergiraju**
* Primjene:

  * **Kontrola robota**, **video igre**, **autonomna navigacija**

---

## ğŸ”¹ 5. PlastiÄnost (bioloÅ¡ki inspirirano uÄenje)

* Temelji se na **aktivnosti neurona i promjenama sinaptiÄke jaÄine**.
* Najpoznatije: **STDP (Spike-Timing-Dependent Plasticity)**

  * TeÅ¾ine se mijenjaju prema vremenskom odnosu pre- i post-sinaptiÄkih spikeova.
* KoriÅ¡teno na: **MNIST, CIFAR-10, ImageNet**
* Prednosti:

  * MoÅ¾e **pribliÅ¾iti klasiÄne ML metode** (klasteriranje, Bayes inference)
  * Kombinira se s **reservoir computingom** (npr. NeuCube)
* Primjene:

  * **EEG analiza**, **detekcija stanja spavanja**, **prostetiÄke kontrole**
* Varijante:

  * **Rekurentne SNN mreÅ¾e s kaÅ¡njenjima i plastiÄnoÅ¡Ä‡u**
  * **Polychronization networks** â€“ klasifikacija vremensko-prostorno varijabilnih uzoraka
  * **Winner-take-all** modeli
  * UÄenje **tajminga spikeova** (precizna klasifikacija prema vremenu)

---

## ğŸ”¹ 6. Nemachine learning algoritmi

* Neuromorfni hardver moÅ¾e rjeÅ¡avati **ne-ML probleme**:

  * **Graf algoritmi** (npr. shortest path)
  * **Random walks** i **Markov chains**
  * **NP-kompletni problemi** (SAT, QUBO, graph partitioning)
* Primjeri:

  * **IBM TrueNorth**, **Intel Loihi**, **SpiNNaker** rjeÅ¡avaju NP probleme
  * Neuromorfni pristupi ponekad **precizniji od D-Wave kvantnog raÄunala!**
* Prednosti:

  * Paralelna, niskoenergetska obrada
  * OdliÄna primjena u **grafovima, relacijskim strukturama**, **Bayesovim mreÅ¾ama**

---

## ğŸ”¹ 7. Trenutno stanje i izazovi

* **SNN-ovi i neuromorfni hardver joÅ¡ nisu u stvarnim aplikacijama.**
* Fokus je zasad na **benchmark datasetima i demonstracijama**.
* Glavni izazov:

  * JoÅ¡ **nema kombinacije algoritma i aplikacije** gdje SNN nadmaÅ¡uje deep learning u toÄnosti.
  * Prednost je zasad **u energetskoj uÄinkovitosti**, ne u performansama.
* Potrebno:

  * Å iriti fokus **izvan backpropagationa**
  * Razvijati **novije, bioloÅ¡ki inspirirane algoritme**
  * Iskoristiti **vremensku i dogaÄ‘ajnu prirodu** SNN-ova

---

## ğŸ”¹ 8. ZakljuÄna poruka

> Neuromorfni sustavi ne bi trebali pokuÅ¡avati samo *imitirati* deep learning,
> nego razviti **nove algoritme** koji koriste **njihovu bioloÅ¡ku i vremensku prirodu** â€”
> evoluciju, plastiÄnost, dogaÄ‘ajnu obradu i inherentnu paralelizaciju.

---


SavrÅ¡eno â€” ovo je vaÅ¾an dio teksta koji govori o **ograniÄenjima pristupa i skalabilnosti u neuromorfnom raÄunanju**.
Evo ti **jasne i detaljne natuknice** na hrvatskom:

---

### âš™ï¸ **Å iri pristup neuromorfnom hardveru i simulatorima â€“ kljuÄni izazovi i rjeÅ¡enja**

#### ğŸ”’ Trenutni problemi:

* **OgraniÄen pristup hardveru:**

  * Postoji **malo dostupnih neuromorfnih sustava** (poput Loihi, TrueNorth, SpiNNaker).
  * **Dostupni su samo putem ograniÄenog cloud pristupa**, Å¡to usporava istraÅ¾ivanje i razvoj.

* **Softver i simulacije nisu dovoljno pristupaÄni:**

  * Postoji nekoliko **open-source simulatora** (npr. **NEST**, **Brian**, **Nengo**), ali svaki je:

    * specijaliziran za **odreÄ‘enu zajednicu** ili **vrstu zadataka**,
    * teÅ¡ko primjenjiv izvan tih specifiÄnih podruÄja.
  * **NEST** je fokusiran na **raÄunalnu neuroznanost**,
    **Nengo** na **Neural Engineering Framework (NEF)**,
    Å¡to ograniÄava njihovu **Å¡iru upotrebljivost** u raÄunarstvu i industriji.

* **Slaba skalabilnost i performanse simulatora:**

  * Mnogi simulatori **nisu dovoljno brzi** pri radu u velikim razmjerima.
  * Zbog **eksplozije koliÄine podataka**, potrebno je procesirati informacije **brÅ¾e nego Å¡to se generiraju**,
    Å¡to trenutni simulatori **ne mogu pratiti**.
  * Posljedica: **sporo treniranje SNN-ova** i **teÅ¡ko testiranje novih algoritama**.

---

#### ğŸš€ Preporuke i buduÄ‡i smjer:

* **Razviti pristupaÄnije i univerzalnije alate** koji bi omoguÄ‡ili:

  * **Å¡iru upotrebu u raÄunalnoj znanosti i industriji**,
  * **brÅ¾e eksperimentiranje i inovaciju** u algoritmima.
* **PoboljÅ¡ati performanse simulatora** kako bi mogli:

  * **raditi u realnom vremenu**,
  * **skalirati** na **velike podatkovne setove i HPC (high-performance computing)** sustave.
* **OmoguÄ‡iti brÅ¾u evaluaciju algoritama** Äak i kada fiziÄki hardver nije dostupan â€”
  time bi se ubrzao **razvoj i testiranje novih neuromorfnih rjeÅ¡enja**.

---

### ğŸ’¡ Ukratko:

> Napredak neuromorfnog raÄunarstva trenutno koÄi **ograniÄen pristup hardveru** i **slaba skalabilnost simulatora**.
> RjeÅ¡enje je razvoj **brzih, skalabilnih i univerzalnih softverskih alata** koji omoguÄ‡uju brzu inovaciju i Å¡iru dostupnost zajednici.

---

---

### ğŸ”¹ Glavna ideja:

U buduÄ‡nosti, **neuromorfna raÄunala** neÄ‡e raditi sama za sebe, nego Ä‡e biti **dio veÄ‡eg ekosustava** â€” zajedno s **klasiÄnim raÄunalima**, **GPU-ovima**, pa Äak i **kvantnim raÄunalima**.
Svako od njih ima svoju **specijalnost**:

* CPU â€“ dobar za opÄ‡e zadatke
* GPU â€“ moÄ‡an za paralelne izraÄune
* Neuromorfni Äip â€“ izuzetno energetski uÄinkovit za obradu u stilu mozga (event-based, SNN, itd.)
* Kvantni Äip â€“ jak za specifiÄne optimizacijske i probabilistiÄke probleme

Dakle, ideja je: **kombinirati sve njih pametno**, tako da svaka komponenta radi ono Å¡to najbolje zna.

---

### ğŸ”¹ Problem:

Ali â€” postoji **ogroman izazov** u tome da sve te razliÄite arhitekture **rade zajedno**.

Trenutno:

* Neuromorfna raÄunala **ovise o klasiÄnim raÄunalima** (tzv. *host machines*) za:

  * programiranje samog neuromorfnog Äipa (definiranje mreÅ¾e i pravila)
  * komunikaciju sa senzorima i ureÄ‘ajima u stvarnom svijetu
  * primanje i slanje podataka

Ta ovisnost ima **visoku cijenu** â€” i **u vremenu** i **u energiji**.
Dakle, Äak i ako neuromorfni Äip radi ultraefikasno, ako mora stalno Äekati ili komunicirati s klasiÄnim raÄunalom, **gubi se njegova prednost**.
Na kraju, kad se uraÄunaju svi â€œoverheadiâ€ (komunikacija, prijenos podataka, CPU obrada), koristi od neuromorfnog pristupa mogu **potpuno nestati**.

---

### ğŸ”¹ RjeÅ¡enje koje autori predlaÅ¾u:

Treba razviti **nove modele programiranja i arhitekture** koje Ä‡e:

* **smanjiti ovisnost** neuromorfnih raÄunala o klasiÄnim hostovima,
* **optimizirati komunikaciju** izmeÄ‘u njih (da ne troÅ¡i viÅ¡e nego Å¡to vrijedi),
* i omoguÄ‡iti **jedinstveno programiranje** heterogenog sustava â€” tako da programer ne mora ruÄno "spajati" CPU + GPU + neuromorfni Äip.

---

### ğŸ”¹ Ukratko:

â¡ï¸ BuduÄ‡a raÄunala neÄ‡e biti samo "brÅ¾a", nego **pametno organizirana** kombinacija razliÄitih tehnologija.
â¡ï¸ Glavni izazov: **kako natjerati neuromorfna, kvantna i klasiÄna raÄunala da uÄinkovito suraÄ‘uju** bez da troÅ¡e previÅ¡e energije i vremena na meÄ‘usobnu komunikaciju.

ğŸ”¹ Glavna ideja:

Ovaj dio govori o nedostatku standardiziranih benchmarka i metrika u podruÄju neuromorfnog raÄunarstva.
To je OGROMAN problem â€” jer bez njih ne moÅ¾eÅ¡ objektivno usporediti:

koji hardver radi bolje,

koji algoritam je uÄinkovitiji,

ili koja metoda ima stvarne prednosti u praksi.

ğŸ”¹ ZaÅ¡to su benchmarki vaÅ¾ni?

Usporedi to s deep learningom:

Kad se pojavio ImageNet dataset, svi su znali:
â€œAko tvoj model pobijedi na ImageNetu â€” imaÅ¡ dobru arhitekturu.â€

Taj izazov je pokrenuo eksploziju napretka â€” AlexNet, ResNet, EfficientNet...
Benchmark je bio zajedniÄki cilj cijele zajednice.

â¡ï¸ Neuromorfno raÄunarstvo nema takav â€œImageNet momentâ€.
Ne postoji jedan zajedniÄki izazov ili set jasnih metrika koji bi usmjerio istraÅ¾ivanja i omoguÄ‡io fer usporedbe.

ğŸ”¹ Trenutna situacija:

Postoji nekoliko pokuÅ¡aja benchmark setova i datasetova specifiÄnih za spike-based i event-based pristupe:

Neuromorphic MNIST (N-MNIST) â€” spike verzija klasiÄnog MNIST-a

DVS Gesture Dataset â€” gesta prepoznata pomoÄ‡u Dynamic Vision Sensor (event kamera)

Spiking Heidelberg Audio Dataset (SHD) â€” zvuÄni dogaÄ‘aji za spike mreÅ¾e

Ali...
â¡ï¸ nisu Å¡iroko prihvaÄ‡eni u zajednici,
â¡ï¸ nemaju status â€œstandardnog testaâ€,
â¡ï¸ i Äesto ne iskoriÅ¡tavaju pravu prednost neuromorfnih sustava â€” temporalnu obradu dogaÄ‘aja u stvarnom vremenu.

Zato se Äesto koriste stari ML datasetovi poput MNIST, CIFAR-10 i ImageNet, ali oni:

nemaju vremensku dimenziju,

nisu event-based,

pa zapravo ne pokazuju pun potencijal neuromorfnih sustava.

ğŸ”¹ Problem jedinstvenog benchmarka:

Autori upozoravaju â€” nije ni idealno imati samo jedan zadatak (kao Å¡to je bio ImageNet u ML-u).
ZaÅ¡to?
Jer to moÅ¾e dovesti do â€œuske optimizacijeâ€ â€” svi algoritmi se prilagoÄ‘avaju samo da bi bili bolji na tom jednom zadatku, a gubi se Å¡ira primjena.

ğŸ”¹ RjeÅ¡enje:

ğŸ‘‰ Umjesto jednog â€œsvetog gralaâ€ benchmarka,
treba napraviti suite (set) razliÄitih izazova i metrika koji Ä‡e:

pokrivati razne tipove zadataka (vizualne, auditivne, motorne, bioloÅ¡ke simulacije itd.),

ukljuÄivati razliÄite tipove algoritama (ML i non-ML pristupe),

i omoguÄ‡iti fer usporedbe izmeÄ‘u razliÄitih arhitektura (CPU, GPU, neuromorfni, kvantni...).

ğŸ”¹ Ukratko:

ğŸ§  Problem: Nema zajedniÄkih benchmarka â†’ teÅ¡ko usporediti performanse i napredak.

âš™ï¸ Posljedica: Razvoj ide sporije jer svatko radi na svom datasetu, s vlastitim metrikama.

ğŸš€ RjeÅ¡enje: Napraviti skup razliÄitih izazova koji potiÄu inovaciju u viÅ¡e smjerova â€” ne samo jedan â€œImageNet za neuromorfneâ€.

Brutalan i vaÅ¾an odlomak â€” ovo ulazi pravo u **â€œsoftverskeâ€ izazove neuromorfnog raÄunarstva**! ğŸ’¥
Evo ti **detaljno, ali jasno strukturirane natuknice** koje hvataju sve bitno:

---

## ğŸ§  KljuÄna tema: â€œDefining programming abstractionsâ€

â¡ï¸ Problem: **Nema jednostavnog, apstraktnog naÄina za programiranje neuromorfnih sustava.**
Trenutno programeri moraju **ruÄno definirati svaki neuron, sinapsu, parametre i veze**.
To je:

* sporo,
* komplicirano,
* sklono pogreÅ¡kama,
* i potpuno drugaÄiji naÄin razmiÅ¡ljanja od klasiÄnog programiranja.

---

### ğŸ”¹ 1. Trenutni naÄin rada

* Programer mora **ruÄno dizajnirati SNN (Spiking Neural Network)** za zadatak.
* Definira se:

  * svaki neuron,
  * svaka sinapsa,
  * njihove veze,
  * parametri (threshold, delay, weightâ€¦).
* To traÅ¾i **mikro-razinu kontrole** â†’ usporedivo s pisanjem â€œassembly koda za mozakâ€.

â¡ï¸ **Posljedica:** ogroman trud, mala fleksibilnost, visoka moguÄ‡nost greÅ¡ke.
â¡ï¸ Zato razvoj *non-ML* algoritama na neuromorfnim sustavima ide jako sporo.

---

### ğŸ”¹ 2. ZaÅ¡to se najviÅ¡e koriste graf algoritmi

* Neuromorfne mreÅ¾e imaju prirodnu analogiju s grafovima:

  * **ÄŒvorovi (nodes)** â†’ neuroni
  * **Bridovi (edges)** â†’ sinapse
* Zato je **jednostavno mapirati graf strukturu** u SNN.
  â¡ï¸ Zato su mnogi *non-machine learning* algoritmi fokusirani upravo na graf probleme (npr. pretraÅ¾ivanje grafa, optimizacija).

---

### ğŸ”¹ 3. PostojeÄ‡i pokuÅ¡aji apstrakcije (viÅ¡a razina)

Postoje neki modeli koji pokuÅ¡avaju â€œolakÅ¡atiâ€ programiranje:

* **Neural Engineering Framework (NEF)** â†’
  omoguÄ‡uje definiranje apstraktnih izraÄuna pomoÄ‡u neurona (Äesto koriÅ¡ten za bioloÅ¡ki realistiÄne modele).
* **Dynamic Neural Fields (DNF)** â†’
  fokusiran na *embodied cognition* (npr. simulacije kognitivnih procesa u robotici).

â¡ï¸ Ali problem:
Ovi pristupi su **ograniÄeni na specifiÄne sluÄajeve**.
Ne postoji **opÄ‡a apstrakcija** koja bi omoguÄ‡ila programiranje neuromorfnih raÄunala za *razne* zadatke (ne samo neuronske modele ili robotiku).

---

### ğŸ”¹ 4. MoguÄ‡e rjeÅ¡enje: Subnetworks kao â€œprogramske primitiveâ€

ZamiÅ¡lja se ideja da bi se mogli definirati **mali, standardizirani â€œspike subnetworksâ€** koji obavljaju osnovne zadatke poznate programerima:

* logiÄke operacije (**AND, OR, XOR**),
* uvjeti (**if / else**),
* petlje (**loops**),
* binarne operacije itd.

â¡ï¸ Takvi â€œneuronski blokoviâ€ mogli bi se **sastavljati u veÄ‡e sustave**, baÅ¡ kao Å¡to se funkcije i moduli spajaju u normalnim programima.

* Postoji istraÅ¾ivanje (Plank et al.) koje pokazuje kako spike mreÅ¾e mogu realizirati **AND, OR, XOR** logiku.
* Ali to je tek poÄetak â€” ogroman prostor za razvoj **â€œneuromorfnih programskih konstrukataâ€**.

---

### ğŸ”¹ 5. Problem: nedostatak svijesti u Å¡iroj zajednici

Dok ne postoje jasne apstrakcije i dok se Å¡ira programska zajednica **ne upozna s konceptima spike-raÄunarstva**, razvoj *non-ML* neuromorfnih algoritama bit Ä‡e spor.

â¡ï¸ Dakle, **nije samo hardverski problem**, veÄ‡ i **problem edukacije i alata**.

---

### ğŸ”¹ 6. Bitno upozorenje: Neuromorfno â‰  za sve

Autori naglaÅ¡avaju:

* Da, moguÄ‡e je implementirati razne algoritme na neuromorfnim raÄunalima,
  **ali ne znaÄi da sve treba**.
* Neuromorfni sustavi su **specijalizirani procesori**, ne â€œopÄ‡e namjeneâ€ (kao CPU).
* Treba ih koristiti tamo gdje imaju **prirodnu prednost** â€” u:

  * real-time obradi dogaÄ‘aja,
  * energetski uÄinkovitim simulacijama,
  * bioloÅ¡kim modelima,
  * adaptivnim i vremenski ovisnim sustavima.

---

### ğŸ”¹ 7. ZakljuÄak:

* ğŸ§© **Problem:** nema jednostavnog naÄina za programiranje neuromorfnih sustava.
* âš™ï¸ **Trenutno:** sve se definira ruÄno, na neuronskoj razini.
* ğŸ’¡ **Postoje pokuÅ¡aji:** NEF i DNF â€” ali ograniÄeni.
* ğŸš€ **BuduÄ‡nost:** stvaranje â€œneuromorfnih programskih apstrakcijaâ€ (npr. neuronskih modula za osnovne operacije).
* âš ï¸ **Napomena:** neuromorfni Äipovi su specijalizirani â€” nisu za svaki problem.

---

## ğŸ§© **OUTLOOK â€” BuduÄ‡nost neuromorfnog raÄunarstva**

### ğŸ”¹ 1. Ogroman potencijal izvan Mooreovog zakona

* Neuromorfni procesori su:

  * **energetski izuzetno uÄinkoviti**,
  * **sposobni za strojno uÄenje i neke nestrojne (non-ML) izraÄune**,
  * **velika nada za post-Moore eru** â€“ omoguÄ‡uju napredak performansi bez tradicionalnog skaliranja tranzistora.
* Nude **nove paradigme obrade podataka** inspirirane biologijom (asinkrono, dogaÄ‘ajno, paralelno).

---

### ğŸ”¹ 2. Tri glavna buduÄ‡a **use-casea** za neuromorfne procesore

#### ğŸŸ¢ (1) **Edge computing** â€” ureÄ‘aji na rubu mreÅ¾e

* Idealni zbog **niskog energetskog troÅ¡ka**.
* Primjene:

  * autonomna vozila i dronovi,
  * robotika,
  * udaljeni senzori,
  * nosivi ureÄ‘aji,
  * Internet of Things (IoT).
* Fokus: **ekstremno niska potroÅ¡nja i real-time obrada**.

#### ğŸŸ  (2) **AI akceleratori i koprocesori** u osobnim ureÄ‘ajima

* Mogu postati **ko-akceleratori** u:

  * pametnim telefonima,
  * laptopima,
  * stolnim raÄunalima.
* SliÄni danaÅ¡njim GPU/NPU akceleratorima, ali s **reda veliÄine manjom potroÅ¡njom energije**.
* Mogu znaÄajno **produÅ¾iti trajanje baterije** i ubrzati AI zadatke.

#### ğŸ”µ (3) **Koprocesori u heterogenim HPC sustavima**

* U buduÄ‡im **heterogenim superraÄunalima**, neuromorfni Äipovi Ä‡e:

  * izvrÅ¡avati **spike-based simulacije**,
  * pokretati **graf algoritme**,
  * **rjeÅ¡avati diferencijalne jednadÅ¾be**,
  * **aproksimirati NP-kompletne probleme** uÄinkovito.
* Fokus: **reconfigurability** i **trening ubrzanje** za kompleksne znanstvene izraÄune.

â¡ï¸ **Napomena:** implementacije Ä‡e se razlikovati:

* Edge ureÄ‘aji â€“ visoka specijalizacija, minimalna potroÅ¡nja.
* HPC okruÅ¾enja â€“ veÄ‡a fleksibilnost i moguÄ‡nost treniranja.

---

### ğŸ”¹ 3. Trenutno stanje i smjer razvoja

* VeÄ‡ postoji **nekoliko velikih neuromorfnih sustava** dostupnih istraÅ¾ivaÄima (npr. Loihi, SpiNNaker).
* Aktivno se razvijaju i **nove vrste materijala i ureÄ‘aja** za fiziÄku implementaciju (npr. memristori, analogni elementi).
* Ovo stvara **ogromnu priliku za â€œhardwareâ€“software co-designâ€** â€” zajedniÄki razvoj od materijala do aplikacija.

---

### ğŸ”¹ 4. **Hardwareâ€“software codesign pristup**

Trenutno:

* Razvoj ide **odozdo prema gore** â†’ prvo materijali i ureÄ‘aji, pa tek onda algoritmi.

Bolji pristup:

* **â€œCijeli stack codesignâ€** â€“ paralelno oblikovati sve slojeve:

  * materijali i ureÄ‘aji,
  * arhitektura,
  * algoritmi,
  * aplikacije.

â¡ï¸ Time bi algoritmi mogli **utjecati na dizajn samog hardvera** i obrnuto.

---

### ğŸ”¹ 5. **Primjeri suvremenog codesign pristupa**

* **Bayesian optimization** i **Neural Architecture Search (NAS)** koriste se za optimizaciju cijelog sustava.
* Primjer:

  * kod **memristive crossbar** akceleratora,
  * automatski se odreÄ‘uje broj i veliÄina crossbara kako bi se **maksimizirala toÄnost i energetska uÄinkovitost**.

---

###  6. **Biologija â†”ï¸ Materijali: novi smjer razvoja**

* Trenutno se u sinaptiÄkoj plastiÄnosti ide â€œodozgo prema doljeâ€:

  * inspiracija iz biologije â†’ implementacija u ureÄ‘ajima â†’ prilagodba algoritma.
* Novi smjer:

  * **uÄiti iz fiziÄkih svojstava novih materijala** kako bi se razvili *novi algoritmi plastiÄnosti* (bottom-up).
* Ideja: moÅ¾da postoje **fiziÄke pojave u materijalima** koje mogu nadahnuti *potpuno nove modele uÄenja*.

---

###  7. **Paradigm shift â€“ promjena naÄina razmiÅ¡ljanja**

* UspjeÅ¡no koriÅ¡tenje neuromorfnih raÄunala zahtijevat Ä‡e **promjenu paradigme programiranja**.
* IstraÅ¾ivaÄi moraju **razmiÅ¡ljati u terminima dogaÄ‘aja, vremena i paralelizma**, a ne samo sekvencijalnog koda.

---

###  8. **Potencijalni najveÄ‡i dobitnici**

* Osim klasiÄnog ML-a, dvije skupine algoritama koje bi mogle **najviÅ¡e profitirati**:

  * **Graf algoritmi** (dijagrami, mreÅ¾e, optimizacija veza)
  * **Optimizacijski zadaci** (posebno NP-teÅ¡ki problemi)
* Oboje imaju koristi od:

  * **masivne paralelizacije**,
  * **asinkronosti**,
  * **stohastiÄne prirode neuromorfnih sustava**.

---

###  9. **ZakljuÄna vizija**

* Neuromorfno raÄunarstvo je joÅ¡ u ranoj fazi, ali:

  * ima **ogroman potencijal** za redefiniranje raÄunarstva,
  * omoguÄ‡uje **energetski uÄinkovite i paralelne izraÄune**,
  * **nadopunjuje** postojeÄ‡e paradigme (ne zamjenjuje ih).
* Vrijeme je da **Å¡ira raÄunalna znanstvena zajednica** poÄne ukljuÄivati neuromorfne raÄunare kao **dio buduÄ‡e raÄunalne infrastrukture**.

---

Event-based vision: A Survey, Guillermo Gallego & co.
- Event kamere - bio-inspired senzori koji, za razliku od standarnih frame-based kamera, asinkrono mjere per-pixel promjene svjetline i kao output izbacuju stream evenata (svaki se sastoji od: vremena, lokacija i oznake promjene svjetline)
- Features: high temporal resolution, high dynamic range, low power consumption, high pixel bandwith, reduced motion blur, low latency, high speed
- Koriste se za sve levele CV-a (od feature detectiona i trackinga, optical flowa do rekonstrukcije, segmentacije i recognitiona)
- Postoje posebne tehnologije za to (npr. SCNNs)


- ZapoÄelo 1986. - Carver Mead => spoj inÅ¾enjerske i bioliÅ¡ke perspektive
- 1991. - Silicijska zjenica => oponaÅ¡anje prirodne arhitekture oka
- Cilj: shvatiti kako mozak radi i sloÅ¾iti ga na raÄunalnom Äipu
- Bio-inspired tehnologija silikonskih zjenica/event kamera
- Vid je najdominantniji ljudski osjet => najjaÄi signali
- Event based senzori rijeÅ¡avaju neke probleme frame-based visiona (high speed motion estimation; high dynamic range)
- Asinkroni senzori => sampling scene na temelju dinamike u istoj, a ne na temelju internog clocka koji nema veze s dogaÄ‘ajima na sceni (kao kod frame based di se koristi sampling u k fps)
- Visok temporal resolution; niska latencija; visok dynamic range, niska potroÅ¡nja energije
- Robotika, wearable ureÄ‘aji + situacije di standarnde kamere ne delaju dobro (high speed&dynamic range)...nekontrolirano osvjetljenje, latencija + podruÄja di je vaÅ¾no oÄuvanje elektriÄne energije
- AR/VR, video igre

- Rade znatno drukÄije nego standarne kamere (asinkrono mjere promjene u intenzitetu svjetlosti by-pixel) pa su potrebne nove metode za procesiranje outputa

- Object tracking, surveillance and monitoring, object/gesture recognition, depth estimation, structured light 3d scanning, optical flow estimation, image reonstruction, localization&mapping, image deblurring, star tracking

Glavna razlika u odnosu na standardne frame based kamere:
- standardne kamere koriste full images at a rate specified by external clock (npr. 30fps)
- event kamere reagiraju na promjene svjetlosti u sceni asinkrono i neovisno za svaki piksel
- output event kamere je varijabilna data-rate sekvenca digitalnih evenata (spikeova)

- Svaki spike predstavlja promjenu osjvetljenja u odreÄ‘enom pikselu u odreÄ‘enom vremenskom trenutku => spiking nature bioloÅ¡kog vida
- Svaki piksel pamti log intenziteta za svaki eent i kontinuirano prati promjenu intenziteta u odnosu na upamÄ‡enu vrijednost
- Kada promjena preÄ‘e threshold, kamera Å¡alje event koji se Å¡alje (x,y koordinate lokacije, t timestamp, 1-bitni polaritet promjene (ON ako se svjetlost poveÄ‡ala, OFF ako se smanjila)
- Eventi se Å¡alju od pixel arraya prema periferiji i onda van iz kamere koristeÄ‡i shared digital output bus (Address-event representation; AER)
- Rate od 2 MHz do 1200 Mhz ovisno o Äipu i hardveru

- Event kamere su data-driven senzori (output im ovisi o koliÄini kretanja ili promjeni svjetlosti u sceni)
- ÄŒa je kretanje brÅ¾e/ÄeÅ¡Ä‡e/intenzivnije, viÅ¡e evenata po sekundi se generira
- Svaki piksel ima vlastiti sampling rate i prati intenzitet evenata koji signalizira
- Eventi imaju timestampove na razini mikrosekunde => Å¡alju se s latencijom manjom od milisekunde
- Senzori brzo reagiraju na stimulans 

- Incident light => produkt osvjetljenja scene i odsjaja povrÅ¡ine koja se "snima"
- Ako je osvjetljenje otprilike konstantno, incident light je minimalan i nastaje samo kada se ovjekt gledanja pomiÄe
- DVS pikesli imaju konaÄan bandwith; ako su nadolazeÄ‡e promjene u intenzitetu preÄeste, photoreceptor "filtrira" varijacije u njima i ne registrira ih => ukratko; dvs pikseli imaju fiziÄki limit maksimalne brzine kojom reagiraju na promjene
- Ako su eventi prebrzi; senzor praktiÄki lovi manje evenata nego ako su u "normalnoj brzini"

- NajÄeÅ¡Ä‡i event camera dizajni:
- first silicon retina: Mahowald&Mead (1986-1992)
- logaritamski pikesli => output spike eventi nastaju koristeÄ‡i AER protokol
- Problem: treba precizno uÅ¡zimavati svaku pojedinu Å¾icu (bias parametri); mismatch u responsevima za razliÄite piksele; pikseli su preveliki

- DVS event camera => utemeljena na frame-based silicon mreÅ¾nici (continous-time fotoreceptor + redout circle koji se resetira svaki put kad se pixel samplira)
- UviÄ‘eno je da je potreban i neki oblik statiÄkog outputa ("absoulute brightness")
- Ideja: kamera koje concurrently daju i statiÄki i dinamiÄki output)

- ATIS => asinkroni time based image sensor => pikesli sa DVS subpikselima
- OkidaÄ resetira kondenzator na visoki napon; sturja se odvodi iz kondenzatora pomoÄ‡u diode; Å¡to je input svjetliji, to se kondenzator brÅ¾e prazni
- Samo pikseli koji se stvarno mijenjaju imaju utjecaj na napon
- ÄŒa je svjetliji event; to su promjene ÄeÅ¡Ä‡e
- Neodostatak: jako veliki pikesli; u mraku je jako sporo i novi eventi mogu prekinuti oÄitavanje starih...nepraktiÄno

- DAVIS => spoj aktivnog pixel senzora (APS) i DVS-a
- puno manji pikseli
- dijeljena fotodioda
- frameovi se obraÄ‘uju u konstantom rateu
- problem: ograniÄeni dynamic range; redundancija ako se pikseli ne promjene

Prednosti event kamera
High temporal resolution:
 - praÄ‡enje promjena osvjetljenja je brzo
 - iÅ¡Äitavanje evenata je digitalno, s 1MHz clockom (eventi su detektirani i timestampirani u roku mikrosekunde)
 - mogu snimati jako brze pokrete, bez da dolazi do blura koji je standardan za frame-based kamere

Low latency:
 - svaki piksel radi zasebno; ne treba se Äekati global exposure za cijeli frame
 - Äim se event detektira, transmitted je (latencija ispod milisekunde u realnom okruÅ¾enju)

Low power:
 - transmitaju se samo promjene u osvjetljenju; nema redundantnih podataka
 - struja se troÅ¡i samo za procesiranje piksela koji se mijenjaju

High dynamic range:
 - i viÅ¡e nego duplo bolje nego kod najkvalitetnijih frame-based kamera
 - mogu captureati informacije u svim uvjetima..od mjeseÄine do sunca
 - fotoreceptori rade logaritamski i svaki piksel radi zasebno, bez da Äeka "zatvaraÄ" kamere
 - poput zjenice, prilagodljivi su i jakom mraku i jakoj svjetlosti

Izazovi:
- dizajn novih korisnih softverskih algoritama i hardverskih metoda
1) space-time output
   Output event kamera je fundamenatalno drukÄiji od outputa standardnih kamera; eventi su asinkroni i prostorno sparse (rijetki), dok su frameovi sinkroni i dense (frame toÄno prati tijek onoga ispred kamere)
2) different photometric sensing
   Standardne kamere daju grayscale info, dok eventi u sebi sadrÅ¾e binarni (increase/decrease) info o promjeni svjetlosti. Promjene svjetlosti ne ovise samo o trenutnom osvjetljenju scene nego i o trenutnim i proÅ¡lim kretnjama u sceni
3) noise and dynamics
   Svi vision senzori su noisy jer postoji neizbjeÅ¾an noise u Äesticama sjvetlosti i u samim el. krugovima u tranzistorima. Problem ze event based kamere: kako kvantizirati temporal contrast

---

### **Kvantizacija temporalnog kontrasta â€“ saÅ¾etak**

**1. Temporalni kontrast (C):**

* Mjeri promjenu svjetline kroz vrijeme:
  [
  C(t) = \frac{I(t) - I(t - Î”t)}{I(t - Î”t)}
  ]
* DVS piksel reagira samo kad ta promjena prijeÄ‘e odreÄ‘eni prag (Î¸).

**2. Generiranje eventa:**

* Ako |C(t)| > Î¸ â†’ generira se event (ON za porast, OFF za pad svjetline).
* Male promjene ispod praga se ignoriraju.

**3. Problem kvantizacije:**

* Potrebno je definirati kako pretvoriti kontinuirane promjene svjetline u diskretne dogaÄ‘aje.
* KljuÄno je odabrati prag koji daje dovoljno informacija, ali bez previÅ¡e Å¡uma.

**4. Izazovi:**

* **Previsok prag:** gube se male, ali vaÅ¾ne promjene.
* **Prenizak prag:** nastaje previÅ¡e Å¡uma (previÅ¡e eventova).
* **FiziÄko ograniÄenje:** pikseli imaju ograniÄen odziv (RC krug â†’ bandwidth limit), pa ne mogu detektirati ekstremno brze promjene.

**5. Logaritamska kvantizacija:**

* U praksi se koristi logaritamska razina svjetline:
  [
  \log(I(t)) - \log(I(t - Î”t))
  ]
* Time se postiÅ¾e bolja stabilnost u razliÄitim uvjetima osvjetljenja.

**6. ZakljuÄak:**
Kvantizacija temporalnog kontrasta je proces kojim DVS senzor pretvara kontinuirane promjene svjetline u diskretne, informativne dogaÄ‘aje pomoÄ‡u praga i logaritamske transformacije, uz fiziÄko ograniÄenje brzine odziva piksela.

---

Nove metode trebaju uzeti u obzir: space-time, photometriÄku i stohastiÄku prirodu podataka
Kako najefikasnije izvuÄ‡i info iz evenata da bude relevantno za task koji se rijeÅ¡ava?
Kako se noisy i neidealni efekti mogu modificirati da se lakÅ¡e izvlaÄe korisne informacije



---

## ğŸ”¹ Osnovni koncept

Event-based kamera (DVS) ima piksele koji **ne snimaju frameove**, nego reagiraju *neovisno i asinkrono* na **promjene u logaritmu svjetlosnog toka** (fotostruke).

Definicija:
[
L = \log(I)
]
gdje je ( I ) â€“ fotostruja (intenzitet svjetlosti), a ( L ) logaritamska svjetlina (â€œbrightnessâ€).

---

## ğŸ”¹ Kada se generira event

Svaki piksel ima svoju zadnju pohranjenu vrijednost svjetline.
Event se generira kad promjena svjetline **od zadnjeg eventa** prijeÄ‘e odreÄ‘eni prag ( C ):

[
L(x_k, t_k) - L(x_k, t_k - \Delta t_k) = p_k C \quad (1)
]

* ( x_k ): koordinate piksela koji je ispalio event
* ( t_k ): trenutak dogaÄ‘aja
* ( p_k \in {+1, -1} ): **polarnost** eventa

  * ( +1 ) = porast svjetline (**ON event**)
  * ( -1 ) = pad svjetline (**OFF event**)
* ( C ): **temporalni kontrastni prag** (threshold) â€” minimalna promjena log-svjetline potrebna da piksel reagira

Dakle:
svaki piksel *pamti zadnju vrijednost L* i *emitira event* kad se promijeni za Â±C.

---

## ğŸ”¹ ZnaÄenje praga C

* Prag ( C ) postavljaju **bias struje** u tranzistorima piksela.
* Te struje definiraju **osjetljivost** i **brzinu detekcije**.
* Prag se moÅ¾e softverski podesiti (tipiÄno 10â€“50% promjene osvjetljenja).
* NiÅ¾i prag â†’ veÄ‡a osjetljivost, ali i viÅ¡e Å¡uma.
* Donja granica (~1%) postiÅ¾e se samo pri jakom svjetlu i niskom Å¡umu.

---

## ğŸ”¹ Povezanost s derivacijom svjetline

Ako su promjene male (tj. kratko vrijeme izmeÄ‘u dva eventa), promjenu svjetline moÅ¾eÅ¡ aproksimirati derivacijom (Taylorova ekspanzija):

[
L(x_k, t_k) - L(x_k, t_k - \Delta t_k) \approx \frac{\partial L}{\partial t}(x_k, t_k) , \Delta t_k
]

Ubacimo to u prethodnu formulu (1):

[
\frac{\partial L}{\partial t}(x_k, t_k) \approx \frac{p_k C}{\Delta t_k} \quad (3)
]

To znaÄi da **frekvencija eventova (1/Î”t)** indirektno kodira **brzinu promjene svjetline**.
Drugim rijeÄima: viÅ¡e eventova u jedinici vremena = brÅ¾a promjena u sceni.

---

## ğŸ”¹ Fizikalno znaÄenje

* DVS ne mjeri **apsolutnu svjetlinu**, nego **promjene** u njoj.
* KlasiÄna kamera daje â€œkadrove svjetlineâ€, dok DVS daje â€œspikeove kontrastaâ€.
* To je *asinkrono mjerenje derivacije u vremenu*.

---

## ğŸ”¹ Povezanost s gibajuÄ‡im rubovima

Ako pretpostavimo da je ukupna svjetlina scene konstantna, promjene svjetline proizlaze iz **kretanja rubova**.
Linearizacijom i primjenom *brightness constancy assumption* dobijeÅ¡:

[
\frac{\partial L}{\partial t} = -\nabla L \cdot v
]

* ( \nabla L = (\partial_x L, \partial_y L) ) je **gradijent svjetline** (smjer ruba).
* ( v = (v_x, v_y) ) je **brzina kretanja toÄke na slici**.

Dakle:

* Ako je gibanje **paralelno s rubom** ((v \perp \nabla L)) â†’ nema promjene â†’ nema eventa.
* Ako je gibanje **okomito na rub** ((v \parallel \nabla L)) â†’ maksimalna promjena â†’ mnogo eventova.

To objaÅ¡njava zaÅ¡to DVS detektira **ruba u pokretu**, a ne teksture koje miruju.

---

## ğŸ”¹ ProbabilistiÄki model generiranja eventa

Idealna jednadÅ¾ba (1) pretpostavlja savrÅ¡en senzor bez Å¡uma.
U stvarnosti postoje:

* **SluÄajni Å¡um** (shot noise u fotostruji)
* **mismatch** izmeÄ‘u tranzistora
* **varijacije praga** izmeÄ‘u piksela

Zbog toga je prag **stohastiÄan**, tj. nije uvijek toÄno C, nego varira oko njega prema **normalnoj raspodjeli**:

[
P(C) \sim \mathcal{N}(C, \sigma_C)
]
gdje je tipiÄna Å¡irina distribucije (Ïƒ) oko 2â€“4% kontrasta.

---

## ğŸ”¹ Dodatni efekti

* **Refraktorni period:** kratko vrijeme nakon emitiranja eventa u kojem piksel *ignorira nove promjene* (ograniÄava brzinu).
* **Bus congestion:** kad previÅ¡e piksela istovremeno Å¡alje evente, nastaje â€œzaguÅ¡enjeâ€ na sabirnici.
* **Fixed Pattern Noise (FPN):** varijacija praga i odziva izmeÄ‘u piksela (standardna devijacija 2â€“4%).

---

## ğŸ”¹ ZakljuÄak

Event-based kamera:

1. Radi u log-svjetlosnoj domeni.
2. Generira event kad promjena svjetline prijeÄ‘e prag ( C ).
3. ( p_k ) oznaÄava polaritet (ON/OFF).
4. Derivacija svjetline ( \frac{\partial L}{\partial t} ) povezana je s frekvencijom eventova.
5. Eventi nastaju najviÅ¡e na pokretnim rubovima, kad je ( v \parallel \nabla L ).
6. Prag ( C ) je stohastiÄan zbog Å¡uma, a fiziÄki ga ograniÄavaju bias struje, shot noise i osvjetljenje.

---



---

### **Napredne event kamere â€“ saÅ¾etak kljuÄnih toÄaka**

**1. OpÄ‡i kontekst**

* Trenutno su dostupne samo kroz **znanstvene suradnje** s razvojnim timovima.
* Fokus istraÅ¾ivanja je na **proÅ¡irenju funkcionalnosti**: boja, osjetljivost, dinamiÄki raspon.

---

**2. Event kamere s bojom (Color event cameras)**

* Cilj: omoguÄ‡iti *color vision* u event kamerama (kao kod ljudi i obiÄnih kamera).
* **Rani pokuÅ¡aji** koristili â€œ*vertacolor principle*â€ (razliÄite valne duljine svjetla razliÄito prodiru u silicij).

  * Pionir: **Foveon senzori**.
  * Problem: **slaba separacija boja** (nema Äiste razlike izmeÄ‘u R, G, B kanala).
* **Noviji pristupi:**

  * **Color Filter Arrays (CFA)** â€“ integrirani RGB filteri iznad piksela.
  * **Color-splitter prizme** â€“ optiÄki razdvajaju boje na odvojene senzore.

    * Prednost: bolja separacija boja.
    * Mana: **veÄ‡a cijena** i sloÅ¾enost.

---

**3. PoveÄ‡ana kontrastna osjetljivost (Higher Contrast Sensitivity)**

* Cilj: **detektirati manje promjene svjetline** (veÄ‡a osjetljivost).
* Eksperimentalni senzori postigli osjetljivost do **~1% promjene osvjetljenja** (u laboratorijskim uvjetima).
* Tehnika:

  * Temeljeno na ideji **bolometra** â€“ pojaÄanje signala *prije detektora promjene*.
  * To smanjuje **Fixed Pattern Noise (FPN)** i poveÄ‡ava preciznost detekcije.
* Problem: preamplifikacija zahtijeva **aktivnu kontrolu pojaÄanja** da se izbjegne zasiÄ‡enje (â€œclippingâ€).
* Kompromis: **veÄ‡a osjetljivost â†’ manji dinamiÄki raspon**.

---

**4. KljuÄna ograniÄenja**

* Trenutni napredni modeli su **eksperimentalni**, nisu komercijalno dostupni.
* Balans izmeÄ‘u **osjetljivosti, dinamiÄkog raspona i troÅ¡ka** joÅ¡ nije optimalno rijeÅ¡en.

---


---

### **Ekstrakcija informacija iz event podataka â€“ saÅ¾etak kljuÄnih toÄaka**

**1. KljuÄno pitanje:**
Kako izvuÄ‡i *znaÄajne informacije* iz asinkronih, rijetkih i vremenski preciznih event podataka â€” ovisi o konkretnoj **aplikaciji** (npr. praÄ‡enje, rekonstrukcija, prepoznavanje).
To pitanje odreÄ‘uje **dizajn algoritma**.

---

**2. Svojstva event podataka:**

* **Asinkroni** â€“ svaki piksel Å¡alje event neovisno.
* **Sparse** â€“ veÄ‡ina piksela u datom trenutku ne generira event.
* **Visoka vremenska rezolucija** i **niska latencija**.

---

**3. Dvije osnovne kategorije algoritama:**

| Kategorija                            | Opis                                                  | Latencija | Napomena                                  |
| ------------------------------------- | ----------------------------------------------------- | --------- | ----------------------------------------- |
| **(i) Event-by-event**                | Svaki dolazni event odmah aÅ¾urira stanje sustava      | Minimalna | NajniÅ¾a latencija, ali veÄ‡a sloÅ¾enost     |
| **(ii) Event-packet (grupne metode)** | Obrada blokova (paketa) dogaÄ‘aja u vremenskom prozoru | ViÅ¡a      | Uvodi kaÅ¡njenje, ali stabilniji rezultati |

*Napomena:*
Granica izmeÄ‘u kategorija nije stroga â€“ prozori mogu â€œklizitiâ€ po jedan event, pa se stanje moÅ¾e aÅ¾urirati i kontinuirano.

---

**4. KljuÄna spoznaja:**
Jedan event sam po sebi **nije dovoljan** za pouzdanu procjenu â€”
potrebno je dodatno znanje ili povijest proÅ¡lih dogaÄ‘aja.

---

**5. Orijentacijska (ortogonalna) klasifikacija algoritama:**
Prema **naÄinu obrade dogaÄ‘aja:**

| Tip pristupa                 | Opis                                                                            |
| ---------------------------- | ------------------------------------------------------------------------------- |
| **Model-based**              | Koristi fizikalne ili geometrijske modele (npr. optiÄki tok, geometriju kamere) |
| **Model-free / Data-driven** | UÄi reprezentacije iz podataka (npr. deep learning, ML pristupi)                |

---

**6. Prema tipu funkcije cilja (loss function):**

* **Geometrijska** â€“ temelji se na poloÅ¾aju i pokretu toÄaka u prostoru.
* **Vremenska (temporal)** â€“ koristi vremenski slijed i kaÅ¡njenja izmeÄ‘u eventova.
* **Fotometrijska** â€“ temelji se na polaritetu i aktivnosti dogaÄ‘aja (ON/OFF).

---

**7. Trenutni fokus istraÅ¾ivanja:**
IstraÅ¾uju se prednosti i mane svake kategorije (event-by-event vs. group, model-based vs. ML) te kombinacije koje optimiziraju balans izmeÄ‘u **toÄnosti, brzine i robusnosti**.

---
KONCEPT POSITIVE I NEGATIVE EVENATA:
| Type           | Meaning            | Triggered when  | Color in visualization |
| -------------- | ------------------ | --------------- | ---------------------- |
| Positive Event | Pixel got brighter | Î”L â‰¥ +threshold | Green                  |
| Negative Event | Pixel got darker   | Î”L â‰¤ -threshold | Red                    |


Eventi se procesiraju i Äesto se transformiraju u alternativne reprezentacije (npr. events in space time, event frames, time surface s timestampovima po pikselu, voxel grid, motion compensated event image, reconstrcted intensity image itd.)

---

### **1. Events in spaceâ€“time (prostorno-vremenski dogaÄ‘aji)**

* Svaki event se predstavlja trojkom *(x, y, t, p)* â†’ pozicija, vrijeme i polaritet.
* Vizualno: â€œtoÄkiceâ€ u 3D prostoru gdje je Z-os vrijeme.
* Koristi se za analizu *temporalne dinamike* (kretanje objekata, optical flow).
* To je najosnovnija forma â€” niÅ¡ta agregirano, Äista sirova temporalna informacija.

---

### **2. Event frame (akumulirani dogaÄ‘aji u sliku)**

* Najjednostavnije: â€œbrojiâ€ koliko se pozitivnih i negativnih dogaÄ‘aja dogodilo u odreÄ‘enom vremenskom prozoru.
* DobijeÅ¡ 2D sliku (kao frame) gdje intenzitet piksela = broj dogaÄ‘aja.
* GubiÅ¡ preciznu vremensku informaciju, ali moÅ¾eÅ¡ koristiti standardne CNN-ove.
* Korisno za vizualizaciju ili klasiÄne detekcijske mreÅ¾e.

---

### **3. Time surface**

* Svaki piksel sadrÅ¾i **vrijeme posljednjeg dogaÄ‘aja**.
* DobijeÅ¡ â€œmapu svjeÅ¾ineâ€ â€” noviji eventi imaju veÄ‡e vrijednosti.
* Koristi se za *motion detection* i *feature tracking*, jer pokazuje gdje se *nedavno* neÅ¡to promijenilo.
* MoÅ¾e se eksponencijalno â€œzaboravljatiâ€ starije evente â†’ time decay.

---

### **4. Voxel grid**

* DogaÄ‘aje rasporediÅ¡ u 3D mreÅ¾u (x, y, vrijeme).
* Vremenska dimenzija se diskretizira u N binova (npr. 5â€“10 vremenskih slojeva).
* DobijeÅ¡ â€œ3D tensorâ€ koji CNN ili transformer moÅ¾e direktno obraÄ‘ivati.
* Zlatni standard u deep-learning pristupima za event kamere (npr. EV-FlowNet, E2VID).

---

### **5. Motion-compensated event image**

* PokuÅ¡ava â€œporavnatiâ€ dogaÄ‘aje tako da izgleda kao da su snimljeni istovremeno.
* Radi *kompenzaciju gibanja* objekata ili kamere na temelju pretpostavljenog optic flow-a.
* Kad to ispravno napraviÅ¡, svi eventi od istog ruba poravnaju se â†’ oÅ¡tra rekonstruirana slika.
* Koristi se kod rekonstrukcije scene i odvajanja pozadine/predmeta u pokretu.

---

### **6. Reconstructed intensity image**

* Koristi sve dogaÄ‘aje (Äesto + poÄetni â€œkey frameâ€) da rekonstruira standardnu RGB ili grayscale sliku.
* Ideja: integrira promjene svjetline tijekom vremena.
* Koristi se u **E2VID** i sliÄnim mreÅ¾ama koje rade â€œframe-like outputâ€ iz event streama.
* Super za situacije s visokim dinamiÄkim rasponom ili slabim osvjetljenjem.


Metode za event processing

Preprocessing (input adaptation)
Core processing (feature extraction and analysis)
Postprocessing (output creation)

U preprocessingu koristi se event packet
Motion-compensated event images se koriste u core processingu

Metoda obrade ovisi o tome kako su eventi reprezentirani i koji je hardver dostupan

| **Aspekt**                 | **Event-by-Event obrada**                                                | **Event-Packet obrada**                                                       |
| -------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------------- |
| **Opis**                   | Svaki dogaÄ‘aj se procesira individualno, odmah po dolasku.               | DogaÄ‘aji se grupiraju u vremenske pakete i procesiraju zajedno.               |
| **TipiÄne reprezentacije** | Sparse (rijetke) reprezentacije, vremenski toÄne (x, y, t, p).           | Dense reprezentacije poput event framea, voxel grida, time surfacea.          |
| **Hardverska platforma**   | Neuromorfni Äipovi i SNN arhitekture.                                    | Standardni CPU/GPU procesori.                                                 |
| **TipiÄni algoritmi**      | Spiking neuronske mreÅ¾e (SNN), deterministiÄki i probabilistiÄki filtri. | DNN-ovi, CNN-ovi, ruÄno dizajnirani feature extractori.                       |
| **Prednosti**              | Vrlo niska latencija, energetska uÄinkovitost, prirodno asinkrono.       | Jednostavnije za implementaciju, kompatibilno s postojeÄ‡im ML frameworkovima. |
| **Nedostaci**              | Zahtijeva specijalizirani hardver i kompleksniju arhitekturu.            | Gubi vremensku preciznost i poveÄ‡ava latenciju.                               |
| **TipiÄne primjene**       | Real-time kontrola, robotika, edge sustavi, ultra-brzi odziv.            | Analiza scene, rekonstrukcija slike, uÄenje iz dogaÄ‘ajnih podataka.           |

---


---

## ğŸ§  Event-by-Event metode

### ğŸ”¹ 1. DeterministiÄki filteri

* **Primjeri:** prostorno-vremenske konvolucije, activity filteri.
* **Koriste se za:**

  * Redukciju Å¡uma
  * Ekstrakciju znaÄajki (feature extraction)
  * Rekonstrukciju slike
  * Filtriranje svjetline
* **Prednost:** savrÅ¡eno prirodni za asinkrone podatke â€” omoguÄ‡uju minimalnu latenciju i iskoriÅ¡tavaju svojstva senzora.

---

### ğŸ”¹ 2. ProbabilistiÄki (Bayesovski) filteri

* **Primjeri:** Kalman filter, particle filter.
* **Koriste se za:**

  * PraÄ‡enje poloÅ¾aja i orijentacije (pose tracking) u SLAM sustavima.
* **Zahtijevaju dodatne informacije:**

  * Npr. grayscale slike, mapu scene ili povijesne evente.
* **NaÄin rada:** svaki novi event usporeÄ‘uje se s postojeÄ‡om "appearance" informacijom â†’ razlika (innovation) aÅ¾urira stanje filtra.
* **Prednosti:** mogu kombinirati podatke iz viÅ¡e izvora i raditi s djelomiÄnim informacijama.

---

### ğŸ”¹ 3. ViÅ¡eslojni neuronski modeli (ANN / SNN)

* **Dvije glavne grane:**

  * **SNN (Spiking Neural Networks)** â€“ prirodno procesiraju evente jedan po jedan.
  * **KlasiÄne DNN mreÅ¾e** â€“ Äesto trenirane na event-paketima, kasnije konvertirane u SNN.

---

### ğŸ”¹ 4. UÄenje i treniranje

* **Nesupervizirano uÄenje:**

  * Koristi se za ekstrakciju znaÄajki (feature extraction).
  * Rezultat se Äesto Å¡alje u klasiÄni klasifikator (npr. SVM).
  * Ipak, i dalje je potrebna odreÄ‘ena koliÄina oznaÄenih podataka (labeled data).

* **Supervizirano uÄenje:**

  * Ako ima dovoljno oznaÄenih podataka, moÅ¾e se direktno trenirati ANN/SNN bez dodatnog klasifikatora.
  * **Rezultat:** viÅ¡a toÄnost nego kod nesuperviziranog pristupa.

---

### ğŸ”¹ 5. Kombinirani pristupi

* Tijekom treniranja: koriste **pakete eventa** (frame-based deep learning).
* Nakon treniranja: model se pretvara u **SNN koji procesira evente jedan po jedan**.
* Ova kombinacija koristi prednosti i klasiÄnih GPU mreÅ¾a i neuromorfnih sustava.

---

### ğŸ”¹ 6. Glavne primjene

* **Klasifikacija objekata**
* **Prepoznavanje akcija / pokreta**
* **Embedded sustavi** â€“ optimizirani za efikasnost i nisku latenciju, Äesto koriste **custom SNN hardver**.

---

### ğŸ”¹ 7. Trendovi i buduÄ‡i razvoj

* PoveÄ‡an interes za:

  * **Supervizirano uÄenje direktno u SNN-ovima**
  * **Ugradnju takvih sustava u embedded ureÄ‘aje** radi brzine i energetske uÄinkovitosti.

---

Naravno â€” ovo je jako bogat odlomak, pa sam ti izvukao **sve kljuÄne koncepte i ideje** u pregledne, tematski grupirane natuknice u **markdown formatu**.
Sve bitno o **"Methods for Groups of Events"** (tj. grupnom procesiranju eventa) je ovdje saÅ¾eto i jasno ğŸ‘‡

---

## âš™ï¸ Methods for Groups of Events

*(Metode koje procesiraju viÅ¡e dogaÄ‘aja zajedno â€” grupno, a ne pojedinaÄno)*

---

### ğŸ”¹ 1. Osnovna ideja

* **Razlog:** pojedinaÄni eventi nose premalo informacija i puno Å¡uma.
* **RjeÅ¡enje:** grupiranjem viÅ¡e eventa postiÅ¾e se bolji **signal-to-noise ratio**.
* **Proces:** viÅ¡e eventa se kombinira u **reprezentacije** poput:

  * event packet
  * event frame
  * time surface (TS)
  * voxel grid
* Takve reprezentacije omoguÄ‡uju koriÅ¡tenje klasiÄnih CV (computer vision) metoda.

---

### ğŸ”¹ 2. Event Frames

* Vrlo praktiÄna reprezentacija jer omoguÄ‡uje ponovnu upotrebu klasiÄnih CV alata.
* **Koristi se za:**

  * stereo viziju (dobri, ali skromni rezultati)
  * estimaciju poloÅ¾aja kamere (pose estimation)
  * optical flow (block matching)
  * input za DNN, SVM, Random Forest klasifikatore
* **Posebna prednost:** adaptivni frame rate (ovisno o sceni).
* **Napomena:** rijetki radovi uzimaju u obzir fotometrijsko znaÄenje eventa (npr. promjenu svjetline).

---

### ğŸ”¹ 3. Intensity Increment Images

* Koriste **inkremente svjetline** izmeÄ‘u dogaÄ‘aja.
* **Primjene:**

  * praÄ‡enje znaÄajki (feature tracking)
  * deblurring (odstranjivanje zamuÄ‡enja slike)
  * praÄ‡enje kamere (camera tracking)

---

### ğŸ”¹ 4. Time Surfaces (TS)

* **Opis:** mapa koja biljeÅ¾i *vrijeme zadnjeg eventa po pikselu*.
* **Osjetljive su na:** rubove i smjer gibanja objekta.
* **Primjene:**

  * analiza gibanja i prepoznavanje oblika
  * iz TS-a se moÅ¾e izvesti **optical flow** (fitanjem ravnina kroz prostor-vrijeme)
  * ulaz za **CNN-e** koji raÄunaju optical flow i brzinu
  * **corner detection** (Harris, FAST, ili noviji ML pristupi)
  * stereo vizija pomoÄ‡u **temporalnog podudaranja** (event concurrence & timestamp similarity)
* **Problem:** degradacija performansi u teksturiranim scenama â†’ **motion overwriting** (novi eventi briÅ¡u tragove starih).

---

### ğŸ”¹ 5. Voxel Grids

* **Opis:** 3D volumetrijska reprezentacija (x, y, t).
* **Prednosti:** bolje Äuva vremensku informaciju.
* **Nedostatak:** troÅ¡i viÅ¡e memorije i raÄunske snage.
* **Koristi se za:**

  * optical flow (varijacijska optimizacija)
  * DNN ulaze/izlaze s viÅ¡e kanala (multi-channel input/output)
* **NaÄin obrade:**

  * konvolucije nad voxelima
  * optimizacija po kriteriju minimalne greÅ¡ke (objective function)

---

### ğŸ”¹ 6. KoriÅ¡tenje konvencionalnih CV alata

* Kad se eventi pretvore u grid/frame formu â€” mogu se koristiti svi klasiÄni alati:

  * **CNN feature extractori**
  * **SliÄnosne metrike (cross-correlation, event alignment)** za:

    * klasifikaciju (SVM, CNN)
    * klasteriranje
    * detekciju pokreta (motion estimation)
* U **neuroscience** zajednici postoje i metriÄki pristupi koji rade direktno na *spikeovima* â€” bez konverzije u slike.

---

### ğŸ”¹ 7. Deep Learning pristupi

* Koriste **DNN** nad razliÄitim reprezentacijama:

  * event images
  * time surfaces (TS)
  * voxel grids
  * point sets
* **Primjene:**

  * klasifikacija
  * rekonstrukcija slike
  * predikcija kuta upravljanja (steering angle)
  * optical flow, depth, ego-motion estimacija
* **Supervizirano uÄenje:**

  * koriste *ground truth* (npr. pozu kamere, grayscale sliku)
  * mjere *photoconsistency*
* **Nesupervizirano uÄenje:**

  * koristi samo input evente (nema oznaka)
  * loss funkcije za to su istraÅ¾ene u [99]
* **Arhitektura:**

  * najÄeÅ¡Ä‡e *encoder-decoder*
  * koristi samo konvolucije (manje parametara)
  * gubitak (loss) se moÅ¾e primijeniti na svaku razinu dekodera.

---

### ğŸ”¹ 8. Motion Compensation

* **Ideja:** pronaÄ‡i parametre gibanja koji najbolje "poravnaju" skup eventa u vremenu.
* **Prednost:** koristi *kontinuirani vremenski model* â€” iskoriÅ¡tava visoku temporalnu rezoluciju senzora.
* **Primjene:**

  * ego-motion estimacija
  * optical flow
  * procjena dubine
  * segmentacija pokreta
  * feature motion za VIO (Visual-Inertial Odometry)
* **Algoritmi:** koriste optimizacijske metode kao Å¡to su **Gauss-Newton** i **Conjugate Gradient**.

---

### ğŸ”¹ 9. Odabir veliÄine grupe eventa

* KljuÄni **hiperparametar** â€“ koliko eventa ulazi u jednu grupu.
* **Strategije odabira:**

  1. **Fiksni broj eventa**
  2. **Fiksno vrijeme promatranja** (konstantni frame rate)
  3. **Adaptivni pristupi** â€” npr. threshold prema gustoÄ‡i eventa u regiji.
* **Trade-off:**

  * Fiksni broj eventa = jednostavno, ali ne uzima u obzir varijacije po slici.
  * Fiksno vrijeme = broj eventa se mijenja (nekad premalo, nekad previÅ¡e).
  * Adaptivno = najbolje rjeÅ¡enje, ali sloÅ¾enije za dizajnirati.

---

* Dizajn event kamera temelji se na bioloÅ¡kim principima i raÄunalnim primitivima, poput Spiking Neural Networks (SNN).
* DVS (Dynamic Vision Sensor) je inspiriran bioloÅ¡kim vizualnim putevima, posebno â€œtransientâ€ (privremenim) putevima koji obraÄ‘uju dinamiÄke vizualne informacije u â€œwhereâ€ (gdje) putu.
* Transient put postoji kod mnogih Å¾ivotinja, ukljuÄujuÄ‡i ljude, i Äini oko 30% ljudskog vizualnog sustava.
* PoÄinje s transient ganglijskim stanicama u retini (izvan fovee), zatim prolazi kroz magno slojeve talamusa i pod-slojeve podruÄja V1, te zavrÅ¡ava u podruÄjima MT i MST (dio dorzalnog puta, povezanog s prepoznavanjem pokreta).
* DVS senzor odgovara dijelu tog transient puta do razine retinalnih ganglijskih stanica.
* ATIS (senor koji biljeÅ¾i i svjetlinu) generira grayscale dogaÄ‘aje koji odgovaraju â€œsustainedâ€ ili â€œwhatâ€ (Å¡to) putu kroz parvo slojeve mozga.

Transient - dio vizualnog sustava koji reagira na brze promjene i pokret u vidnom polju; obraÄ‘uje dinamiÄke informacije poput gibanja ili promjene kontrasta; brza, ali kratkotrajna reakcija.
Fovea - srediÅ¡nji dio mreÅ¾nice oka gdje je vidna oÅ¡trina najveÄ‡a; sadrÅ¾i gusto rasporeÄ‘ene ÄunjiÄ‡e koji detektiraju boje; odgovorna za detaljno i precizno gledanje.
Magno slojevi talamusa - dio lateralnog genikulatnog tijela (LGN) u talamusu; obraÄ‘uju informacije o pokretu, kontrastu i svjetlini; povezani su s transient putem (gdje put).
V1 - primarno vidno podruÄje u okcipitalnom reÅ¾nju mozga; prvi korak obrade vizualnih informacija iz oka; analizira osnovne znaÄajke slike kao Å¡to su rubovi, orijentacija i smjer kretanja.
MT - podruÄje srednjeg temporalnog reÅ¾nja (Middle Temporal area); specijalizirano za percepciju kretanja; sadrÅ¾i stanice osjetljive na smjer i brzinu gibanja.
MST - podruÄje medijalno od MT (Medial Superior Temporal area); obraÄ‘uje sloÅ¾enije oblike kretanja poput rotacije, ekspanzije i optiÄkog toka (npr. kretanje kroz prostor).
Ganglijske stanice - stanice mreÅ¾nice koje primaju signale od fotoreceptora (ÄunjiÄ‡a i Å¡tapiÄ‡a) i prosljeÄ‘uju ih mozgu putem vidnog Å¾ivca; postoje razliÄiti tipovi (npr. transient i sustained).
What put - ventralni (Å¡to) vizualni put; obraÄ‘uje informacije o obliku, boji i identitetu objekata; odgovoran za prepoznavanje i kategorizaciju onoga Å¡to vidimo.
Parvo slojevi mozga - parvocelularni slojevi LGN-a u talamusu; prenose informacije o boji i finim detaljima slike; povezani s what putem i sporijom, ali preciznijom obradom.

Umjetni neuroni, poput Leaky-Integrate and Fire ili Adaptivnih Eksponencijalnih su inspirirani neuronima pronaÄ‘enima u vizualnom kortexu sisavaca
Oni su osnovne gradivne jedinice SNN-ova
Neuron prima input spikeove (evente) iz malog podruÄja vidokruga (receptive field)
Spikeovi modificiraju membranski potencijal i stvaraju output spike (action potencijal) kada napon nadmaÅ¡i threshold
Neuroni su povezani hijerarhijski i stvaraju SNN-ove
Spikeove mogu stvarati ili pikseli event kamere ili neuroni SNN-a

* Prvi slojevi vizualnih modela koriste receptive fields temeljene na **Difference of Gaussians** (osjetljivost na kontrast izmeÄ‘u srediÅ¡ta i okoline), **Gabor filterima** (osjetljivost na orijentirane rubove) ili njihovim kombinacijama.
* Kako informacija prolazi dublje kroz mreÅ¾u, receptive fields postaju **sve sloÅ¾eniji**.
* U umjetnim neuronskim mreÅ¾ama (ANN), obrada u unutarnjim slojevima Äesto se **aproksimira konvolucijom**.
* U umjetnim spiking neuronskim mreÅ¾ama (SNN), Äesto se pretpostavlja da neuron **ne generira izlazne spikeove** ako nije primio ulazne spikeove iz prethodnog sloja.
* Ta pretpostavka omoguÄ‡uje **preskakanje izraÄuna** za neaktivne neurone, Äime se poveÄ‡ava uÄinkovitost.
* Rezultat vizualne obrade u takvim sustavima pojavljuje se **gotovo istovremeno s podraÅ¾ajem**, za razliku od klasiÄnih CNN-ova gdje se konvolucije raÄunaju istodobno u svim toÄkama i u fiksnim vremenskim intervalima.

* Bio-inspirirani modeli koriste se za **niz niskorazinskih vizualnih zadataka**.
* **Event-based optical flow** moÅ¾e se izraÄunati pomoÄ‡u **spatio-temporalno orijentiranih filtera** koji oponaÅ¡aju rad receptive fields u primarnom vidnom korteksu.
* Ti isti filteri koriste se i za **spike-based modele selektivne paÅ¾nje**, temeljene na bioloÅ¡kim principima.
* **Modeli inspirirani binokularnim vidom** (s rekurzivnim lateralnim vezama te ekscitacijsko-inhibicijskim neuronskim vezama) primijenjeni su za **event-based stereo korespondenciju** i **kontrolu konvergencije oÄiju kod humanoidnih robota**.
* Vizualni korteks posluÅ¾io je kao inspiracija za **hijerarhijski model ekstrakcije znaÄajki**, implementiran u SNN-ovima i koriÅ¡ten za **prepoznavanje objekata**.
* UÄinkovitost takvih mreÅ¾a raste ako **bolje iskoriÅ¡tavaju precizno vremensko usklaÄ‘ivanje spikeova**.
* Rani modeli bili su **ruÄno dizajnirani** (npr. pomoÄ‡u Gabor filtera), dok noviji koriste **uÄenje temeljeno na STDP-u (Spike-Timing Dependent Plasticity)** za samostalno formiranje receptive fields, Å¡to daje bolje rezultate.
* Novija istraÅ¾ivanja ukljuÄuju i **supervizirane metode uÄenja** poput **backpropagationa** za implementaciju **spiking dubokih konvolucijskih mreÅ¾a**.
* Prednosti bio-inspiriranih metoda u odnosu na klasiÄne: **niÅ¾a latencija** i **veÄ‡a uÄinkovitost**.
* **Vid kukaca** takoÄ‘er je izvor inspiracije â€” razvijeni su **event-based sustavi za izbjegavanje prepreka i brzo prepoznavanje meta** u malim robotima, temeljeni na neuronima koji reagiraju na nadolazeÄ‡e objekte i pokreÄ‡u **reflekse izbjegavanja**.


Primjene:
	Low-level:
		- detekcija znaÄajki
		- praÄ‡enje objekata
		- optical flow estimation
	3d scene structure related:
		- procjena dubine
		- vizualna odometrija
		- intensity image reconstruction
	Higher-level:
		- segmentacija gibanja
		- prepoznavanje i povezivanje percepcije s kontrolom pokreta
		
* **Detekcija i praÄ‡enje znaÄajki** kljuÄni su elementi mnogih vizualnih zadataka poput **vizualne odometrije** (Odometrija je metoda za **mjerenje prijeÄ‘enog puta i poloÅ¾aja u prostoru** na temelju informacija o **kretanju senzora ili kamere**.

U kontekstu **vizualne odometrije**, to znaÄi da se **raÄuna koliko se kamera (ili robot) pomaknula** analizom promjena u slikama â€” dakle, prati se kako se toÄke u okolini pomiÄu izmeÄ‘u kadrova ili dogaÄ‘aja, pa se iz toga procijeni **putanja i orijentacija**.
), **segmentacije objekata** i **razumijevanja scene**.
* **Event kamere** omoguÄ‡uju **asinkrono praÄ‡enje** koje se prilagoÄ‘ava dinamici scene, uz **nisku latenciju**, **velik dinamiÄki raspon** i **malu potroÅ¡nju energije**.
* Time se omoguÄ‡uje **praÄ‡enje i tijekom â€œslijepog vremenaâ€** izmeÄ‘u okvira standardne kamere.
* Za to je potrebno razviti metode koje uzimaju u obzir **prostorno-vremenske** i **fotometrijske** karakteristike event podataka, jer oni biljeÅ¾e samo **promjene svjetline**.
* **Glavni izazovi:**

  * Promjene u izgledu scene uzrokovane **ovisnoÅ¡Ä‡u o smjeru gibanja**, Å¡to oteÅ¾ava detekciju i praÄ‡enje znaÄajki.
  * Potreba za **povezivanjem dogaÄ‘aja kroz vrijeme** (data association) unatoÄ promjenama izgleda.
  * **Å um senzora** i **event clutter** (viÅ¡ak dogaÄ‘aja) uzrokovan **pokretom kamere**.

* **Rani event-based algoritmi** za detekciju znaÄajki bili su vrlo jednostavni i sluÅ¾ili su za demonstraciju **niske latencije** i **male raÄunske sloÅ¾enosti** event sustava.
* Pretpostavljali su **statiÄnu kameru** i pratili **pokretne objekte** kao skupove dogaÄ‘aja (blobs), **krugove** ili **linije**.
* Obrada se radila samo na pikselima koji su generirali dogaÄ‘aje.
* **Gaussian filteri** i **mjeÅ¡avine Gaussovih funkcija** koristili su se za detekciju i praÄ‡enje takvih blobova.
* Svaki novi dogaÄ‘aj bio je **povezan s najbliÅ¾im postojeÄ‡im blobom** i asinkrono je **aÅ¾urirao njegove parametre** (poziciju, veliÄinu, itd.).
* Ovi pristupi koriÅ¡teni su u **nadzoru prometa**, **praÄ‡enju robota visoke brzine** i **praÄ‡enju Äestica u tekuÄ‡inama ili mikrorobotici**, ali su **ograniÄeni na jednostavne oblike**.
* Kasnije su razvijene metode za **praÄ‡enje sloÅ¾enijih, visokokontrastnih oblika**, temeljene na algoritmima kao Å¡to su **ICP (Iterative Closest Point)**, **gradient descent**, **Mean-Shift**, **Monte Carlo metode** i **particle filtering**.
* **Iterativne metode** (npr. ICP) koristile su **najbliÅ¾eg susjeda** za povezivanje dogaÄ‘aja s ciljanim oblikom i aÅ¾uriranje njegove transformacije, omoguÄ‡ujuÄ‡i **vrlo brzo praÄ‡enje (do 200 kHz)**.
* Drugi radovi koristili su **rotirane i skalirane verzije oblika (kernels)** s ugraÄ‘enim mehanizmom **odbijanja** kako se ne bi preklapali.
* **SloÅ¾eni objekti** poput lica ili tijela praÄ‡eni su pomoÄ‡u **modela sastavljenih od viÅ¡e dijelova** povezanih elastiÄnim â€œopruÅ¾nimâ€ vezama koje simuliraju fiziÄki sustav.
* VeÄ‡ina metoda tretira dogaÄ‘aje kao **pojedinaÄne toÄke bez polariteta** i aÅ¾urira stanje sustava **asinkrono**, s vrlo **malom latencijom**.
* UspjeÅ¡nost metoda ovisi o **finoj prilagodbi parametara**, koji se obiÄno podeÅ¡avaju **eksperimentalno** za odreÄ‘eni objekt.
* Ove metode traÅ¾e **prethodno znanje ili korisniÄki unos** o tome Å¡to se prati, Å¡to je pogodno za specifiÄne zadatke (npr. automobili ili lopte), ali nije praktiÄno za opÄ‡enite scene.
* Noviji pristupi definiraju **realistiÄnije znaÄajke** temeljene na **lokalnim rubnim uzorcima** (edge patterns), predstavljene kao skupovi toÄaka.
* Dolazni dogaÄ‘aji se s njima **usklaÄ‘uju pomoÄ‡u ICP-a**.
* Neki pristupi koriste **klasiÄne detektore i trackere** na **motion-compensated event slikama**, Å¡to daje dobre rezultate u prirodnim scenama i omoguÄ‡uje **procjenu vlastitog gibanja (ego-motion)**.
* ZnaÄajke izvedene iz **motion-compensated dogaÄ‘aja** pruÅ¾aju dobru reprezentaciju rubova, ali su **ovisne o smjeru kretanja**, pa s vremenom dolazi do **drifta (odmicanja praÄ‡enja)**.
* Za **praÄ‡enje bez drifta** potrebne su **motion-invariant znaÄajke** koje nisu osjetljive na promjenu smjera kretanja.



* **Kombinacija dogaÄ‘aja i frameova** (npr. kod senzora poput **DAVIS-a**) omoguÄ‡uje **jednostavnije povezivanje podataka (data association)**, jer su dostupne **apsolutne vrijednosti svjetline** â€” dakle, â€œmapaâ€ znaÄajke ne ovisi o smjeru kretanja.
* Ovi pristupi koriste **prednosti oba svijeta**: stabilnost i kontekst frameova + brzinu i nisku latenciju event podataka.
* Algoritmi automatski **detektiraju rubne uzorke (edge patterns)** na frameovima, a zatim ih **asinkrono prate dogaÄ‘ajima**.
* **Pozicija znaÄajke** dobiva se pomoÄ‡u **Harris corner detektora**, a **deskriptor znaÄajke** temelji se na **rubovima oko tog kuta**.
* U nekim metodama (npr. [125], [126]) **Canny rubovi** se pretvaraju u **skupove toÄaka (templates)** koje se koriste za **ICP praÄ‡enje** â€” pretpostavlja se da se dogaÄ‘aji javljaju **na jakim rubovima**.
* U radu [64], rubni uzorci se temelje izravno na **intenzitetima framea**, a praÄ‡enje se provodi tako da se traÅ¾e **parametri gibanja** koji **minimiziraju fotometrijsku pogreÅ¡ku** izmeÄ‘u dogaÄ‘aja i predviÄ‘ene slike iz generativnog modela.
* Usporedba pet metoda praÄ‡enja (iz [64]) pokazuje da **generativni model** daje **najveÄ‡u toÄnost (Äak i sub-pikselnu)**, ali je **raÄunski zahtjevan**.
* KljuÄno otkriÄ‡e: **frameovi nisu nuÅ¾ni** â€” mogu se **rekonstruirati iz samih dogaÄ‘aja**, a rezultati detekcije i praÄ‡enja ostaju **gotovo jednako dobri**.

Ukratko:
â†’ **Spajanje event + frame podataka** daje toÄno, robusno i brzo praÄ‡enje znaÄajki.
â†’ **Generativni pristupi** nude najbolju preciznost.
â†’ **Event-only sustavi** mogu postiÄ‡i sliÄne rezultate rekonstrukcijom frameova iz dogaÄ‘aja â€” Å¡to otvara put potpuno **frame-free sustavima**.

* **Event kamere** prirodno reagiraju na **rubove** u sceni, Å¡to ubrzava **detekciju niÅ¾erazinskih znaÄajki** poput **kljuÄnih toÄaka (keypoints)** ili **kutova (corners)**.
* Takve toÄke omoguÄ‡uju **pouzdano praÄ‡enje** jer ne pate od **aperture problema** i sluÅ¾e kao lokalni orijentiri za ekstrakciju znaÄajki.
* Metoda iz [186] detektira kutove kao **sjeciÅ¡ta dvaju pokretnih rubova**, dobivenih **aproksimacijom ravnina** u **prostorno-vremenskom toku dogaÄ‘aja**.

  * Za ublaÅ¾avanje Å¡uma koristi se **least-squares + RANSAC-sliÄna metoda uzorkovanja**.
  * Ta lokalna aproksimacija ravnina korisna je i za **procjenu optiÄkog toka** i **trajanja dogaÄ‘aja** (event lifetime).
* Razvijene su i **event inaÄice poznatih detektora kutova**, poput **Harris** i **FAST**, koje rade nad **time surface (TS)** reprezentacijom dogaÄ‘aja.

  * U [114] se **TS binarizira**, pa se na nju primjenjuju **derivacijski filtri Harris detektora**.
  * U [115] se derivacijski filtri zamjenjuju **piksel-po-piksel usporedbama** na **dvije koncentriÄne kruÅ¾nice** oko dogaÄ‘aja; kutovi se detektiraju tamo gdje **TS pokazuje dvije odvojene regije** (nova vs. stara dogaÄ‘anja).
* **[111]** poboljÅ¡ava ovaj pristup i uvodi **praÄ‡enje kutova** â€” pretpostavlja da kutovi prate **kontinuirane putanje**, a povezuju se po **blizini** pomoÄ‡u **grafova hipoteza**.
* Glavni problem TS-baziranih metoda: **ovisnost o smjeru gibanja**, jer promjena smjera mijenja izgled TS-a.
* **[112]** uvodi **data-driven pristup** â€” uÄi izgled TS-a za kutove koristeÄ‡i **nadzirano uÄenje** (labeliranje prema sivim slikama iz DAVIS/ATIS kamere).

  * Kao kompromis izmeÄ‘u toÄnosti i brzine koristi se **random forest klasifikator**.
* **Kutovi iz dogaÄ‘aja** imaju praktiÄne primjene u **vizualnoj odometriji** i **segmentaciji vlastitog gibanja (ego-motion segmentation)**, iako ih je zasad **relativno malo primijenjenih rjeÅ¡enja**.

* Opisane metode zahtjevaju da toÄno znamo Äa pratimo + joÅ¡ se traÅ¾i neki standardni naÄin evaluacije performansi
* 
